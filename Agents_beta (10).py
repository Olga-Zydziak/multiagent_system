#!/usr/bin/env python
# coding: utf-8

# ################################################################################
# ### IMPORT WSZYSTKICH POTRZEBNYCH ZALEÅ»NOÅšCI
# ################################################################################

# In[1]:


import os
import io
import sys
import subprocess
import tempfile
import traceback
import uuid
import json
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import datetime
import logging
from enum import Enum
import matplotlib.pyplot as plt
# --- Frameworki AgentÃ³w ---
import autogen
from autogen import Agent, ConversableAgent
from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent
from langgraph.graph import StateGraph, END
from pydantic import BaseModel, Field
from langchain_core.tools import tool
from langchain_google_vertexai import ChatVertexAI
from google.cloud import secretmanager
from typing import Optional, Tuple
from langchain_anthropic import ChatAnthropic
import langchain
from langchain.cache import SQLiteCache

#--Frameworki pamiÄ™ci--

from memory_models import MemoryRecord, MemoryType,DistilledMemory,DistilledSuccessMemory
from memory_bank_client import MemoryBankClient
import vertexai
from vertexai import agent_engines


# ################################################################################
# ### KONFIGURACJA PODSTAWOWA
# ################################################################################

# In[2]:


def get_secret(project_id: str, secret_id: str, version_id: str = "latest") -> str:
    """Pobiera wartoÅ›Ä‡ sekretu z Google Secret Manager."""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"
    response = client.access_secret_version(request={"name": name})
   
    return response.payload.data.decode("UTF-8")


# In[3]:


class ApiType(Enum):
    GOOGLE = "google"
    ANTHROPIC = "anthropic"
    def __str__(self):
        return self.value


# In[4]:


LOCATION="us-central1"
PROJECT_ID="dark-data-discovery"

#---------AGENTS--------:
MAIN_AGENT="gemini-2.5-pro"
API_TYPE_GEMINI=str(ApiType.GOOGLE)

CRITIC_MODEL="claude-3-7-sonnet-20250219"
CODE_MODEL="claude-sonnet-4-20250514"
API_TYPE_SONNET = str(ApiType.ANTHROPIC)

LANGCHAIN_API_KEY = get_secret(PROJECT_ID,"LANGCHAIN_API_KEY")
ANTHROPIC_API_KEY=get_secret(PROJECT_ID,"ANTHROPIC_API_KEY")

MEMORY_ENGINE_DISPLAY_NAME="memory-gamma-way"

INPUT_FILE_PATH = "gs://super_model/data/structural_data/synthetic_fraud_dataset.csv"

MAX_CORRECTION_ATTEMPTS=5


# In[5]:


os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = LANGCHAIN_API_KEY
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_PROJECT"] = "Projekt Multi-Agent-System v9.0-Integrated"
os.environ["ANTHROPIC_API_KEY"] =ANTHROPIC_API_KEY


# In[6]:


#---cache-------
langchain.llm_cache = SQLiteCache(database_path=".langchain.db")


# ################################################################################
# ### INICJOWANIE I KONFIGURACJA PAMIÄ˜CI DÅUGOTRWAÅEJ
# ################################################################################

# In[7]:


AGENT_ENGINE_NAME = "" # Zostanie wypeÅ‚niona po pobraniu lub utworzeniu silnika

# Inicjalizacja gÅ‚Ã³wnego klienta Vertex AI
client = vertexai.Client(project=PROJECT_ID, location=LOCATION)

def get_or_create_agent_engine(display_name: str) :
    """
    Pobiera istniejÄ…cy Agent Engine po nazwie wyÅ›wietlanej lub tworzy nowy, jeÅ›li nie istnieje.
    """
    # 1. Pobierz listÄ™ wszystkich istniejÄ…cych silnikÃ³w w projekcie
    all_engines = agent_engines.list()
    
    # 2. SprawdÅº, czy ktÃ³ryÅ› z nich ma pasujÄ…cÄ… nazwÄ™
    for engine in all_engines:
        if engine.display_name == display_name:
            print(f"INFO: Znaleziono i poÅ‚Ä…czono z istniejÄ…cym Agent Engine: '{display_name}'")
            return engine
            
    # 3. JeÅ›li pÄ™tla siÄ™ zakoÅ„czyÅ‚a i nic nie znaleziono, stwÃ³rz nowy silnik
    print(f"INFO: Nie znaleziono Agent Engine o nazwie '{display_name}'. Tworzenie nowego...")
    try:
        new_engine = agent_engines.create(
            display_name=display_name
        )
        print(f"INFO: PomyÅ›lnie utworzono nowy Agent Engine.")
        return new_engine
    except Exception as e:
        print(f"KRYTYCZNY BÅÄ„D: Nie moÅ¼na utworzyÄ‡ Agent Engine. SprawdÅº konfiguracjÄ™ i uprawnienia. BÅ‚Ä…d: {e}")
        exit()


# In[8]:


agent_engine =get_or_create_agent_engine(MEMORY_ENGINE_DISPLAY_NAME)
AGENT_ENGINE_NAME = agent_engine.resource_name
print(AGENT_ENGINE_NAME)


# ################################################################################
# ### ### FAZA 1: PLANOWANIE STRATEGICZNE (AutoGen)
# ################################################################################

# In[9]:


#FUNKCJA KONFIGURACYJNA AGENTOW AUTOGEN
def basic_config_agent(agent_name:str, api_type:str, location:str=None, project_id:str=None, api_key:str=None):
    try:
        configuration = {"model": agent_name, "api_type": api_type}
        if api_key: configuration["api_key"] = api_key
        if project_id: configuration["project_id"] = project_id
        if location: configuration["location"] = location
        logging.info(f"Model configuration: {configuration}")
        return [configuration]

    except Exception as e:
        logging.error(f"Failed to initialize Vertex AI or configure LLM: {e}")
        print(f"Error: Failed to initialize Vertex AI or configure LLM. Please check your project ID, region, and permissions. Details: {e}")
        exit()



#TRIGGER AGENT
class TriggerAgent(ConversableAgent):
    """Agent decydujÄ…cy, czy dane nadajÄ… siÄ™ do dalszego przetwarzania."""
    def __init__(self, llm_config):
        super().__init__(
            name="TriggerAgent",
            llm_config=llm_config,
            system_message="""JesteÅ› 'StraÅ¼nikiem Danych'. Twoim jedynym zadaniem jest analiza podsumowania danych (nazwy kolumn, pierwsze wiersze).
Na tej podstawie musisz podjÄ…Ä‡ decyzjÄ™: czy te dane majÄ… charakter **tabularyczny** (jak plik CSV lub tabela bazy danych)?
- JeÅ›li TAK: odpowiedz **tylko i wyÅ‚Ä…cznie**: 'Dane sÄ… tabularyczne. PrzekazujÄ™ do PlannerAgent w celu stworzenia planu analizy.'. Nie dodawaj nic wiÄ™cej.
- JeÅ›li NIE (np. sÄ… to logi serwera, obrazy, czysty tekst): Twoja wiadomoÅ›Ä‡ MUSI koÅ„czyÄ‡ siÄ™ sÅ‚owem 'TERMINATE'. WyjaÅ›nij krÃ³tko, dlaczego dane nie sÄ… tabularyczne, np. 'Dane nie sÄ… tabularyczne, to zbiÃ³r artykuÅ‚Ã³w tekstowych. TERMINATE'."""
        )

#PLANNER AGENT        
class PlannerAgent(ConversableAgent):
    """Agent tworzÄ…cy szczegÃ³Å‚owy plan przygotowania danych."""
    def __init__(self, llm_config):
        super().__init__(
            name="PlannerAgent",
            llm_config=llm_config,
            system_message="""JesteÅ› 'Architektem Planu'. OtrzymaÅ‚eÅ› potwierdzenie, Å¼e dane sÄ… tabularyczne.
Twoim zadaniem jest stworzenie szczegÃ³Å‚owego, numerowanego planu czyszczenia i przygotowania danych do ogÃ³lnej analizy i modelowania. Plan musi byÄ‡ praktyczny i zgodny z najlepszymi praktykami.
Twoje zadanie skÅ‚ada siÄ™ z dwÃ³ch czÄ™Å›ci:
1.  **Analiza Inspiracji:** JeÅ›li w wiadomoÅ›ci od uÅ¼ytkownika znajduje siÄ™ sekcja '--- INSPIRACJE Z POPRZEDNICH URUCHOMIEÅƒ ---', 
potraktuj jÄ… jako cennÄ… inspiracjÄ™ i punkt wyjÅ›cia. Zawiera ona sprawdzonÄ… strategiÄ™ ("zÅ‚otÄ… myÅ›l") i moÅ¼e rÃ³wnieÅ¼ zawieraÄ‡ konkretne kroki. Twoim zadaniem jest **krytyczna adaptacja** tego planu. 
**SprawdÅº, czy kaÅ¼dy krok z inspiracji ma sens w kontekÅ›cie AKTUALNEGO podglÄ…du danych.** MoÅ¼esz usunÄ…Ä‡, dodaÄ‡ lub zmodyfikowaÄ‡ kroki, aby idealnie pasowaÅ‚y do obecnego problemu.
2.  **Tworzenie Planu:** JeÅ›li nie ma inspiracji, stwÃ³rz nowy, solidny plan od podstaw.
Plan powinien zawieraÄ‡ kroki takie jak:
1.  Weryfikacja i obsÅ‚uga brakujÄ…cych wartoÅ›ci (np. strategia imputacji dla kaÅ¼dej istotnej kolumny).
2.  Weryfikacja i korekta typÃ³w danych (np. konwersja stringÃ³w na daty lub liczby).
3.  InÅ¼ynieria cech (np. tworzenie nowych, uÅ¼ytecznych kolumn jak 'dzien_tygodnia' z daty lub kategoryzacja wartoÅ›ci liczbowych).
4.  Wykrywanie i obsÅ‚uga wartoÅ›ci odstajÄ…cych (outlierÃ³w).
5.  Normalizacja lub skalowanie danych (jeÅ›li to konieczne, wyjaÅ›nij krÃ³tko dlaczego).

Po przedstawieniu pierwszej wersji planu, oczekuj na recenzjÄ™ od CriticAgenta.
- JeÅ›li CriticAgent przeÅ›le uwagi, stwÃ³rz **NOWÄ„, KOMPLETNÄ„ WERSJÄ˜** planu, ktÃ³ra uwzglÄ™dnia **WSZYSTKIE** jego sugestie.
- W poprawionym planie zaznacz, co zostaÅ‚o zmienione. PrzeÅ›lij zaktualizowany plan z powrotem do CriticAgenta.
Kontynuuj ten proces, aÅ¼ CriticAgent ostatecznie zaakceptuje TwÃ³j plan."""
        )

#CRITIC AGENT
class CriticAgent(ConversableAgent):
    """Agent oceniajÄ…cy plan i dbajÄ…cy o jego jakoÅ›Ä‡."""
    def __init__(self, llm_config):
        super().__init__(
            name="CriticAgent",
            llm_config=llm_config,
            system_message="""JesteÅ› 'Recenzentem JakoÅ›ci'. Twoim zadaniem jest konstruktywna krytyka planu od PlannerAgenta. OceÅ„ go pod kÄ…tem praktycznoÅ›ci, realizmu i efektywnoÅ›ci.
Twoje ZÅ‚ote Zasady:
1.  **PROSTOTA JEST KLUCZEM:** Agresywnie kwestionuj nadmiernie skomplikowane kroki. Czy naprawdÄ™ potrzebujemy KNNImputer, gdy prosta mediana wystarczy?
2.  **JEDNA ZMIANA NA RAZ:** JeÅ›li plan proponuje stworzenie kilku zÅ‚oÅ¼onych cech w jednym kroku, odrzuÄ‡ to. Zarekomenduj podzielenie tego na osobne, Å‚atwiejsze do weryfikacji kroki. Plan musi byÄ‡ odporny na bÅ‚Ä™dy.
3.  **KONKRETNE SUGESTIE:** Zawsze podawaj konkretnÄ… alternatywÄ™. Zamiast 'To jest zÅ‚e', napisz 'Krok X jest nieoptymalny. SugerujÄ™ Y, poniewaÅ¼ Z.'

**PROCES ZATWIERDZANIA (KRYTYCZNIE WAÅ»NE):**
- JeÅ›li plan wymaga jakichkolwiek poprawek, jasno je opisz i odeÅ›lij do PlannerAgenta. **NIE UÅ»YWAJ** poniÅ¼szych fraz kluczowych.
- JeÅ›li plan jest **doskonaÅ‚y** i nie wymaga Å¼adnych zmian, Twoja odpowiedÅº **MUSI** mieÄ‡ nastÄ™pujÄ…cÄ…, Å›cisÅ‚Ä… strukturÄ™:
Najpierw napisz liniÄ™:
`OSTATECZNY PLAN:`
PoniÅ¼ej wklej **CAÅY, KOMPLETNY** plan od PlannerAgenta.
Na samym koÅ„cu wiadomoÅ›ci dodaj frazÄ™:
`PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI`"""
        )


# In[10]:


# --- Konfiguracja czatu grupowego ---
main_agent_configuration={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(agent_name=MAIN_AGENT, api_type=API_TYPE_GEMINI, location=LOCATION, project_id=PROJECT_ID)}
critic_agent_configuration ={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(api_key=ANTHROPIC_API_KEY,agent_name=CRITIC_MODEL, api_type=API_TYPE_SONNET)}


#---WYWOÅANIE AGENTÃ“W
trigger_agent = TriggerAgent(llm_config=main_agent_configuration)
planner_agent = PlannerAgent(llm_config=main_agent_configuration)
critic_agent = CriticAgent(llm_config=main_agent_configuration)


# In[11]:


#FUNKCJA CHATU GRUPOWEGO-WYMYÅšLANIE PLANU
def run_autogen_planning_phase(input_path: str,inspiration_prompt: str = "") -> Optional[str]:
    """
    Uruchamia fazÄ™ planowania z agentami AutoGen i zwraca finalny plan.
    """
    print("\n" + "="*80)
    print("### ### FAZA 1: URUCHAMIANIE PLANOWANIA STRATEGICZNEGO (AutoGen) ### ###")
    print("="*80 + "\n")

    try:
        df_summary = pd.read_csv(input_path, nrows=5)
        data_preview = f"Oto podglÄ…d danych:\n\nKolumny:\n{df_summary.columns.tolist()}\n\nPierwsze 5 wierszy:\n{df_summary.to_string()}"
        
        if inspiration_prompt:
            print("INFO: DoÅ‚Ä…czam inspiracje z pamiÄ™ci do fazy planowania.")
            data_preview += "\n\n" + inspiration_prompt
        
    except Exception as e:
        logging.error(f"Nie moÅ¼na wczytaÄ‡ pliku wejÅ›ciowego {input_path}: {e}")
        return None
    
    
    
    user_proxy = autogen.UserProxyAgent(
       name="UserProxy",
       human_input_mode="NEVER",
       max_consecutive_auto_reply=10,
       is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
       code_execution_config=False,
       system_message="ZarzÄ…dzasz procesem. PrzekaÅ¼ podglÄ…d danych do TriggerAgenta, a nastÄ™pnie moderuj dyskusjÄ™ miÄ™dzy Plannerem a Krytykiem. JeÅ›li w wiadomoÅ›ci sÄ… inspiracje z przeszÅ‚oÅ›ci, przekaÅ¼ je Plannerowi."
    )

    def custom_speaker_selection_func(last_speaker: Agent, groupchat: autogen.GroupChat):
        messages = groupchat.messages

        # Warunek poczÄ…tkowy, pierwszy mÃ³wi TriggerAgent
        if len(messages) <= 1:
            return trigger_agent

        # Standardowy przepÅ‚yw: Trigger -> Planner -> Critic -> Planner ...
        elif last_speaker is trigger_agent:
            return planner_agent
        elif last_speaker is planner_agent:
            return critic_agent
        elif last_speaker is critic_agent:

            if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in messages[-1]['content']:
                return None # To elegancko koÅ„czy rozmowÄ™
            else:
                # JeÅ›li nie, wracamy do Plannera z uwagami
                return planner_agent
        else:
            # Sytuacja awaryjna lub koniec, nie wybieraj nikogo
            return None

    groupchat = autogen.GroupChat(
        agents=[user_proxy, trigger_agent, planner_agent, critic_agent],
        messages=[],
        max_round=15,
        speaker_selection_method=custom_speaker_selection_func
    )
    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=main_agent_configuration)

    user_proxy.initiate_chat(manager, message=data_preview)

    # Ekstrakcja finalnego planu
    final_plan = None
    critic_messages = [msg['content'] for msg in groupchat.messages if msg['name'] == 'CriticAgent']
    for msg in reversed(critic_messages):
        if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in msg:
            match = re.search(r"OSTATECZNY PLAN:(.*)PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI", msg, re.DOTALL)
            if match:
                final_plan = match.group(1).strip()
                print("Faza planowania zakoÅ„czona. Ostateczny plan zostaÅ‚ zaakceptowany.")
                break
    
    if not final_plan:
        print(" Faza planowania zakoÅ„czona bez akceptacji planu lub z powodu TERMINATE.")

    
    full_conversation_log = "\n\n".join([f"--- Komunikat od: {msg['name']} ---\n{msg['content']}" for msg in groupchat.messages])

    
    return final_plan, full_conversation_log


# ################################################################################
# ### ### FAZA 2: WYKONANIE PLANU (LangGraph)
# ################################################################################

# In[12]:


#Zasady tworzenia architektury dla wykonawcÃ³w kodu
class ArchitecturalRule(TypedDict):
    id: str; description: str; check: Callable[[str], bool]; error_message: str

ARCHITECTURAL_RULES: List[ArchitecturalRule] = [
    {"id": "NO_MAIN_BLOCK", "description": "Å»adnego bloku `if __name__ == '__main__':`.", "check": lambda code: bool(re.search(r'if\s+__name__\s*==\s*["\']__main__["\']\s*:', code)), "error_message": "Wykryto niedozwolony blok `if __name__ == '__main__':`."},
    {"id": "NO_ARGPARSE", "description": "Å»adnego `argparse` ani `sys.argv`.", "check": lambda code: bool(re.search(r'import\s+argparse', code)), "error_message": "Wykryto niedozwolony import moduÅ‚u `argparse`."},
    {"id": "SINGLE_FUNCTION_LOGIC", "description": "CaÅ‚a logika musi byÄ‡ w funkcji `process_data(input_path: str, output_path: str)`.", "check": lambda code: "def process_data(input_path: str, output_path: str)" not in code, "error_message": "Brak wymaganej definicji funkcji `process_data(input_path: str, output_path: str)`."},
    {"id": "ENDS_WITH_CALL", "description": "Skrypt musi koÅ„czyÄ‡ siÄ™ **dokÅ‚adnie jednÄ… liniÄ…** w formacie: `process_data(input_path, output_path)  # noqa: F821`. Komentarz `# noqa: F821` jest **obowiÄ…zkowy**.", "check": lambda code: not re.search(r'^\s*process_data\(input_path,\s*output_path\)\s*#\s*noqa:\s*F821\s*$', [line for line in code.strip().split('\n') if line.strip()][-1]), "error_message": "Skrypt nie koÅ„czy siÄ™ wymaganym wywoÅ‚aniem `process_data(input_path, output_path)  # noqa: F821`."},
]

class ArchitecturalRulesManager:
    @staticmethod
    def get_rules_as_string() -> str:
        rules_text = "\n".join(f"        - {rule['description']}" for rule in ARCHITECTURAL_RULES)
        return f"<ARCHITECTURAL_RULES>\n    **Krytyczne Wymagania DotyczÄ…ce Struktury Kodu:**\n{rules_text}\n</ARCHITECTURAL_RULES>"


# In[13]:


# --- PROMPTY DLA AGENTÃ“W LANGCHAIN ---


# In[15]:


class PromptTemplates:
    @staticmethod
    def code_generator(plan: str, available_columns: List[str]) -> str:
        return f"""**Persona:** Ekspert InÅ¼ynierii Danych.\n**Plan Biznesowy:**\n{plan}\n
        **DostÄ™pne Kolumny:**\n{available_columns}\n{ArchitecturalRulesManager.get_rules_as_string()}\n
        **Zadanie:** Napisz kompletny skrypt Pythona realizujÄ…cy plan, przestrzegajÄ…c wszystkich zasad. OdpowiedÅº musi zawieraÄ‡ tylko i wyÅ‚Ä…cznie blok kodu ```python ... ```."""
    
    @staticmethod
    def tool_based_debugger() -> str:
        return """JesteÅ› 'GÅ‚Ã³wnym InÅ¼ynierem JakoÅ›ci Kodu'. Twoim zadaniem jest nie tylko naprawienie zgÅ‚oszonego bÅ‚Ä™du, ale zapewnienie, Å¼e kod bÄ™dzie dziaÅ‚aÅ‚ poprawnie.
- JeÅ›li bÅ‚Ä…d to `ModuleNotFoundError`, uÅ¼yj `request_package_installation`.
- JeÅ›li bÅ‚Ä…d to `ImportError` wskazujÄ…cy na konflikt wersji, rÃ³wnieÅ¼ uÅ¼yj `request_package_installation`, aby zasugerowaÄ‡ aktualizacjÄ™ pakietu, ktÃ³ry jest ÅºrÃ³dÅ‚em bÅ‚Ä™du.
- Dla wszystkich innych bÅ‚Ä™dÃ³w w kodzie (np. `SyntaxError`, `KeyError`), uÅ¼yj `propose_code_fix` a nastÄ™pnie przeanalizuj poniÅ¼szy bÅ‚Ä…d i wadliwy kod. Twoja praca skÅ‚ada siÄ™ z dwÃ³ch krokÃ³w:
1.  **Analiza i Naprawa:** Zidentyfikuj przyczynÄ™ bÅ‚Ä™du i stwÃ³rz kompletnÄ…, poprawionÄ… wersjÄ™ caÅ‚ego skryptu.
2.  **WywoÅ‚anie NarzÄ™dzia:** WywoÅ‚aj narzÄ™dzie `propose_code_fix`, podajÄ…c **OBOWIÄ„ZKOWO** dwa argumenty: `analysis` (twoja analiza) oraz `corrected_code` (peÅ‚ny, naprawiony kod).
Przeanalizuj poniÅ¼szy bÅ‚Ä…d i wadliwy kod. """

    @staticmethod
    def create_reporting_prompt(plan: str, original_summary: str, processed_summary: str) -> str:
        return  f"""
**Persona:** JesteÅ› autonomicznym, starszym Analitykiem Danych. Twoim zadaniem nie jest tworzenie fragmentÃ³w kodu, ale dostarczenie kompletnego, gotowego do wdroÅ¼enia skryptu w Pythonie, ktÃ³ry generuje profesjonalny raport w formacie HTML. Twoja praca musi byÄ‡ w peÅ‚ni samowystarczalna.

---
## 1. DostÄ™pne Zasoby w Åšrodowisku Wykonawczym

TwÃ³j skrypt bÄ™dzie wykonany w Å›rodowisku, w ktÃ³rym nastÄ™pujÄ…ce zmienne sÄ… juÅ¼ zdefiniowane i gotowe do uÅ¼ycia:

- `df_original`: Ramka danych Pandas z danymi *przed* przetwarzaniem.
- `df_processed`: Ramka danych Pandas z danymi *po* przetworzeniu.
- `report_output_path`: String zawierajÄ…cy Å›cieÅ¼kÄ™, pod ktÃ³rÄ… naleÅ¼y zapisaÄ‡ finalny plik HTML (np. 'reports/final_report.html').

---
## 2. Kontekst Biznesowy i Dane

Dane zostaÅ‚y przetworzone zgodnie z nastÄ™pujÄ…cym planem: {plan}.

Oto podsumowania statystyczne danych, ktÃ³re masz przeanalizowaÄ‡:
{original_summary}
{processed_summary}

---
## 3. Twoje GÅ‚Ã³wne Zadanie: Stworzenie Kompletnego Skryptu RaportujÄ…cego

Napisz **jeden, kompletny i wykonywalny skrypt w Pythonie**, ktÃ³ry realizuje nastÄ™pujÄ…ce kroki:

1.  **Analiza i Podsumowanie (w HTML):** StwÃ³rz zwiÄ™zÅ‚e, ale wnikliwe podsumowanie kluczowych zmian miÄ™dzy `df_original` a `df_processed`. Zapisz je w zmiennej `summary_html`.
2.  **Generowanie Wizualizacji:** StwÃ³rz co najmniej dwie wartoÅ›ciowe wizualizacje porÃ³wnawcze (np. histogramy, boxploty) za pomocÄ… Matplotlib, aby zilustrowaÄ‡ najwaÅ¼niejsze zmiany (np. wpÅ‚yw usuniÄ™cia wartoÅ›ci odstajÄ…cych na rozkÅ‚ad).
3.  **Konwersja WykresÃ³w:** KaÅ¼dy wygenerowany wykres musi zostaÄ‡ przekonwertowany do formatu base64 i osadzony w tagu `<img>`.
4.  **ZÅ‚oÅ¼enie Raportu HTML:** Skonstruuj kompletny dokument HTML, zawierajÄ…cy zarÃ³wno analizÄ™ tekstowÄ…, jak i osadzone wizualizacje.
5.  **Zapis do Pliku:** Zapisz finalny string HTML do pliku, korzystajÄ…c ze zmiennej `report_output_path`.

---
## 4. Wymagana Struktura Skryptu (Szablon)

TwÃ³j kod musi idealnie pasowaÄ‡ do poniÅ¼szej struktury. Nie modyfikuj jej, jedynie uzupeÅ‚nij oznaczone sekcje.

```python
# ===================================================================
# === AUTONOMICZNY SKRYPT GENERUJÄ„CY RAPORT ANALITYCZNY ===
# ===================================================================
# Importy i funkcje pomocnicze sÄ… juÅ¼ zapewnione w Å›rodowisku,
# ale dla przejrzystoÅ›ci zostanÄ… tu zdefiniowane.
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import io
import base64

# --- Funkcja pomocnicza do osadzania wykresÃ³w ---
def fig_to_base64(fig):
    img_buf = io.BytesIO()
    fig.savefig(img_buf, format='png', bbox_inches='tight')
    img_buf.seek(0)
    base64_str = base64.b64encode(img_buf.getvalue()).decode('utf-8')
    plt.close(fig)
    return base64_str

# --- Zmienne wejÅ›ciowe (dostÄ™pne globalnie w skrypcie) ---
# df_original: pd.DataFrame
# df_processed: pd.DataFrame
# report_output_path: str

# Inicjalizacja listy na wykresy
figures_html_list = []

# ===================================================================
# ### KROK 1: Analiza tekstowa i podsumowanie w HTML ###
# ===================================================================

# <<< UZUPEÅNIJ TÄ˜ SEKCJÄ˜ >>>
# PorÃ³wnaj kluczowe statystyki, zmiany w rozkÅ‚adach, liczbÄ™ kolumn itp.
# Wynik zapisz w zmiennej summary_html.
summary_html = f\"\"\"
<h2>Podsumowanie Zmian w Danych</h2>
<p>Analiza porÃ³wnawcza wykazaÅ‚a nastÄ™pujÄ…ce kluczowe rÃ³Å¼nice:</p>
<ul>
    <li><strong>Struktura danych:</strong> Liczba kolumn zmieniÅ‚a siÄ™ z {len(df_original.columns)} na {len(df_processed.columns)}.</li>
    <li><strong>WartoÅ›ci odstajÄ…ce:</strong> Maksymalna wartoÅ›Ä‡ w kolumnie 'Transaction_Amount' zostaÅ‚a zredukowana z {df_original['Transaction_Amount'].max():.2f} do {df_processed['Transaction_Amount'].max():.2f}, co Å›wiadczy o skutecznej obsÅ‚udze outlierÃ³w.</li>
    # Dodaj wiÄ™cej wnikliwych obserwacji...
</ul>
\"\"\"


# ===================================================================
# ### KROK 2: Generowanie wizualizacji porÃ³wnawczych ###
# ===================================================================

# <<< UZUPEÅNIJ TÄ˜ SEKCJÄ˜ >>>
# StwÃ³rz co najmniej dwa wykresy. PamiÄ™taj o tytuÅ‚ach i etykietach.

# --- Wykres 1: PorÃ³wnanie rozkÅ‚adu kwoty transakcji ---
fig1, ax = plt.subplots(figsize=(12, 6))
ax.hist(df_original['Transaction_Amount'], bins=50, alpha=0.6, label='Oryginalne', color='blue')
ax.hist(df_processed['Transaction_Amount'], bins=50, alpha=0.8, label='Przetworzone', color='green')
ax.set_title('PorÃ³wnanie RozkÅ‚adu Kwoty Transakcji', fontweight='bold')
ax.set_xlabel('Kwota Transakcji')
ax.set_ylabel('CzÄ™stoÅ›Ä‡')
ax.legend()
ax.grid(True, linestyle='--', alpha=0.6)
fig1.tight_layout()
figures_html_list.append(f"<h3>Wykres 1: Dystrybucja Kwot Transakcji</h3>{fig_to_base64(fig1)}")

# --- Wykres 2: (Dodaj kolejny, np. boxplot dla innej zmiennej) ---
# ...


# ===================================================================
# ### KROK 3: ZÅ‚oÅ¼enie i zapis finalnego raportu HTML ###
# ===================================================================

# PoÅ‚Ä…cz wszystkie czÄ™Å›ci w jeden dokument HTML
all_figures_html = "".join(figures_html_list)

full_html_report = f\"\"\"
<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <title>Raport z Analizy Przetwarzania Danych</title>
    <style>
        body {{ font-family: sans-serif; margin: 2em; background-color: #f9f9f9; }}
        .container {{ max-width: 1000px; margin: auto; background: #fff; padding: 2em; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
        h2, h3 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 5px;}}
        img {{ max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px; border-radius: 4px; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>Raport PorÃ³wnawczy Danych</h1>
        {summary_html}
        {all_figures_html}
    </div>
</body>
</html>
\"\"\"

# Zapis do pliku z obsÅ‚ugÄ… bÅ‚Ä™dÃ³w
try:
    with open(report_output_path, "w", encoding="utf-8") as f:
        f.write(full_html_report)
    print(f"Raport zostaÅ‚ pomyÅ›lnie wygenerowany i zapisany jako '{report_output_path}'.")
except IOError as e:
    print(f"WystÄ…piÅ‚ bÅ‚Ä…d podczas zapisywania pliku raportu: {e}")
"""
    def create_meta_auditor_prompt(source_code: str, autogen_conversation: str, langgraph_log: str, final_code: str, final_report: str) -> str:
        return f"""**Persona:** GÅ‚Ã³wny Audytor SystemÃ³w AI. Twoim zadaniem jest krytyczna ocena caÅ‚ego procesu AI.
**DostÄ™pne Dane do Analizy:**
1. KOD Å¹RÃ“DÅOWY SYSTEMU:\n```python\n{source_code}\n```
2. ZAPIS ROZMOWY (PLANOWANIE):\n```\n{autogen_conversation}\n```
3. LOGI (WYKONANIE):\n```\n{langgraph_log}\n```
4. FINALNY KOD:\n```python\n{final_code}\n```
5. FINALNY RAPORT (fragment):\n```html\n{final_report[:2000]}\n```
**Zadania Audytorskie (odpowiedz na kaÅ¼de pytanie):**
1. **Ocena Planowania:** Czy dyskusja Planner-Krytyk byÅ‚a efektywna? Czy Krytyk byÅ‚ rygorystyczny?
2. **Ocena Wykonania:** Czy byÅ‚y pÄ™tle naprawcze? Jak skuteczny byÅ‚ debugger?
3. **Ocena Produktu:** Czy raport HTML jest uÅ¼yteczny?
4. **Ocena PromptÃ³w AgentÃ³w (Analiza Meta):**
    - Na podstawie analizy logÃ³w i kodu ÅºrÃ³dÅ‚owego, oceÅ„ jakoÅ›Ä‡ i precyzjÄ™ promptÃ³w dla poszczegÃ³lnych agentÃ³w (Planner, Krytyk, Debugger, Generator Raportu).
    - Czy ktÃ³ryÅ› z zaobserwowanych problemÃ³w (nawet tych naprawionych) mÃ³gÅ‚ wynikaÄ‡ z niejasnoÅ›ci w prompcie?
    - Czy widzisz moÅ¼liwoÅ›Ä‡ ulepszenia ktÃ³regoÅ› z promptÃ³w, aby system dziaÅ‚aÅ‚ bardziej niezawodnie lub efektywnie w przyszÅ‚oÅ›ci?
5. **Rekomendacje do Samodoskonalenia:** Zaproponuj 1-3 konkretne zmiany w kodzie lub promptach, ktÃ³re usprawniÄ… system.
**Format WyjÅ›ciowy:** ZwiÄ™zÅ‚y raport tekstowy."""


# In[16]:


#Funkcje pomocnicze, narzÄ™dzia dla agentÃ³ langchain

def extract_python_code(response: str) -> str:
    response = response.strip()
    match = re.search(r'```python\n(.*?)\n```', response, re.DOTALL)
    if match: return match.group(1).strip()
    if response.startswith("'''") and response.endswith("'''"): return response[3:-3].strip()
    if response.startswith('"""') and response.endswith('"""'): return response[3:-3].strip()
    return response

#--funkcja dla pamieci--
def intelligent_truncate(text: str, max_len: int) -> str:
    """Skraca tekst, zachowujÄ…c jego poczÄ…tek i koniec."""
    if not isinstance(text, str) or len(text) <= max_len:
        return text
    half_len = (max_len - 25) // 2
    start = text[:half_len]
    end = text[-half_len:]
    return f"{start}\n\n[... treÅ›Ä‡ skrÃ³cona ...]\n\n{end}"


#Dla inteligentnego debbugera:
class DebugReport(BaseModel):
    analysis: str = Field(description="Techniczna analiza bÅ‚Ä™du.")
    corrected_code: str = Field(description="Kompletny, poprawiony kod.")

    
class GeneratedPythonScript(BaseModel):
    """
    Model przechowujÄ…cy kompletny i gotowy do wykonania skrypt w Pythonie.
    """
    script_code: str = Field(description="Kompletny kod w Pythonie, gotowy do bezpoÅ›redniego wykonania. Musi zawieraÄ‡ wszystkie niezbÄ™dne elementy, takie jak definicje, logikÄ™ i zapis pliku.")    
    

class CodeFixArgs(BaseModel):
    analysis: str = Field(description="Techniczna analiza przyczyny bÅ‚Ä™du i wprowadzonej poprawki w kodzie.")
    corrected_code: str = Field(description="PeÅ‚ny, kompletny i POPRAWIONY skrypt w Pythonie. Musi byÄ‡ gotowy do wykonania.")
    
class PackageInstallArgs(BaseModel):
    package_name: str = Field(description="Nazwa pakietu, ktÃ³ry naleÅ¼y zainstalowaÄ‡, aby rozwiÄ…zaÄ‡ bÅ‚Ä…d 'ModuleNotFoundError'. Np. 'scikit-learn', 'seaborn'.")
    analysis: str = Field(description="KrÃ³tka analiza potwierdzajÄ…ca, Å¼e przyczynÄ… bÅ‚Ä™du jest brakujÄ…cy pakiet.")

@tool(args_schema=CodeFixArgs)
def propose_code_fix(analysis: str, corrected_code: str) -> None:
    """UÅ¼yj tego narzÄ™dzia, aby zaproponowaÄ‡ poprawionÄ… wersjÄ™ kodu w odpowiedzi na bÅ‚Ä…d skÅ‚adniowy lub logiczny."""
    pass

@tool(args_schema=PackageInstallArgs)
def request_package_installation(package_name: str, analysis: str) -> None:
    """UÅ¼yj tego narzÄ™dzia, aby poprosiÄ‡ o instalacjÄ™ brakujÄ…cej biblioteki, gdy napotkasz bÅ‚Ä…d 'ModuleNotFoundError'."""
    pass 

    
def install_package(package_name: str, upgrade: bool = True) -> bool:
    """
    Instaluje lub aktualizuje podany pakiet uÅ¼ywajÄ…c pip.
    
    Args:
        package_name (str): Nazwa pakietu do instalacji.
        upgrade (bool): JeÅ›li True, uÅ¼ywa flagi --upgrade.
    """
    try:
        command = [sys.executable, "-m", "pip", "install", package_name]
        if upgrade:
            command.insert(2, "--upgrade")
        
        action = "Aktualizacja" if upgrade else "Instalacja"
        print(f"  [INSTALATOR] PrÃ³ba: {action} pakietu {package_name}...")
        
        result = subprocess.run(command, check=True, capture_output=True, text=True)
        print(f"  [INSTALATOR] PomyÅ›lnie zakoÅ„czono. Logi pip:\n{result.stdout}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"  [INSTALATOR] BÅ‚Ä…d podczas operacji na pakiecie {package_name}.\n{e.stderr}")
        return False
    
#DLA report agenta
def embed_plot_to_html(figure) -> str:
    """Konwertuje figurÄ™ matplotlib do stringa base64 do osadzenia w HTML."""
    buffer = io.BytesIO()
    figure.savefig(buffer, format='png', bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    graphic = base64.b64encode(image_png)
    graphic = graphic.decode('utf-8')
    plt.close(figure) # WaÅ¼ne: zamykamy figurÄ™
    return f'<img src="data:image/png;base64,{graphic}" alt="Wykres analizy danych"/>'

#Dla meta agenta
def read_source_code(file_path: str) -> str:
    """Odczytuje zawartoÅ›Ä‡ pliku kodu ÅºrÃ³dÅ‚owego."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f: return f.read()
    except Exception as e: return f"Nie udaÅ‚o siÄ™ odczytaÄ‡ kodu ÅºrÃ³dÅ‚owego: {e}"


#Zapis planowania preprocessingu- AutoGen
def save_autogen_conversation_log(log_content: str, file_path: str):
    """Zapisuje peÅ‚nÄ… treÅ›Ä‡ konwersacji agentÃ³w AutoGen do pliku tekstowego."""
    print(f"INFO: PrÃ³ba zapisu peÅ‚nego logu rozmowy do pliku: {file_path}")
    try:
        # Upewniamy siÄ™, Å¼e katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PEÅNY ZAPIS ROZMOWY AGENTÃ“W (FAZA PLANOWANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"âœ… SUKCES: Log rozmowy zostaÅ‚ pomyÅ›lnie zapisany.")
    except Exception as e:
        print(f"âŒ BÅÄ„D: Nie udaÅ‚o siÄ™ zapisaÄ‡ logu rozmowy. Przyczyna: {e}")

#Zapis rozmowy agentow wykonowczych- LangChain        
def save_langgraph_execution_log(log_content: str, file_path: str):
    """Zapisuje peÅ‚ny, szczegÃ³Å‚owy log z wykonania grafu LangGraph do pliku."""
    print(f"INFO: PrÃ³ba zapisu peÅ‚nego logu wykonania LangGraph do pliku: {file_path}")
    try:
        # Upewniamy siÄ™, Å¼e katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PEÅNY ZAPIS WYKONANIA GRAFU LANGGRAPH (FAZA WYKONANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"âœ… SUKCES: Log wykonania LangGraph zostaÅ‚ pomyÅ›lnie zapisany.")
    except Exception as e:
        print(f"âŒ BÅÄ„D: Nie udaÅ‚o siÄ™ zapisaÄ‡ logu LangGraph. Przyczyna: {e}")       

#--narzedzie do przetwarzania info dla pamieci dlugotrwalej, llm agent uzywa llm!!
def distill_memory_content(failing_code: str, error_traceback: str, debugger_analysis: str, corrected_code: str) -> dict:
    """UÅ¼ywa LLM do 'przedestylowania' surowych danych o bÅ‚Ä™dzie i jego naprawie do zwiÄ™zÅ‚ego, ustrukturyzowanego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia (wersja ekspercka)...")
    
    prompt_template = f"""
    Persona: JesteÅ› starszym inÅ¼ynierem oprogramowania, ktÃ³ry pisze zwiÄ™zÅ‚e post-mortemy do wewnÄ™trznej bazy wiedzy. Twoim celem jest stworzenie notatki, ktÃ³ra bÄ™dzie maksymalnie uÅ¼yteczna dla innych agentÃ³w w przyszÅ‚oÅ›ci.
    Przeanalizuj poniÅ¼szy kontekst i wyciÄ…gnij z niego kluczowe, gotowe do uÅ¼ycia wnioski.
    Kontekst:
    [WADLIWY KOD]: {failing_code}
    [PEÅNY BÅÄ„D]: {error_traceback}
    [ANALIZA PROBLEMU]: {debugger_analysis}
    [POPRAWIONY KOD]: {corrected_code}
    Zadanie: Na podstawie powyÅ¼szego kontekstu, wygeneruj obiekt, ktÃ³ry bÄ™dzie pasowaÅ‚ do zdefiniowanej struktury.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: PomyÅ›lnie przedestylowano wspomnienie (wersja ekspercka).")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEÅ»ENIE: Destylacja (ekspercka) nie powiodÅ‚a siÄ™: {e}. ZapisujÄ™ surowe dane.")
        return {
            "problem_summary": debugger_analysis,
            "key_takeaway": "N/A - distillation failed",
            "raw_error": intelligent_truncate(error_traceback, 500)
        }
#pamiec dlugotrwala-zapis w meta agent, sukces 
def distill_success_memory(final_plan: str) -> dict:
    """UÅ¼ywa LLM do podsumowania udanego planu w zwiÄ™zÅ‚Ä… notatkÄ™."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o sukcesie...")
    prompt_template = f"""
    Persona: JesteÅ› starszym inÅ¼ynierem AI, ktÃ³ry dokumentuje udane strategie.
    Kontekst: Przeanalizuj poniÅ¼szy plan, ktÃ³ry zakoÅ„czyÅ‚ siÄ™ sukcesem i stwÃ³rz zwiÄ™zÅ‚e podsumowanie w formacie JSON.
    [FINALNY PLAN]: {final_plan}
    """
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        # UÅ¼ywamy nowego, lÅ¼ejszego modelu DistilledSuccessMemory
        structured_llm = llm.with_structured_output(DistilledSuccessMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: PomyÅ›lnie przedestylowano wspomnienie o sukcesie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEÅ»ENIE: Destylacja sukcesu nie powiodÅ‚a siÄ™: {e}.")
        return {"plan_summary": "N/A - distillation failed"}
    
    
def distill_memory_content(debugger_analysis: str, failing_code: str, corrected_code: str) -> dict:
    """UÅ¼ywa LLM do 'przedestylowania' analizy debuggera i zmian w kodzie do zwiÄ™zÅ‚ego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o naprawie...")
    
    # Zamiast peÅ‚nego bÅ‚Ä™du, uÅ¼ywamy zwiÄ™zÅ‚ej analizy od debuggera!
    prompt_template = f"""
    Persona: JesteÅ› starszym inÅ¼ynierem oprogramowania, ktÃ³ry pisze zwiÄ™zÅ‚e post-mortemy.
    Przeanalizuj poniÅ¼szy kontekst dotyczÄ…cy naprawy bÅ‚Ä™du i wyciÄ…gnij z niego kluczowe, gotowe do uÅ¼ycia wnioski.
    Kontekst:
    [ANALIZA PROBLEMU WG DEBUGGERA]: {debugger_analysis}
    [WADLIWY FRAGMENT KODU]: {intelligent_truncate(failing_code, 500)}
    [POPRAWIONY KOD]: {intelligent_truncate(corrected_code, 500)}
    Zadanie: Na podstawie powyÅ¼szego kontekstu, wygeneruj obiekt JSON zgodny ze strukturÄ… DistilledMemory.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: PomyÅ›lnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEÅ»ENIE: Destylacja (naprawa) nie powiodÅ‚a siÄ™: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}
    
    
    
    

    
def distill_full_fix_session(initial_error: str, fix_attempts: List[Dict], successful_code: str) -> Dict[str, Any]:
    """UÅ¼ywa LLM, aby podsumowaÄ‡ caÅ‚Ä… sesjÄ™ naprawczÄ… w jedno zwiÄ™zÅ‚e wspomnienie."""
    print("  [INFO] Uruchamiam destylacjÄ™ caÅ‚ej sesji naprawczej...")

    # Tworzymy skonsolidowanÄ… historiÄ™ analiz debuggera
    consolidated_analysis = "\n".join(
        [f"PrÃ³ba {i+1}: {attempt.get('debugger_analysis', 'Brak analizy.')}" for i, attempt in enumerate(fix_attempts)]
    )

    prompt_template = f"""
Persona: JesteÅ› starszym inÅ¼ynierem, ktÃ³ry pisze ekstremalnie zwiÄ™zÅ‚e post-mortemy. Priorytetem jest gÄ™stoÅ›Ä‡ informacji przy minimalnej liczbie sÅ‚Ã³w.

Przeanalizuj caÅ‚Ä… sesjÄ™ naprawy bÅ‚Ä™du i wyciÄ…gnij z niej kluczowe wnioski.

[PIERWOTNY BÅÄ„D]:
{initial_error}

[HISTORIA ANALIZ Z NIEUDANYCH PRÃ“B NAPRAWY]:
{consolidated_analysis}

[KOD, KTÃ“RY OSTATECZNIE ZADZIAÅAÅ]:
{successful_code}

Zadanie: Wygeneruj obiekt JSON. KaÅ¼de pole tekstowe musi byÄ‡ pojedynczym, klarownym zdaniem. CaÅ‚oÅ›Ä‡ nie moÅ¼e przekroczyÄ‡ 150 sÅ‚Ã³w.
"""
    try:
        llm = ChatVertexAI(
            model_name=MAIN_AGENT, 
            project_id=PROJECT_ID, 
            location=LOCATION,
            max_output_tokens=512
        )
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("  [INFO] PomyÅ›lnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"  [OSTRZEÅ»ENIE] Destylacja sesji nie powiodÅ‚a siÄ™: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}



    
def generate_meta_insight(audit_report: str) -> Optional[dict]:
    """UÅ¼ywa LLM do wyciÄ…gniÄ™cia z raportu audytora jednego, kluczowego wniosku."""
    print("INFO: Uruchamiam proces generowania wniosku META...")
    prompt = f"""
    Przeanalizuj poniÅ¼szy raport audytora. Twoim zadaniem jest znalezienie JEDNEJ, najwaÅ¼niejszej i najbardziej konkretnej rekomendacji dotyczÄ…cej ulepszenia systemu.
    JeÅ›li znajdziesz takÄ… rekomendacjÄ™, przeksztaÅ‚Ä‡ jÄ… w obiekt JSON zgodny ze strukturÄ… MetaInsightMemory. JeÅ›li raport jest ogÃ³lnikowy i nie zawiera konkretnych propozycji, zwrÃ³Ä‡ null.
    [RAPORT AUDYTORA]:\n{audit_report}
    """
    try:
        llm = ChatVertexAI(model_name=CRITIC_MODEL, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(MetaInsightMemory)
        insight_object = structured_llm.invoke(prompt)
        print("INFO: PomyÅ›lnie wygenerowano wniosek META.")
        return insight_object.dict()
    except Exception:
        print("OSTRZEÅ»ENIE: Nie udaÅ‚o siÄ™ wygenerowaÄ‡ wniosku META z raportu audytora.")
        return None


# In[17]:


#Zmienne przekazywane do grafu LangChian
class AgentWorkflowState(TypedDict):
    plan: str; input_path: str; output_path: str; report_output_path: str
    available_columns: List[str]; generated_code: str; generated_report_code: str
    correction_attempts: int; error_message: Optional[str]; failing_node: Optional[str]
    error_context_code: Optional[str]; debugger_analysis: Optional[str]
    package_to_install: Optional[str]; user_approval_status: Optional[str]
    tool_choice: Optional[str]; tool_args: Optional[Dict]
    source_code: str
    autogen_log: str
    langgraph_log: str
    # --- Pola pamiÄ™ci ---
    run_id: str
    dataset_signature: str
    error_record_id: Optional[str]
    memory_client: MemoryBankClient
    pending_fix_session: Optional[Dict[str, Any]] 
    


# In[18]:


# --- Definicje wÄ™zÅ‚Ã³w LangGraph ---

def schema_reader_node(state: AgentWorkflowState):
    print("--- WÄ˜ZEÅ: ANALIZATOR SCHEMATU DANYCH ---")
    print(f"DEBUG: PrÃ³bujÄ™ odczytaÄ‡ plik ze Å›cieÅ¼ki: {state.get('input_path')}")
    try:
        df_header = pd.read_csv(state['input_path'], nrows=0)
        
        #pamiÄ™Ä‡ dÅ‚ugotrwaÅ‚a, tworzenie sygnatury
        memory_client = state['memory_client']
        dataset_signature = memory_client.create_dataset_signature(df_header)
        print(f"INFO: Wygenerowano sygnaturÄ™ danych: {dataset_signature}")
        #--koniec--
        
        return {"available_columns": df_header.columns.tolist(),"dataset_signature": dataset_signature}
    except Exception as e:
        return {"error_message": f"BÅ‚Ä…d odczytu pliku: {e}", "failing_node": "schema_reader"}

def code_generator_node(state: AgentWorkflowState):
    print("---  WÄ˜ZEÅ: GENERATOR KODU ---")
    
    llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    prompt = PromptTemplates.code_generator(state['plan'], state['available_columns'])
    response = llm.invoke(prompt).content
    code = extract_python_code(response)
    
    print("\nAgent-Analityk wygenerowaÅ‚ nastÄ™pujÄ…cy kod:")
    print("--------------------------------------------------")
    print(code)
    print("--------------------------------------------------")
    return {"generated_code": code}


def architectural_validator_node(state: AgentWorkflowState):
    print("--- ğŸ›¡ï¸ WÄ˜ZEÅ: STRAÅ»NIK ARCHITEKTURY ğŸ›¡ï¸ ---")
    code_to_check = state.get('generated_code', '')
    if not code_to_check:
        error_message = "Brak kodu do walidacji."
        print(f"  [WERDYKT] âŒ {error_message}")
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": "", "correction_attempts": state.get('correction_attempts', 0) + 1}

    errors = [rule["error_message"] for rule in ARCHITECTURAL_RULES if rule["check"](code_to_check)]
    
    if errors:
        error_message = "BÅ‚Ä…d Walidacji Architektonicznej: " + " ".join(errors)
        # <<< WAÅ»NY PRINT >>>
        print(f"  [WERDYKT] âŒ Kod Å‚amie zasady architektury: {' '.join(errors)}")
        
        pending_session = {
            "initial_error": error_message,  # UÅ¼ywamy bÅ‚Ä™du walidacji jako bÅ‚Ä™du poczÄ…tkowego
            "initial_code": code_to_check,
            "fix_attempts": []
        }
        
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": code_to_check, "correction_attempts": state.get('correction_attempts', 0) + 1}
    else:
        # <<< WAÅ»NY PRINT >>>
        print("  [WERDYKT] Kod jest zgodny z architekturÄ… systemu.")
        return {"error_message": None, "pending_fix_session": None}

    
def data_code_executor_node(state: AgentWorkflowState):
    """
    Wykonuje finalny kod do przetwarzania danych.
    """
    print("--- WÄ˜ZEÅ: WYKONANIE KODU DANYCH  ---")
    try:
        print("  [INFO] Uruchamiam ostatecznie zatwierdzony kod...")
        
        # Definiujemy Å›rodowisko wykonawcze tylko z niezbÄ™dnymi bibliotekami
        exec_scope = {
            'pd': pd,
            'input_path': state['input_path'],
            'output_path': state['output_path']
        }
        
        exec(state['generated_code'], exec_scope)
        
        print("  [WYNIK] Kod wykonany pomyÅ›lnie.")
        return {"error_message": None, "correction_attempts": 0}
        
    except Exception as e:
        error_traceback = traceback.format_exc()
        print(f"  [BÅÄ„D] WystÄ…piÅ‚ bÅ‚Ä…d. Przekazywanie do inteligentnego debuggera:\n{error_traceback}")
        
        #--pamiÄ™Ä‡ dÅ‚ugotrwaÅ‚a: zapis bÅ‚Ä™du, sesja tymczasowa
        
        pending_session = {
            "initial_error": error_traceback,
            "initial_code": state['generated_code'],
            "fix_attempts": []  # Pusta lista na przyszÅ‚e prÃ³by naprawy
        }
        #--koniec--
        
        return {
            "failing_node": "data_code_executor", 
            "error_message": error_traceback, 
            "error_context_code": state['generated_code'], 
            "correction_attempts": state.get('correction_attempts', 0) + 1,
            "pending_fix_session": pending_session
        }

    
def universal_debugger_node(state: AgentWorkflowState):
    print(f"--- WÄ˜ZEÅ: INTELIGENTNY DEBUGGER (BÅ‚Ä…d w: {state.get('failing_node')}) ---")
    
    # llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    llm = ChatVertexAI(model_name=MAIN_AGENT,temperature=0.0, project=PROJECT_ID, location=LOCATION)
    tools = [propose_code_fix, request_package_installation]
    llm_with_tools = llm.bind_tools(tools)
    prompt = PromptTemplates.tool_based_debugger()
    error_context = f"Wadliwy Kod:\n```python\n{state['error_context_code']}\n```\n\nBÅ‚Ä…d:\n```\n{state['error_message']}\n```"
    response = llm_with_tools.invoke(prompt + error_context)
    if not response.tool_calls:
        print("  [BÅÄ„D DEBUGGERA] Agent nie wybraÅ‚ Å¼adnego narzÄ™dzia. Eskalacja.")
        return {"error_message": "Debugger nie byÅ‚ w stanie podjÄ…Ä‡ decyzji.", "failing_node": "universal_debugger"}
    chosen_tool = response.tool_calls[0]
    tool_name = chosen_tool['name']
    tool_args = chosen_tool['args']
    print(f"  [DIAGNOZA] Debugger wybraÅ‚ narzÄ™dzie: '{tool_name}' z argumentami: {tool_args}")
    return {"tool_choice": tool_name, "tool_args": tool_args, "debugger_analysis": tool_args.get("analysis", "")}


def apply_code_fix_node(state: AgentWorkflowState):
    """Aplikuje poprawkÄ™ kodu zaproponowanÄ… przez debuggera."""
    print("--- WÄ˜ZEÅ: APLIKOWANIE POPRAWKI KODU ---")
    analysis = state.get("debugger_analysis", "")
    corrected_code = state.get("tool_args", {}).get("corrected_code")
    
    if not corrected_code:
        print("  [OSTRZEÅ»ENIE] Debugger nie dostarczyÅ‚ kodu. Wymuszam jego wygenerowanie...")
        
        # Tworzymy bardzo prosty prompt, ktÃ³ry ma tylko jedno zadanie
        force_prompt = f"""Na podstawie poniÅ¼szej analizy i wadliwego kodu, wygeneruj PEÅNY, POPRAWIONY i gotowy do uruchomienia skrypt Pythona.
        Twoja odpowiedÅº musi zawieraÄ‡ TYLKO i WYÅÄ„CZNIE blok kodu, bez Å¼adnych dodatkowych wyjaÅ›nieÅ„.

        [ANALIZA BÅÄ˜DU]:
        {analysis}

        [WADLIWY KOD]:
        ```python
        {state['error_context_code']}"""
        
        
        try:
            llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
            response = llm.invoke(force_prompt).content
            corrected_code = extract_python_code(response) # UÅ¼ywamy istniejÄ…cej funkcji pomocniczej
            print("  [INFO] PomyÅ›lnie wymuszono wygenerowanie kodu.")
        except Exception as e:
            print(f"  [BÅÄ„D KRYTYCZNY] Nie udaÅ‚o siÄ™ wymusiÄ‡ generacji kodu: {e}")
            return {"error_message": "Nie udaÅ‚o siÄ™ naprawiÄ‡ kodu nawet po eskalacji."}
        
        
    #--pamiÄ™Ä‡ dÅ‚ugotrwaÅ‚a info dla pamieci--
    
    
    session = state.get('pending_fix_session')
    if not session:
        # Sytuacja awaryjna, nie powinno siÄ™ zdarzyÄ‡ w normalnym przepÅ‚ywie
        print("  [OSTRZEÅ»ENIE] PrÃ³ba aplikacji poprawki bez aktywnej sesji naprawczej.")
        session = {}

    # Dodajemy informacje o tej konkretnej prÃ³bie do listy w sesji
    attempt_info = {
        "debugger_analysis": state.get("debugger_analysis", "Brak analizy."),
        "corrected_code": corrected_code,
        "attempt_number": len(session.get("fix_attempts", [])) + 1
    }
    
    if "fix_attempts" in session:
        session["fix_attempts"].append(attempt_info)
    else:
        session["fix_attempts"] = [attempt_info]
    
    print(f"  [INFO] Dodano prÃ³bÄ™ naprawy nr {attempt_info['attempt_number']} do sesji.")
    
    
    #--koniec--
    
    return {
        "generated_code": corrected_code, 
        "error_message": None, 
        "tool_choice": None, 
        "tool_args": None,
        "pending_fix_session": session  # Aktualizujemy sesjÄ™ w stanie
    }


def human_approval_node(state: AgentWorkflowState):
    print("\n" + "="*80 + "\n### WYMAGANA AKCJA CZÅOWIEKA  ###\n" + "="*80)
    package_name = state.get("tool_args", {}).get("package_name")
    user_input = input(f"Agent chce zainstalowaÄ‡ pakiet '{package_name}'. Czy zgadzasz siÄ™? [y/n]: ").lower().strip()
    if user_input == 'y':
        print("Zgoda. Przechodzenie do instalacji.")
        return {"user_approval_status": "APPROVED", "package_to_install": package_name}
    else:
        print("Odrzucono. Przekazywanie do debuggera w celu znalezienia alternatywy.")
        new_error_message = f"Instalacja pakietu '{package_name}' zostaÅ‚a odrzucona przez uÅ¼ytkownika. Zmodyfikuj kod, aby nie uÅ¼ywaÅ‚ tej zaleÅ¼noÅ›ci."
        return {"user_approval_status": "REJECTED", "error_message": new_error_message}


def package_installer_node(state: AgentWorkflowState):
    """Instaluje lub aktualizuje pakiet po uzyskaniu zgody."""
    package_name = state.get("package_to_install")
    
    # DomyÅ›lnie prÃ³bujemy aktualizacji, bo to rozwiÄ…zuje problemy z zaleÅ¼noÅ›ciami
    success = install_package(package_name, upgrade=True)
    
    if success:
        return {"package_to_install": None, "user_approval_status": None, "error_message": None}
    else:
        return {"error_message": f"Operacja na pakiecie '{package_name}' nie powiodÅ‚a siÄ™.", "failing_node": "package_installer"}

def commit_memory_node(state: AgentWorkflowState) -> Dict[str, Any]:
    """Zapisuje skonsolidowanÄ… wiedzÄ™ do pamiÄ™ci po udanej naprawie kodu."""
    session = state.get('pending_fix_session')
    
    # JeÅ›li nie ma sesji (np. kod zadziaÅ‚aÅ‚ za 1. razem), nie rÃ³b nic
    if not session or not session.get("fix_attempts"):
        return {"pending_fix_session": None}

    print("--- WÄ˜ZEÅ: ZATWIERDZANIE WIEDZY W PAMIÄ˜CI ---")
    
    distilled_content = distill_full_fix_session(
        initial_error=session['initial_error'],
        fix_attempts=session['fix_attempts'],
        successful_code=state['generated_code']
    )
    
    memory_client = state['memory_client']
    final_record = MemoryRecord(
        run_id=state['run_id'],
        memory_type=MemoryType.SUCCESSFUL_FIX, # Teraz to jest prawdziwy sukces
        dataset_signature=state['dataset_signature'],
        source_node="commit_memory_node",
        content=distilled_content,
        metadata={"total_attempts": len(session['fix_attempts'])}
    )
    memory_client.add_memory(final_record)
    
    # WyczyÅ›Ä‡ sesjÄ™ po udanym zapisie
    return {"pending_fix_session": None} 

    
    
def reporting_agent_node(state: AgentWorkflowState):
    """
    Wczytuje dane wejÅ›ciowe i przetworzone, tworzy ich podsumowania statystyczne,
    a nastÄ™pnie wywoÅ‚uje agenta w celu wygenerowania kodu analitycznego.
    """
    print("\n--- WÄ˜ZEÅ: AGENT RAPORTUJÄ„CY (ANALIZA DANYCH I GENEROWANIE KODU) ---")
    
    try:
        # --- NOWY KROK: Wczytanie i analiza danych ---
        print("  [INFO] Wczytywanie danych do analizy porÃ³wnawczej...")
        df_original = pd.read_csv(state['input_path'])
        df_processed = pd.read_csv(state['output_path'])

        # Tworzenie zwiÄ™zÅ‚ych podsumowaÅ„ tekstowych dla LLM
        # UÅ¼ywamy io.StringIO, aby przechwyciÄ‡ 'print' z df.info() do stringa
        original_info_buf = io.StringIO()
        df_original.info(buf=original_info_buf)
        
        processed_info_buf = io.StringIO()
        df_processed.info(buf=processed_info_buf)

        original_summary = f"""
### Podsumowanie danych ORYGINALNYCH ###
Pierwsze 3 wiersze:
{df_original.head(3).to_string()}

Informacje o kolumnach:
{original_info_buf.getvalue()}
Statystyki (dla kolumn numerycznych):
{df_original.describe().to_string()}
"""
        processed_summary = f"""
### Podsumowanie danych PRZETWORZONYCH ###
Pierwsze 3 wiersze:
{df_processed.head(3).to_string()}

Informacje o kolumnach:
{processed_info_buf.getvalue()}
Statystyki (dla kolumn numerycznych):
{df_processed.describe().to_string()}
"""
        print("  [INFO] Podsumowania danych wygenerowane.")
        # --- KONIEC NOWEGO KROKU ---

        # Krok 2: UtwÃ³rz precyzyjny prompt z nowym kontekstem
        prompt = PromptTemplates.create_reporting_prompt(
            plan=state['plan'],
            original_summary=original_summary,
            processed_summary=processed_summary
        )
        
        # Krok 3: WywoÅ‚aj LLM (bez zmian)
        llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
        structured_llm = llm.with_structured_output(GeneratedPythonScript)
        response_object = structured_llm.invoke(prompt)
        report_analysis_code = response_object.script_code
        
        print("  [INFO] Agent-Analityk wygenerowaÅ‚ kod analityczny na podstawie danych.")
        
        return {"generated_report_code": report_analysis_code}

    except Exception as e:
        print(f"  [BÅÄ„D] Krytyczny bÅ‚Ä…d w agencie raportujÄ…cym: {traceback.format_exc()}")
        return {"generated_report_code": None}

def report_executor_node(state: AgentWorkflowState):
    """
    Wczytuje zewnÄ™trzny szablon HTML, wykonuje kod analityczny od agenta,
    a nastÄ™pnie wstawia wyniki do szablonu, tworzÄ…c finalny raport.
    """
    print("--- WÄ˜ZEÅ: WYKONANIE KODU RAPORTU (Z ZEWNÄ˜TRZNEGO SZABLONU) ---")
    analysis_code = state.get("generated_report_code")
    
    if not analysis_code:
        return {"error_message": "Brak kodu analitycznego do wykonania.", "failing_node": "report_executor"}

    try:
        # Krok 1: Zbuduj kompletny, wykonywalny skrypt do wygenerowania "ciaÅ‚a" raportu
        # Ten skrypt zawiera wszystkie potrzebne importy i funkcje pomocnicze.
        body_script_to_execute = f"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import base64
from io import BytesIO

def embed_plot_to_html(figure):
    \"\"\"Konwertuje figurÄ™ matplotlib do stringa base64 do osadzenia w HTML.\"\"\"
    buffer = BytesIO()
    figure.savefig(buffer, format='png', bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    graphic = base64.b64encode(image_png)
    graphic = graphic.decode('utf-8')
    plt.close(figure)
    return f'<img src="data:image/png;base64,{{graphic}}" alt="Wykres analizy danych" style="max-width: 100%; height: auto;"/>'

# --- Kod wygenerowany przez agenta-analityka ---
{analysis_code}
# ---------------------------------------------

# Przygotowanie finalnego "ciaÅ‚a" HTML do wstawienia w szablon
html_body_content = ""
if 'summary_text' in locals():
    html_body_content += "<h2>Podsumowanie</h2>" + summary_text
if 'figures_to_embed' in locals() and isinstance(figures_to_embed, list):
    html_body_content += "<h2>Wizualizacje</h2>"
    for fig in figures_to_embed:
        html_body_content += embed_plot_to_html(fig)
"""
        # Krok 2: Przygotuj Å›rodowisko i wykonaj powyÅ¼szy skrypt, aby uzyskaÄ‡ treÅ›Ä‡ raportu
        print("  [INFO] Wykonywanie kodu analitycznego w celu wygenerowania treÅ›ci raportu...")
        exec_scope = {
            'df_original': pd.read_csv(state['input_path']),
            'df_processed': pd.read_csv(state['output_path']),
        }
        exec(body_script_to_execute, exec_scope)
        generated_html_body = exec_scope['html_body_content']

        # Krok 3: Wczytaj zewnÄ™trzny szablon HTML
        print("  [INFO] Wczytywanie szablonu z pliku report_template.html...")
        with open("report_template.html", "r", encoding="utf-8") as f:
            template = f.read()

        # Krok 4: Wstaw wygenerowanÄ… treÅ›Ä‡ do szablonu i zapisz finalny raport
        final_html = template.format(generated_html_body=generated_html_body)
        with open(state['report_output_path'], 'w', encoding='utf-8') as f:
            f.write(final_html)

        print(f"  [INFO] Raport HTML zostaÅ‚ pomyÅ›lnie zapisany w: {state['report_output_path']}")
        return {"error_message": None} # Sukces

    except Exception:
        error_traceback = traceback.format_exc()
        print(f"  [BÅÄ„D] WystÄ…piÅ‚ bÅ‚Ä…d podczas wykonywania skryptu raportu:\n{error_traceback}")
        # Przekazujemy do debuggera tylko ten fragment, ktÃ³ry zawiÃ³dÅ‚ (kod od agenta)
        return {
            "failing_node": "report_executor", 
            "error_message": error_traceback, 
            "error_context_code": analysis_code, 
            "correction_attempts": state.get('correction_attempts', 0) + 1
        }

    
def sync_report_code_node(state: AgentWorkflowState):
    """Synchronizuje naprawiony kod z powrotem do stanu agenta raportujÄ…cego."""
    print("--- WÄ˜ZEÅ: SYNCHRONIZACJA KODU RAPORTU ---")
    corrected_code = state.get("generated_code")
    return {"generated_report_code": corrected_code}   
    
    
def meta_auditor_node(state: AgentWorkflowState):
    """Uruchamia audytora ORAZ zapisuje wspomnienia o sukcesie i wnioski META."""
    print("\n" + "="*80 + "\n### ### FAZA 3: META-AUDYT I KONSOLIDACJA WIEDZY ### ###\n" + "="*80 + "\n")
    memory_client = state['memory_client']

    # 1. Zapisz wspomnienie o udanym planie (jeÅ›li nie byÅ‚o bÅ‚Ä™dÃ³w)
    if state.get('plan') and not state.get('error_message'):
        distilled_content = distill_success_memory(final_plan=state['plan'])
        plan_record = MemoryRecord(
            run_id=state['run_id'], memory_type=MemoryType.SUCCESSFUL_PLAN,
            dataset_signature=state['dataset_signature'], source_node="meta_auditor_node",
            content=distilled_content, metadata={"importance_score": 0.8}
        )
        memory_client.add_memory(plan_record)
    
    # 2. Uruchom audytora (logika bez zmian)
    try:
        # ... (caÅ‚a logika generowania raportu audytora, tak jak w oryginale)
        # ZaÅ‚Ã³Å¼my, Å¼e wynikiem jest zmienna 'audit_report'
        final_report_content = "Brak raportu do analizy."
        try:
            with open(state['report_output_path'], 'r', encoding='utf-8') as f:
                final_report_content = f.read()
        except Exception: pass
        
        llm = ChatAnthropic(model_name=CRITIC_MODEL, temperature=0.0, max_tokens=2048)
        prompt = PromptTemplates.create_meta_auditor_prompt(
            source_code=state['source_code'], autogen_conversation=state['autogen_log'],
            langgraph_log=state['langgraph_log'], final_code=state.get('generated_code', 'Brak kodu'),
            final_report=final_report_content
        )
        audit_report = llm.invoke(prompt).content
        # ... (zapis raportu do pliku)

        # 3. WYGENERUJ I ZAPISZ WNIOSEK META
        meta_insight_content = generate_meta_insight(audit_report)
        if meta_insight_content:
            insight_record = MemoryRecord(
                run_id=state['run_id'], memory_type=MemoryType.META_INSIGHT,
                dataset_signature=state['dataset_signature'], source_node="meta_auditor_node",
                content=meta_insight_content, metadata={"importance_score": 1.0}
            )
            memory_client.add_memory(insight_record)

    except Exception as e:
        print(f"BÅÄ„D KRYTYCZNY podczas meta-audytu: {e}")
    return {}

    
    
def human_escalation_node(state: AgentWorkflowState):
    """WÄ™zeÅ‚ eskalacji (bez zmian)."""
    print("\n==================================================")
    print(f"--- WÄ˜ZEÅ: ESKALACJA DO CZÅOWIEKA---")
    print("==================================================")
    # ... (reszta kodu bez zmian)
    report_content = f"""
Data: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Problem: Przekroczono maksymalny limit ({MAX_CORRECTION_ATTEMPTS}) prÃ³b automatycznej naprawy.

Ostatnia analiza debuggera:
{state.get('debugger_analysis', 'Brak analizy.')}

Ostatni kod, ktÃ³ry zawiÃ³dÅ‚:
```python
{state.get('error_context_code', 'Brak kodu.')}
```

PeÅ‚ny traceback ostatniego bÅ‚Ä™du:
{state.get('error_message', 'Brak bÅ‚Ä™du.')}
"""
    file_name = f"human_escalation_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(file_name, "w", encoding="utf-8") as f: f.write(report_content)
    print(f"  [INFO] Raport dla czÅ‚owieka zostaÅ‚ zapisany w pliku: {file_name}")
    return {}


# ################################################################################
# ### ### GÅ‚Ã³wny blok uruchomieniowy
# ################################################################################

# In[19]:


if __name__ == "__main__":
    os.makedirs("reports", exist_ok=True)
    system_source_code = read_source_code("Agents_beta.ipynb") # PamiÄ™taj o poprawnej nazwie pliku

    # --- Inicjalizacja PamiÄ™ci i Uruchomienia ---
    memory_client = MemoryBankClient(client=client, agent_engine=agent_engine)
    run_id = str(uuid.uuid4())
    
    print("\n--- ODPYTYWANIE PAMIÄ˜CI O INSPIRACJE ---")
    inspiration_prompt = ""
    dataset_signature = ""
    try:
        df_preview = pd.read_csv(INPUT_FILE_PATH, nrows=0)
        dataset_signature = memory_client.create_dataset_signature(df_preview)
        past_memories = memory_client.query_memory(
            query_text="Najlepsze strategie i kluczowe wnioski dotyczÄ…ce przetwarzania danych",
            scope={"dataset_signature": dataset_signature},
            top_k=3
        )
        if past_memories:
            inspirations = []
            for mem in past_memories:
                if mem.memory_type == MemoryType.SUCCESSFUL_PLAN and 'key_insight' in mem.content:
                    inspirations.append(f"SPRAWDZONY WNIOSEK Z PLANU: {mem.content['key_insight']}")
                elif mem.memory_type == MemoryType.SUCCESSFUL_FIX and 'key_takeaway' in mem.content:
                    inspirations.append(f"NAUCZKA Z NAPRAWIONEGO BÅÄ˜DU: {mem.content['key_takeaway']}")
            if inspirations:
                inspiration_prompt = "--- INSPIRACJE Z POPRZEDNICH URUCHOMIEÅƒ ---\n" + "\n".join(inspirations)
                print("INFO: PomyÅ›lnie pobrano inspiracje z pamiÄ™ci.")
        else:
            print("INFO: Nie znaleziono inspiracji w pamiÄ™ci dla tego typu danych.")
    except Exception as e:
        print(f"OSTRZEÅ»ENIE: Nie udaÅ‚o siÄ™ pobraÄ‡ inspiracji z pamiÄ™ci: {e}")

    # --- Krok 1: Faza planowania AutoGen ---
    final_plan, autogen_log = run_autogen_planning_phase(input_path=INPUT_FILE_PATH, inspiration_prompt=inspiration_prompt)

    # Zapis logu z planowania (zawsze)
    save_autogen_conversation_log(log_content=autogen_log, file_path="reports/autogen_planning_conversation.log")

    # --- Krok 2: Faza wykonania LangGraph ---
    if final_plan:
        print("\n" + "="*80)
        print("### ### FAZA 2: URUCHAMIANIE WYKONANIA PLANU (LangGraph) ### ###")
        print("="*80 + "\n")
        
        workflow = StateGraph(AgentWorkflowState)
        
        # ZMIANA: Dodajemy nowy wÄ™zeÅ‚ commit_memory_node do listy
        nodes = [
            "schema_reader", "code_generator", "architectural_validator", 
            "data_code_executor", "universal_debugger", "apply_code_fix", 
            "human_approval", "package_installer", "reporting_agent", 
            "report_executor", "human_escalation", "sync_report_code",
            "commit_memory" # NOWY WÄ˜ZEÅ
        ]
        for name in nodes: workflow.add_node(name, globals()[f"{name}_node"])

        # --- Definicja KrawÄ™dzi Grafu ---
        workflow.set_entry_point("schema_reader")
        workflow.add_edge("schema_reader", "code_generator")
        workflow.add_edge("code_generator", "architectural_validator")

        # Funkcja routujÄ…ca, ktÃ³rej moÅ¼emy uÅ¼ywaÄ‡ wielokrotnie
        def should_continue_or_debug(state: AgentWorkflowState) -> str:
            """Sprawdza, czy w stanie jest bÅ‚Ä…d i decyduje o dalszej Å›cieÅ¼ce."""
            if state.get("error_message"):
                if state.get("correction_attempts", 0) >= MAX_CORRECTION_ATTEMPTS:
                    return "request_human_help"
                return "call_debugger"
            # JeÅ›li nie ma bÅ‚Ä™du, kontynuuj normalnÄ… Å›cieÅ¼kÄ™
            return "continue"

        # 1. KRAWÄ˜DÅ¹ WARUNKOWA po walidatorze architektury (KLUCZOWA ZMIANA)
        workflow.add_conditional_edges(
            "architectural_validator",
            should_continue_or_debug,
            {
                "call_debugger": "universal_debugger",
                "request_human_help": "human_escalation",
                "continue": "data_code_executor" # PrzejdÅº dalej tylko jeÅ›li jest OK
            }
        )

        # 2. KRAWÄ˜DÅ¹ WARUNKOWA po wykonaniu kodu danych
        workflow.add_conditional_edges(
            "data_code_executor",
            should_continue_or_debug,
            {
                "call_debugger": "universal_debugger",
                "request_human_help": "human_escalation",
                "continue": "commit_memory" # JeÅ›li sukces, idÅº do zapisu w pamiÄ™ci, a NIE do END
            }
        )

        # ÅšcieÅ¼ka sukcesu i pozostaÅ‚e krawÄ™dzie
        workflow.add_edge("commit_memory", "reporting_agent")
        workflow.add_edge("reporting_agent", "report_executor")

        # KrawÄ™dÅº warunkowa po wykonaniu raportu
        workflow.add_conditional_edges(
            "report_executor",
            should_continue_or_debug,
            {
                "call_debugger": "universal_debugger",
                "request_human_help": "human_escalation",
                "continue": END # Dopiero tutaj koÅ„czymy pracÄ™ po sukcesie
            }
        )

        # ÅšcieÅ¼ki naprawcze i eskalacji (bez zmian)
        workflow.add_edge("human_escalation", END)
        workflow.add_edge("package_installer", "data_code_executor") # Wracamy do wykonania po instalacji

        def route_after_fix(state):
            failing_node = state.get("failing_node")
            if failing_node == "report_executor":
                return "sync_report_code"
            # Po kaÅ¼dej innej naprawie wracamy do walidacji architektonicznej
            return "architectural_validator"

        workflow.add_edge("sync_report_code", "report_executor")
        workflow.add_conditional_edges("apply_code_fix", route_after_fix)

        def route_from_debugger(state):
            if state.get("tool_choice") == "propose_code_fix":
                return "apply_code_fix"
            if state.get("tool_choice") == "request_package_installation":
                return "human_approval"
            return "human_escalation"

        workflow.add_conditional_edges("universal_debugger", route_from_debugger)
        workflow.add_conditional_edges("human_approval", lambda s: s.get("user_approval_status"), {
            "APPROVED": "package_installer",
            "REJECTED": "universal_debugger"
        })

        app = workflow.compile()
        
        initial_state = {
            "plan": final_plan, 
            "input_path": INPUT_FILE_PATH,
            "output_path": "reports/processed_data.csv",
            "report_output_path": "reports/transformation_report.html",
            "correction_attempts": 0, 
            "source_code": system_source_code,
            "autogen_log": autogen_log,
            "memory_client": memory_client,
            "run_id": run_id,
            "dataset_signature": dataset_signature,
            "pending_fix_session": None # ZMIANA: Dodanie nowego pola do stanu poczÄ…tkowego
        }
        
        # --- Uruchomienie grafu z przechwytywaniem logÃ³w ---
        langgraph_log = ""
        final_run_state = initial_state.copy()
        
        for event in app.stream(initial_state, {"recursion_limit": 50}):
            for node_name, state_update in event.items():
                if "__end__" not in node_name:
                    print(f"--- Krok: '{node_name}' ---")
                    if state_update: # Zabezpieczenie przed bÅ‚Ä™dem 'NoneType'
                        printable_update = state_update.copy()
                        for key in ["generated_code", "corrected_code", "generated_report_code", "error_context_code"]:
                            if key in printable_update and printable_update[key]:
                                print(f"--- {key.upper()} ---")
                                print(printable_update[key])
                                print("-" * (len(key) + 8))
                                del printable_update[key]
                        if printable_update:
                            print(json.dumps(printable_update, indent=2, default=str))
                        
                        log_line = f"--- Krok: '{node_name}' ---\n{json.dumps(state_update, indent=2, default=str)}\n"
                        langgraph_log += log_line
                        final_run_state.update(state_update)
                    else:
                        print("  [INFO] WÄ™zeÅ‚ zakoÅ„czyÅ‚ pracÄ™ bez aktualizacji stanu.")
                    print("-" * 20 + "\n")

        # Zapis logu z wykonania (po zakoÅ„czeniu pÄ™tli)
        save_langgraph_execution_log(log_content=langgraph_log, file_path="reports/langgraph_execution.log")

        # Uruchomienie audytora
        final_run_state['langgraph_log'] = langgraph_log
        meta_auditor_node(final_run_state)

        print("\n\n--- ZAKOÅƒCZONO PRACÄ˜ GRAFU I AUDYT ---")
    else:
        print("Proces zakoÅ„czony. Brak planu do wykonania.")


# In[ ]:





# In[ ]:




