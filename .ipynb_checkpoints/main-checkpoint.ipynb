{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b251096d-f8c3-4dfb-ae10-5d33be45f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import json\n",
    "import vertexai\n",
    "from vertexai import agent_engines\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List, Callable, Dict, Optional, Union, Any\n",
    "# Importy z własnych modułów\n",
    "from config import PROJECT_ID, LOCATION, MEMORY_ENGINE_DISPLAY_NAME, INPUT_FILE_PATH, basic_config_agent\n",
    "from agents.state import AgentWorkflowState\n",
    "from agents.autogen_agents import TriggerAgent,PlannerAgent,CriticAgent\n",
    "from agents.langgraph_nodes import * \n",
    "from agents.autogen_agent_utils import run_autogen_planning_phase\n",
    "from memory.memory_bank_client import MemoryBankClient\n",
    "from tools.utils import read_source_code, save_autogen_conversation_log, save_langgraph_execution_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b380a6ac-127b-44dd-9e3b-e0721815cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_ENGINE_NAME = \"\" # Zostanie wypełniona po pobraniu lub utworzeniu silnika\n",
    "\n",
    "# Inicjalizacja głównego klienta Vertex AI\n",
    "client = vertexai.Client(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba1b166-e3c9-4d11-9a08-76336faaa064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_agent_engine(display_name: str) :\n",
    "    \"\"\"\n",
    "    Pobiera istniejący Agent Engine po nazwie wyświetlanej lub tworzy nowy, jeśli nie istnieje.\n",
    "    \"\"\"\n",
    "    # 1. Pobierz listę wszystkich istniejących silników w projekcie\n",
    "    all_engines = agent_engines.list()\n",
    "    \n",
    "    # 2. Sprawdź, czy któryś z nich ma pasującą nazwę\n",
    "    for engine in all_engines:\n",
    "        if engine.display_name == display_name:\n",
    "            print(f\"INFO: Znaleziono i połączono z istniejącym Agent Engine: '{display_name}'\")\n",
    "            return engine\n",
    "            \n",
    "    # 3. Jeśli pętla się zakończyła i nic nie znaleziono, stwórz nowy silnik\n",
    "    print(f\"INFO: Nie znaleziono Agent Engine o nazwie '{display_name}'. Tworzenie nowego...\")\n",
    "    try:\n",
    "        new_engine = agent_engines.create(\n",
    "            display_name=display_name\n",
    "        )\n",
    "        print(f\"INFO: Pomyślnie utworzono nowy Agent Engine.\")\n",
    "        return new_engine\n",
    "    except Exception as e:\n",
    "        print(f\"KRYTYCZNY BŁĄD: Nie można utworzyć Agent Engine. Sprawdź konfigurację i uprawnienia. Błąd: {e}\")\n",
    "        exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6982c7b4-a6dd-476f-b361-d36c50174185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Konfiguracja czatu grupowego ---\n",
    "main_agent_configuration={\"cache_seed\": 42,\"seed\": 42,\"temperature\": 0.0,\n",
    "                        \"config_list\": basic_config_agent(agent_name=MAIN_AGENT, api_type=API_TYPE_GEMINI, location=LOCATION, project_id=PROJECT_ID)}\n",
    "critic_agent_configuration ={\"cache_seed\": 42,\"seed\": 42,\"temperature\": 0.0,\n",
    "                        \"config_list\": basic_config_agent(api_key=ANTHROPIC_API_KEY,agent_name=CRITIC_MODEL, api_type=API_TYPE_SONNET)}\n",
    "\n",
    "\n",
    "#---WYWOŁANIE AGENTÓW\n",
    "trigger_agent = TriggerAgent(llm_config=main_agent_configuration)\n",
    "planner_agent = PlannerAgent(llm_config=main_agent_configuration)\n",
    "critic_agent = CriticAgent(llm_config=main_agent_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d12db3-dfe5-4c56-9494-8721eccacda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    system_source_code = read_source_code(\"Agents_beta.ipynb\") # Pamiętaj o poprawnej nazwie pliku\n",
    "\n",
    "    # --- Inicjalizacja Pamięci i Uruchomienia ---\n",
    "    memory_client = MemoryBankClient(client=client, agent_engine=agent_engine)\n",
    "    run_id = str(uuid.uuid4())\n",
    "    \n",
    "    print(\"\\n--- ODPYTYWANIE PAMIĘCI O INSPIRACJE ---\")\n",
    "    inspiration_prompt = \"\"\n",
    "    dataset_signature = \"\"\n",
    "    try:\n",
    "        df_preview = pd.read_csv(INPUT_FILE_PATH, nrows=0)\n",
    "        dataset_signature = memory_client.create_dataset_signature(df_preview)\n",
    "        past_memories = memory_client.query_memory(\n",
    "            query_text=\"Najlepsze strategie i kluczowe wnioski dotyczące przetwarzania danych\",\n",
    "            scope={\"dataset_signature\": dataset_signature},\n",
    "            top_k=3\n",
    "        )\n",
    "        if past_memories:\n",
    "            inspirations = []\n",
    "            for mem in past_memories:\n",
    "                if mem.memory_type == MemoryType.SUCCESSFUL_PLAN and 'key_insight' in mem.content:\n",
    "                    inspirations.append(f\"SPRAWDZONY WNIOSEK Z PLANU: {mem.content['key_insight']}\")\n",
    "                elif mem.memory_type == MemoryType.SUCCESSFUL_FIX and 'key_takeaway' in mem.content:\n",
    "                    inspirations.append(f\"NAUCZKA Z NAPRAWIONEGO BŁĘDU: {mem.content['key_takeaway']}\")\n",
    "            if inspirations:\n",
    "                inspiration_prompt = \"--- INSPIRACJE Z POPRZEDNICH URUCHOMIEŃ ---\\n\" + \"\\n\".join(inspirations)\n",
    "                print(\"INFO: Pomyślnie pobrano inspiracje z pamięci.\")\n",
    "        else:\n",
    "            print(\"INFO: Nie znaleziono inspiracji w pamięci dla tego typu danych.\")\n",
    "    except Exception as e:\n",
    "        print(f\"OSTRZEŻENIE: Nie udało się pobrać inspiracji z pamięci: {e}\")\n",
    "\n",
    "    # --- Krok 1: Faza planowania AutoGen ---\n",
    "    final_plan, autogen_log = run_autogen_planning_phase(input_path=INPUT_FILE_PATH, inspiration_prompt=inspiration_prompt)\n",
    "\n",
    "    # Zapis logu z planowania (zawsze)\n",
    "    save_autogen_conversation_log(log_content=autogen_log, file_path=\"reports/autogen_planning_conversation.log\")\n",
    "\n",
    "    # --- Krok 2: Faza wykonania LangGraph ---\n",
    "    if final_plan:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"### ### FAZA 2: URUCHAMIANIE WYKONANIA PLANU (LangGraph) ### ###\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        workflow = StateGraph(AgentWorkflowState)\n",
    "        \n",
    "        # ZMIANA: Dodajemy nowy węzeł commit_memory_node do listy\n",
    "        nodes = [\n",
    "            \"schema_reader\", \"code_generator\", \"architectural_validator\", \n",
    "            \"data_code_executor\", \"universal_debugger\", \"apply_code_fix\", \n",
    "            \"human_approval\", \"package_installer\", \"reporting_agent\", \n",
    "            \"report_executor\", \"human_escalation\", \"sync_report_code\",\n",
    "            \"commit_memory\" # NOWY WĘZEŁ\n",
    "        ]\n",
    "        for name in nodes: workflow.add_node(name, globals()[f\"{name}_node\"])\n",
    "\n",
    "        # --- Definicja Krawędzi Grafu ---\n",
    "        workflow.set_entry_point(\"schema_reader\")\n",
    "        workflow.add_edge(\"schema_reader\", \"code_generator\")\n",
    "        workflow.add_edge(\"code_generator\", \"architectural_validator\")\n",
    "\n",
    "        # Funkcja routująca, której możemy używać wielokrotnie\n",
    "        def should_continue_or_debug(state: AgentWorkflowState) -> str:\n",
    "            \"\"\"Sprawdza, czy w stanie jest błąd i decyduje o dalszej ścieżce.\"\"\"\n",
    "            if state.get(\"error_message\"):\n",
    "                if state.get(\"correction_attempts\", 0) >= MAX_CORRECTION_ATTEMPTS:\n",
    "                    return \"request_human_help\"\n",
    "                return \"call_debugger\"\n",
    "            # Jeśli nie ma błędu, kontynuuj normalną ścieżkę\n",
    "            return \"continue\"\n",
    "\n",
    "        # 1. KRAWĘDŹ WARUNKOWA po walidatorze architektury (KLUCZOWA ZMIANA)\n",
    "        workflow.add_conditional_edges(\n",
    "            \"architectural_validator\",\n",
    "            should_continue_or_debug,\n",
    "            {\n",
    "                \"call_debugger\": \"universal_debugger\",\n",
    "                \"request_human_help\": \"human_escalation\",\n",
    "                \"continue\": \"data_code_executor\" # Przejdź dalej tylko jeśli jest OK\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 2. KRAWĘDŹ WARUNKOWA po wykonaniu kodu danych\n",
    "        workflow.add_conditional_edges(\n",
    "            \"data_code_executor\",\n",
    "            should_continue_or_debug,\n",
    "            {\n",
    "                \"call_debugger\": \"universal_debugger\",\n",
    "                \"request_human_help\": \"human_escalation\",\n",
    "                \"continue\": \"commit_memory\" # Jeśli sukces, idź do zapisu w pamięci, a NIE do END\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Ścieżka sukcesu i pozostałe krawędzie\n",
    "        workflow.add_edge(\"commit_memory\", \"reporting_agent\")\n",
    "        workflow.add_edge(\"reporting_agent\", \"report_executor\")\n",
    "\n",
    "        # Krawędź warunkowa po wykonaniu raportu\n",
    "        workflow.add_conditional_edges(\n",
    "            \"report_executor\",\n",
    "            should_continue_or_debug,\n",
    "            {\n",
    "                \"call_debugger\": \"universal_debugger\",\n",
    "                \"request_human_help\": \"human_escalation\",\n",
    "                \"continue\": END # Dopiero tutaj kończymy pracę po sukcesie\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Ścieżki naprawcze i eskalacji (bez zmian)\n",
    "        workflow.add_edge(\"human_escalation\", END)\n",
    "        workflow.add_edge(\"package_installer\", \"data_code_executor\") # Wracamy do wykonania po instalacji\n",
    "\n",
    "        def route_after_fix(state):\n",
    "            failing_node = state.get(\"failing_node\")\n",
    "            if failing_node == \"report_executor\":\n",
    "                return \"sync_report_code\"\n",
    "            # Po każdej innej naprawie wracamy do walidacji architektonicznej\n",
    "            return \"architectural_validator\"\n",
    "\n",
    "        workflow.add_edge(\"sync_report_code\", \"report_executor\")\n",
    "        workflow.add_conditional_edges(\"apply_code_fix\", route_after_fix)\n",
    "\n",
    "        def route_from_debugger(state):\n",
    "            if state.get(\"tool_choice\") == \"propose_code_fix\":\n",
    "                return \"apply_code_fix\"\n",
    "            if state.get(\"tool_choice\") == \"request_package_installation\":\n",
    "                return \"human_approval\"\n",
    "            return \"human_escalation\"\n",
    "\n",
    "        workflow.add_conditional_edges(\"universal_debugger\", route_from_debugger)\n",
    "        workflow.add_conditional_edges(\"human_approval\", lambda s: s.get(\"user_approval_status\"), {\n",
    "            \"APPROVED\": \"package_installer\",\n",
    "            \"REJECTED\": \"universal_debugger\"\n",
    "        })\n",
    "\n",
    "        app = workflow.compile()\n",
    "        \n",
    "        initial_state = {\n",
    "            \"plan\": final_plan, \n",
    "            \"input_path\": INPUT_FILE_PATH,\n",
    "            \"output_path\": \"reports/processed_data.csv\",\n",
    "            \"report_output_path\": \"reports/transformation_report.html\",\n",
    "            \"correction_attempts\": 0, \n",
    "            \"source_code\": system_source_code,\n",
    "            \"autogen_log\": autogen_log,\n",
    "            \"memory_client\": memory_client,\n",
    "            \"run_id\": run_id,\n",
    "            \"dataset_signature\": dataset_signature,\n",
    "            \"pending_fix_session\": None # ZMIANA: Dodanie nowego pola do stanu początkowego\n",
    "        }\n",
    "        \n",
    "        # --- Uruchomienie grafu z przechwytywaniem logów ---\n",
    "        langgraph_log = \"\"\n",
    "        final_run_state = initial_state.copy()\n",
    "        \n",
    "        for event in app.stream(initial_state, {\"recursion_limit\": 50}):\n",
    "            for node_name, state_update in event.items():\n",
    "                if \"__end__\" not in node_name:\n",
    "                    print(f\"--- Krok: '{node_name}' ---\")\n",
    "                    if state_update: # Zabezpieczenie przed błędem 'NoneType'\n",
    "                        printable_update = state_update.copy()\n",
    "                        for key in [\"generated_code\", \"corrected_code\", \"generated_report_code\", \"error_context_code\"]:\n",
    "                            if key in printable_update and printable_update[key]:\n",
    "                                print(f\"--- {key.upper()} ---\")\n",
    "                                print(printable_update[key])\n",
    "                                print(\"-\" * (len(key) + 8))\n",
    "                                del printable_update[key]\n",
    "                        if printable_update:\n",
    "                            print(json.dumps(printable_update, indent=2, default=str))\n",
    "                        \n",
    "                        log_line = f\"--- Krok: '{node_name}' ---\\n{json.dumps(state_update, indent=2, default=str)}\\n\"\n",
    "                        langgraph_log += log_line\n",
    "                        final_run_state.update(state_update)\n",
    "                    else:\n",
    "                        print(\"  [INFO] Węzeł zakończył pracę bez aktualizacji stanu.\")\n",
    "                    print(\"-\" * 20 + \"\\n\")\n",
    "\n",
    "        # Zapis logu z wykonania (po zakończeniu pętli)\n",
    "        save_langgraph_execution_log(log_content=langgraph_log, file_path=\"reports/langgraph_execution.log\")\n",
    "\n",
    "        # Uruchomienie audytora\n",
    "        final_run_state['langgraph_log'] = langgraph_log\n",
    "        meta_auditor_node(final_run_state)\n",
    "\n",
    "        print(\"\\n\\n--- ZAKOŃCZONO PRACĘ GRAFU I AUDYT ---\")\n",
    "    else:\n",
    "        print(\"Proces zakończony. Brak planu do wykonania.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "agents_with_memory_p11",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Agents with memory (Python 3.11)",
   "language": "python",
   "name": "agents_with_memory_p11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
