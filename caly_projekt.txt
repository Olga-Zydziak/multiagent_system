--- FILE: __init__.py ---




--- FILE: config.py ---

import os
import logging
from enum import Enum
from google.cloud import secretmanager
import langchain
from langchain.cache import SQLiteCache





def get_secret(project_id: str, secret_id: str, version_id: str = "latest") -> str:
    """Pobiera warto≈õƒá sekretu z Google Secret Manager."""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"
    response = client.access_secret_version(request={"name": name})
   
    return response.payload.data.decode("UTF-8")


class ApiType(Enum):
    GOOGLE = "google"
    ANTHROPIC = "anthropic"
    def __str__(self):
        return self.value


LOCATION="us-central1"
PROJECT_ID="dark-data-discovery"

#---------AGENTS--------:
MAIN_AGENT="gemini-2.5-pro"
API_TYPE_GEMINI=str(ApiType.GOOGLE)

CRITIC_MODEL="claude-3-7-sonnet-20250219"
CODE_MODEL="claude-sonnet-4-20250514"
API_TYPE_SONNET = str(ApiType.ANTHROPIC)

LANGCHAIN_API_KEY = get_secret(PROJECT_ID,"LANGCHAIN_API_KEY")
ANTHROPIC_API_KEY=get_secret(PROJECT_ID,"ANTHROPIC_API_KEY")

MEMORY_ENGINE_DISPLAY_NAME="memory-gamma-way"

INPUT_FILE_PATH = "gs://super_model/data/structural_data/synthetic_fraud_dataset.csv"

MAX_CORRECTION_ATTEMPTS=5



os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = LANGCHAIN_API_KEY
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_PROJECT"] = "Projekt Multi-Agent-System v9.0-Integrated"
os.environ["ANTHROPIC_API_KEY"] =ANTHROPIC_API_KEY


#---cache-------
langchain.llm_cache = SQLiteCache(database_path=".langchain.db")



    
#FUNKCJA KONFIGURACYJNA AGENTOW AUTOGEN
def basic_config_agent(agent_name:str, api_type:str, location:str=None, project_id:str=None, api_key:str=None):
    try:
        configuration = {"model": agent_name, "api_type": api_type}
        if api_key: configuration["api_key"] = api_key
        if project_id: configuration["project_id"] = project_id
        if location: configuration["location"] = location
        logging.info(f"Model configuration: {configuration}")
        return [configuration]

    except Exception as e:
        logging.error(f"Failed to initialize Vertex AI or configure LLM: {e}")
        print(f"Error: Failed to initialize Vertex AI or configure LLM. Please check your project ID, region, and permissions. Details: {e}")
        exit()


--- FILE: main.ipynb ---

import os
import pandas as pd
import uuid
import json
import vertexai
from vertexai import agent_engines
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
# Importy z w≈Çasnych modu≈Ç√≥w
from config import PROJECT_ID, LOCATION, MEMORY_ENGINE_DISPLAY_NAME, INPUT_FILE_PATH,MAIN_AGENT,CRITIC_MODEL,CODE_MODEL, API_TYPE_GEMINI,API_TYPE_SONNET, ANTHROPIC_API_KEY,basic_config_agent
from agents.state import AgentWorkflowState
from agents.autogen_agents import TriggerAgent,PlannerAgent,CriticAgent
from prompts import AutoGen_Agents_Propmpt
from agents.langgraph_nodes import * 
from agents.autogen_agent_utils import run_autogen_planning_phase
from memory.memory_bank_client import MemoryBankClient
from tools.utils import read_source_code, save_autogen_conversation_log, save_langgraph_execution_log
# --- Koniec kom√≥rki ---
AGENT_ENGINE_NAME = "" # Zostanie wype≈Çniona po pobraniu lub utworzeniu silnika

# Inicjalizacja g≈Ç√≥wnego klienta Vertex AI
client = vertexai.Client(project=PROJECT_ID, location=LOCATION)
# --- Koniec kom√≥rki ---
def get_or_create_agent_engine(display_name: str) :
    """
    Pobiera istniejƒÖcy Agent Engine po nazwie wy≈õwietlanej lub tworzy nowy, je≈õli nie istnieje.
    """
    # 1. Pobierz listƒô wszystkich istniejƒÖcych silnik√≥w w projekcie
    all_engines = agent_engines.list()
    
    # 2. Sprawd≈∫, czy kt√≥ry≈õ z nich ma pasujƒÖcƒÖ nazwƒô
    for engine in all_engines:
        if engine.display_name == display_name:
            print(f"INFO: Znaleziono i po≈ÇƒÖczono z istniejƒÖcym Agent Engine: '{display_name}'")
            return engine
            
    # 3. Je≈õli pƒôtla siƒô zako≈Ñczy≈Ça i nic nie znaleziono, stw√≥rz nowy silnik
    print(f"INFO: Nie znaleziono Agent Engine o nazwie '{display_name}'. Tworzenie nowego...")
    try:
        new_engine = agent_engines.create(
            display_name=display_name
        )
        print(f"INFO: Pomy≈õlnie utworzono nowy Agent Engine.")
        return new_engine
    except Exception as e:
        print(f"KRYTYCZNY B≈ÅƒÑD: Nie mo≈ºna utworzyƒá Agent Engine. Sprawd≈∫ konfiguracjƒô i uprawnienia. B≈ÇƒÖd: {e}")
        exit()

# --- Koniec kom√≥rki ---
agent_engine =get_or_create_agent_engine(MEMORY_ENGINE_DISPLAY_NAME)
AGENT_ENGINE_NAME = agent_engine.resource_name
print(AGENT_ENGINE_NAME)

# --- Koniec kom√≥rki ---
# --- Konfiguracja czatu grupowego ---
main_agent_configuration={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(agent_name=MAIN_AGENT, api_type=API_TYPE_GEMINI, location=LOCATION, project_id=PROJECT_ID)}
critic_agent_configuration ={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(api_key=ANTHROPIC_API_KEY,agent_name=CRITIC_MODEL, api_type=API_TYPE_SONNET)}
trigger_prompt = str(AutoGen_Agents_Propmpt.Trigger_prompt())
planner_prompt = str(AutoGen_Agents_Propmpt.Planner_prompt())
critic_prompt = str(AutoGen_Agents_Propmpt.Critic_prompt())
#---WYWO≈ÅANIE AGENT√ìW
trigger_agent = TriggerAgent(llm_config=main_agent_configuration, prompt=trigger_prompt)
planner_agent = PlannerAgent(llm_config=main_agent_configuration,prompt=planner_prompt)
critic_agent = CriticAgent(llm_config=main_agent_configuration,prompt=critic_prompt)
# --- Koniec kom√≥rki ---
if __name__ == "__main__":
    os.makedirs("reports", exist_ok=True)
    system_source_code = read_source_code("Agents_beta.ipynb") # Pamiƒôtaj o poprawnej nazwie pliku

    # --- Inicjalizacja Pamiƒôci i Uruchomienia ---
    memory_client = MemoryBankClient(client=client, agent_engine=agent_engine)
    run_id = str(uuid.uuid4())
    
    print("\n--- ODPYTYWANIE PAMIƒòCI O INSPIRACJE ---")
    inspiration_prompt = ""
    dataset_signature = ""
    try:
        df_preview = pd.read_csv(INPUT_FILE_PATH, nrows=0)
        dataset_signature = memory_client.create_dataset_signature(df_preview)
        past_memories = memory_client.query_memory(
            query_text="Najlepsze strategie i kluczowe wnioski dotyczƒÖce przetwarzania danych",
            scope={"dataset_signature": dataset_signature},
            top_k=3
        )
        if past_memories:
            inspirations = []
            for mem in past_memories:
                if mem.memory_type == MemoryType.SUCCESSFUL_PLAN and 'key_insight' in mem.content:
                    inspirations.append(f"SPRAWDZONY WNIOSEK Z PLANU: {mem.content['key_insight']}")
                elif mem.memory_type == MemoryType.SUCCESSFUL_FIX and 'key_takeaway' in mem.content:
                    inspirations.append(f"NAUCZKA Z NAPRAWIONEGO B≈ÅƒòDU: {mem.content['key_takeaway']}")
            if inspirations:
                inspiration_prompt = "--- INSPIRACJE Z POPRZEDNICH URUCHOMIE≈É ---\n" + "\n".join(inspirations)
                print("INFO: Pomy≈õlnie pobrano inspiracje z pamiƒôci.")
        else:
            print("INFO: Nie znaleziono inspiracji w pamiƒôci dla tego typu danych.")
    except Exception as e:
        print(f"OSTRZE≈ªENIE: Nie uda≈Ço siƒô pobraƒá inspiracji z pamiƒôci: {e}")

    # --- Krok 1: Faza planowania AutoGen ---
    final_plan, autogen_log = run_autogen_planning_phase(input_path=INPUT_FILE_PATH, inspiration_prompt=inspiration_prompt,
                                                         trigger_agent=trigger_agent,planner_agent=planner_agent,critic_agent=critic_agent,manager_agent_config=main_agent_configuration)

    # Zapis logu z planowania (zawsze)
    save_autogen_conversation_log(log_content=autogen_log, file_path="reports/autogen_planning_conversation.log")

    # --- Krok 2: Faza wykonania LangGraph ---
    if final_plan:
        print("\n" + "="*80)
        print("### ### FAZA 2: URUCHAMIANIE WYKONANIA PLANU (LangGraph) ### ###")
        print("="*80 + "\n")
        
        workflow = StateGraph(AgentWorkflowState)
        
        # ZMIANA: Dodajemy nowy wƒôze≈Ç commit_memory_node do listy
        nodes = [
            "schema_reader", "code_generator", "architectural_validator", 
            "data_code_executor", "universal_debugger", "apply_code_fix", 
            "human_approval", "package_installer", "reporting_agent", 
            "report_executor", "human_escalation", "sync_report_code",
            "commit_memory" # NOWY WƒòZE≈Å
        ]
        for name in nodes: workflow.add_node(name, globals()[f"{name}_node"])

        # --- Definicja Krawƒôdzi Grafu ---
        workflow.set_entry_point("schema_reader")
        workflow.add_edge("schema_reader", "code_generator")
        workflow.add_edge("code_generator", "architectural_validator")

        # Funkcja routujƒÖca, kt√≥rej mo≈ºemy u≈ºywaƒá wielokrotnie
        def should_continue_or_debug(state: AgentWorkflowState) -> str:
            """Sprawdza, czy w stanie jest b≈ÇƒÖd i decyduje o dalszej ≈õcie≈ºce."""
            if state.get("error_message"):
                if state.get("correction_attempts", 0) >= MAX_CORRECTION_ATTEMPTS:
                    return "request_human_help"
                return "call_debugger"
            # Je≈õli nie ma b≈Çƒôdu, kontynuuj normalnƒÖ ≈õcie≈ºkƒô
            return "continue"

        # 1. KRAWƒòD≈π WARUNKOWA po walidatorze architektury (KLUCZOWA ZMIANA)
        workflow.add_conditional_edges(
            "architectural_validator",
            should_continue_or_debug,
            {
                "call_debugger": "universal_debugger",
                "request_human_help": "human_escalation",
                "continue": "data_code_executor" # Przejd≈∫ dalej tylko je≈õli jest OK
            }
        )

        # 2. KRAWƒòD≈π WARUNKOWA po wykonaniu kodu danych
        workflow.add_conditional_edges(
            "data_code_executor",
            should_continue_or_debug,
            {
                "call_debugger": "universal_debugger",
                "request_human_help": "human_escalation",
                "continue": "commit_memory" # Je≈õli sukces, id≈∫ do zapisu w pamiƒôci, a NIE do END
            }
        )

        # ≈öcie≈ºka sukcesu i pozosta≈Çe krawƒôdzie
        workflow.add_edge("commit_memory", "reporting_agent")
        workflow.add_edge("reporting_agent", "report_executor")

        # Krawƒôd≈∫ warunkowa po wykonaniu raportu
        workflow.add_conditional_edges(
            "report_executor",
            should_continue_or_debug,
            {
                "call_debugger": "universal_debugger",
                "request_human_help": "human_escalation",
                "continue": END # Dopiero tutaj ko≈Ñczymy pracƒô po sukcesie
            }
        )

        # ≈öcie≈ºki naprawcze i eskalacji (bez zmian)
        workflow.add_edge("human_escalation", END)
        workflow.add_edge("package_installer", "data_code_executor") # Wracamy do wykonania po instalacji

        def route_after_fix(state):
            failing_node = state.get("failing_node")
            if failing_node == "report_executor":
                return "sync_report_code"
            # Po ka≈ºdej innej naprawie wracamy do walidacji architektonicznej
            return "architectural_validator"

        workflow.add_edge("sync_report_code", "report_executor")
        workflow.add_conditional_edges("apply_code_fix", route_after_fix)

        def route_from_debugger(state):
            if state.get("tool_choice") == "propose_code_fix":
                return "apply_code_fix"
            if state.get("tool_choice") == "request_package_installation":
                return "human_approval"
            return "human_escalation"

        workflow.add_conditional_edges("universal_debugger", route_from_debugger)
        workflow.add_conditional_edges("human_approval", lambda s: s.get("user_approval_status"), {
            "APPROVED": "package_installer",
            "REJECTED": "universal_debugger"
        })

        
        
        app_config ={"MAIN_AGENT" : MAIN_AGENT, "CODE_MODEL": CODE_MODEL, "CRITIC_MODEL":CRITIC_MODEL}
        
        
        app = workflow.compile()
        
        initial_state = {
            "config":app_config,
            "plan": final_plan, 
            "input_path": INPUT_FILE_PATH,
            "output_path": "reports/processed_data.csv",
            "report_output_path": "reports/transformation_report.html",
            "correction_attempts": 0, 
            "source_code": system_source_code,
            "autogen_log": autogen_log,
            "memory_client": memory_client,
            "run_id": run_id,
            "dataset_signature": dataset_signature,
            "pending_fix_session": None # ZMIANA: Dodanie nowego pola do stanu poczƒÖtkowego
        }
        
        # --- Uruchomienie grafu z przechwytywaniem log√≥w ---
        langgraph_log = ""
        final_run_state = initial_state.copy()
        
        for event in app.stream(initial_state, {"recursion_limit": 50}):
            for node_name, state_update in event.items():
                if "__end__" not in node_name:
                    print(f"--- Krok: '{node_name}' ---")
                    if state_update: # Zabezpieczenie przed b≈Çƒôdem 'NoneType'
                        printable_update = state_update.copy()
                        for key in ["generated_code", "corrected_code", "generated_report_code", "error_context_code"]:
                            if key in printable_update and printable_update[key]:
                                print(f"--- {key.upper()} ---")
                                print(printable_update[key])
                                print("-" * (len(key) + 8))
                                del printable_update[key]
                        if printable_update:
                            print(json.dumps(printable_update, indent=2, default=str))
                        
                        log_line = f"--- Krok: '{node_name}' ---\n{json.dumps(state_update, indent=2, default=str)}\n"
                        langgraph_log += log_line
                        final_run_state.update(state_update)
                    else:
                        print("  [INFO] Wƒôze≈Ç zako≈Ñczy≈Ç pracƒô bez aktualizacji stanu.")
                    print("-" * 20 + "\n")

        # Zapis logu z wykonania (po zako≈Ñczeniu pƒôtli)
        save_langgraph_execution_log(log_content=langgraph_log, file_path="reports/langgraph_execution.log")

        # Uruchomienie audytora
        final_run_state['langgraph_log'] = langgraph_log
        meta_auditor_node(final_run_state)

        print("\n\n--- ZAKO≈ÉCZONO PRACƒò GRAFU I AUDYT ---")
    else:
        print("Proces zako≈Ñczony. Brak planu do wykonania.")
# --- Koniec kom√≥rki ---



--- FILE: prompts.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import json
import re

class AutoGen_Agents_Propmpt:
    
    @staticmethod
    def Trigger_prompt() -> str:
        
        return f"""Jeste≈õ 'Stra≈ºnikiem Danych'. Twoim jedynym zadaniem jest analiza podsumowania danych (nazwy kolumn, pierwsze wiersze).
Na tej podstawie musisz podjƒÖƒá decyzjƒô: czy te dane majƒÖ charakter **tabularyczny** (jak plik CSV lub tabela bazy danych)?
- Je≈õli TAK: odpowiedz **tylko i wy≈ÇƒÖcznie**: 'Dane sƒÖ tabularyczne. Przekazujƒô do PlannerAgent w celu stworzenia planu analizy.'. Nie dodawaj nic wiƒôcej.
- Je≈õli NIE (np. sƒÖ to logi serwera, obrazy, czysty tekst): Twoja wiadomo≈õƒá MUSI ko≈Ñczyƒá siƒô s≈Çowem 'TERMINATE'. Wyja≈õnij kr√≥tko, dlaczego dane nie sƒÖ tabularyczne, np. 
'Dane nie sƒÖ tabularyczne, to zbi√≥r artyku≈Ç√≥w tekstowych. TERMINATE'. """
    
    
    @staticmethod
    def Planner_prompt()->str:
        
        return f"""Jeste≈õ 'Architektem Planu'. Otrzyma≈Çe≈õ potwierdzenie, ≈ºe dane sƒÖ tabularyczne.
Twoim zadaniem jest stworzenie szczeg√≥≈Çowego, numerowanego planu czyszczenia i przygotowania danych do og√≥lnej analizy i modelowania. Plan musi byƒá praktyczny i zgodny z najlepszymi praktykami.
Twoje zadanie sk≈Çada siƒô z dw√≥ch czƒô≈õci:
1.  **Analiza Inspiracji:** Je≈õli w wiadomo≈õci od u≈ºytkownika znajduje siƒô sekcja '--- INSPIRACJE Z POPRZEDNICH URUCHOMIE≈É ---', 
potraktuj jƒÖ jako cennƒÖ inspiracjƒô i punkt wyj≈õcia. Zawiera ona sprawdzonƒÖ strategiƒô ("z≈ÇotƒÖ my≈õl") i mo≈ºe r√≥wnie≈º zawieraƒá konkretne kroki. Twoim zadaniem jest **krytyczna adaptacja** tego planu. 
**Sprawd≈∫, czy ka≈ºdy krok z inspiracji ma sens w kontek≈õcie AKTUALNEGO podglƒÖdu danych.** Mo≈ºesz usunƒÖƒá, dodaƒá lub zmodyfikowaƒá kroki, aby idealnie pasowa≈Çy do obecnego problemu.
2.  **Tworzenie Planu:** Je≈õli nie ma inspiracji, stw√≥rz nowy, solidny plan od podstaw.
Plan powinien zawieraƒá kroki takie jak:
1.  Weryfikacja i obs≈Çuga brakujƒÖcych warto≈õci (np. strategia imputacji dla ka≈ºdej istotnej kolumny).
2.  Weryfikacja i korekta typ√≥w danych (np. konwersja string√≥w na daty lub liczby).
3.  In≈ºynieria cech (np. tworzenie nowych, u≈ºytecznych kolumn jak 'dzien_tygodnia' z daty lub kategoryzacja warto≈õci liczbowych).
4.  Wykrywanie i obs≈Çuga warto≈õci odstajƒÖcych (outlier√≥w).
5.  Normalizacja lub skalowanie danych (je≈õli to konieczne, wyja≈õnij kr√≥tko dlaczego).

Po przedstawieniu pierwszej wersji planu, oczekuj na recenzjƒô od CriticAgenta.
- Je≈õli CriticAgent prze≈õle uwagi, stw√≥rz **NOWƒÑ, KOMPLETNƒÑ WERSJƒò** planu, kt√≥ra uwzglƒôdnia **WSZYSTKIE** jego sugestie.
- W poprawionym planie zaznacz, co zosta≈Ço zmienione. Prze≈õlij zaktualizowany plan z powrotem do CriticAgenta.
Kontynuuj ten proces, a≈º CriticAgent ostatecznie zaakceptuje Tw√≥j plan. """
    
    
    @staticmethod
    def Critic_prompt() ->str:
        
        return f"""Jeste≈õ 'Recenzentem Jako≈õci'. Twoim zadaniem jest konstruktywna krytyka planu od PlannerAgenta. Oce≈Ñ go pod kƒÖtem praktyczno≈õci, realizmu i efektywno≈õci.
Twoje Z≈Çote Zasady:
1.  **PROSTOTA JEST KLUCZEM:** Agresywnie kwestionuj nadmiernie skomplikowane kroki. Czy naprawdƒô potrzebujemy KNNImputer, gdy prosta mediana wystarczy?
2.  **JEDNA ZMIANA NA RAZ:** Je≈õli plan proponuje stworzenie kilku z≈Ço≈ºonych cech w jednym kroku, odrzuƒá to. Zarekomenduj podzielenie tego na osobne, ≈Çatwiejsze do weryfikacji kroki. 
Plan musi byƒá odporny na b≈Çƒôdy.
3.  **KONKRETNE SUGESTIE:** Zawsze podawaj konkretnƒÖ alternatywƒô. Zamiast 'To jest z≈Çe', napisz 'Krok X jest nieoptymalny. Sugerujƒô Y, poniewa≈º Z.'

**PROCES ZATWIERDZANIA (KRYTYCZNIE WA≈ªNE):**
- Je≈õli plan wymaga jakichkolwiek poprawek, jasno je opisz i ode≈õlij do PlannerAgenta. **NIE U≈ªYWAJ** poni≈ºszych fraz kluczowych.
- Je≈õli plan jest **doskona≈Çy** i nie wymaga ≈ºadnych zmian, Twoja odpowied≈∫ **MUSI** mieƒá nastƒôpujƒÖcƒÖ, ≈õcis≈ÇƒÖ strukturƒô:
Najpierw napisz liniƒô:
`OSTATECZNY PLAN:`
Poni≈ºej wklej **CA≈ÅY, KOMPLETNY** plan od PlannerAgenta.
Na samym ko≈Ñcu wiadomo≈õci dodaj frazƒô:
`PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI` """
    
    
    
class Langchain_Agents_prompts:
    
    
    @staticmethod
    def code_generator(plan: str, available_columns: List[str]) -> str:
        return f"""**Persona:** Ekspert In≈ºynierii Danych.\n**Plan Biznesowy:**\n{plan}\n
        **Dostƒôpne Kolumny:**\n{available_columns}\n{ArchitecturalRulesManager.get_rules_as_string()}\n
        **Zadanie:** Napisz kompletny skrypt Pythona realizujƒÖcy plan, przestrzegajƒÖc wszystkich zasad. Odpowied≈∫ musi zawieraƒá tylko i wy≈ÇƒÖcznie blok kodu ```python ... ```."""
    
    @staticmethod
    def tool_based_debugger() -> str:
        return """Jeste≈õ 'G≈Ç√≥wnym In≈ºynierem Jako≈õci Kodu'. Twoim zadaniem jest nie tylko naprawienie zg≈Çoszonego b≈Çƒôdu, ale zapewnienie, ≈ºe kod bƒôdzie dzia≈Ça≈Ç poprawnie.
- Je≈õli b≈ÇƒÖd to `ModuleNotFoundError`, u≈ºyj `request_package_installation`.
- Je≈õli b≈ÇƒÖd to `ImportError` wskazujƒÖcy na konflikt wersji, r√≥wnie≈º u≈ºyj `request_package_installation`, aby zasugerowaƒá aktualizacjƒô pakietu, kt√≥ry jest ≈∫r√≥d≈Çem b≈Çƒôdu.
- Dla wszystkich innych b≈Çƒôd√≥w w kodzie (np. `SyntaxError`, `KeyError`), u≈ºyj `propose_code_fix` a nastƒôpnie przeanalizuj poni≈ºszy b≈ÇƒÖd i wadliwy kod. Twoja praca sk≈Çada siƒô z dw√≥ch krok√≥w:
1.  **Analiza i Naprawa:** Zidentyfikuj przyczynƒô b≈Çƒôdu i stw√≥rz kompletnƒÖ, poprawionƒÖ wersjƒô ca≈Çego skryptu.
2.  **Wywo≈Çanie Narzƒôdzia:** Wywo≈Çaj narzƒôdzie `propose_code_fix`, podajƒÖc **OBOWIƒÑZKOWO** dwa argumenty: `analysis` (twoja analiza) oraz `corrected_code` (pe≈Çny, naprawiony kod).
Przeanalizuj poni≈ºszy b≈ÇƒÖd i wadliwy kod. """

    @staticmethod
    def create_reporting_prompt(plan: str, original_summary: str, processed_summary: str) -> str:
        return f'''
**Persona:** Jeste≈õ G≈Ç√≥wnym Analitykiem Danych. Twoim zadaniem jest stworzenie kompleksowego, wizualnego raportu, kt√≥ry krok po kroku opowie historiƒô transformacji danych. Masz pe≈ÇnƒÖ swobodƒô w doborze najlepszych wizualizacji.

**G≈Ç√≥wny Cel Biznesowy:** Udowodnij warto≈õƒá przeprowadzonego procesu czyszczenia i przygotowania danych. Poka≈º, "co by≈Ço przed" i "co jest po" dla ka≈ºdego istotnego kroku.

**Plan Transformacji (Tw√≥j Scenariusz):**
Oto plan, kt√≥ry zosta≈Ç zrealizowany. Twoim zadaniem jest zilustrowanie ka≈ºdego z tych punkt√≥w.
{plan}


**Dostƒôpne Dane:**
W ≈õrodowisku wykonawczym dostƒôpne bƒôdƒÖ pe≈Çne ramki danych: `df_original` i `df_processed`. Mo≈ºesz na nich operowaƒá. U≈ºyj te≈º poni≈ºszych podsumowa≈Ñ do wstƒôpnej analizy.
{original_summary}
{processed_summary}

**Twoje Zadanie (Szczeg√≥≈Çowe Wytyczne):**
Napisz kompletny i samodzielny fragment kodu w Pythonie, kt√≥ry wygeneruje dwie kluczowe zmienne: `summary_text` (HTML) oraz `figures_to_embed` (lista figur Matplotlib).

1.  **Stw√≥rz `summary_text`:** Napisz zwiƒôz≈Çe, mened≈ºerskie podsumowanie w HTML, kt√≥re podkre≈õla kluczowe korzy≈õci z transformacji.
2.  **Stw√≥rz pustƒÖ listƒô `figures_to_embed`**.
3.  **Przejd≈∫ przez KA≈ªDY krok z powy≈ºszego planu:**
    * Dla ka≈ºdego kroku (np. "Obs≈Çuga brakujƒÖcych warto≈õci", "In≈ºynieria cech czasowych", "Obs≈Çuga outlier√≥w") stw√≥rz jednƒÖ lub wiƒôcej wizualizacji, kt√≥re najlepiej go ilustrujƒÖ.
    * **Przyk≈Çadowe inspiracje:**
        * **BrakujƒÖce warto≈õci:** Wykres s≈Çupkowy pokazujƒÖcy liczbƒô brak√≥w przed i po imputacji.
        * **In≈ºynieria cech:** Histogram nowej cechy (np. `Godzina_transakcji`).
        * **Warto≈õci odstajƒÖce:** Boxploty dla kluczowych kolumn przed i po winsoryzacji.
        * **Korekta typ√≥w danych:** Nie wymaga wizualizacji, mo≈ºesz to pominƒÖƒá.
    * Ka≈ºdy wykres musi mieƒá profesjonalny wyglƒÖd: tytu≈Ç, opisane osie, legendƒô.
    * **Przed dodaniem figury do listy, wywo≈Çaj na niej `fig.tight_layout()`**, aby upewniƒá siƒô, ≈ºe wszystkie elementy (tytu≈Çy, osie) mieszczƒÖ siƒô w zapisywanym obrazie.
    * **DODAJ obiekt wygenerowanej figury do listy `figures_to_embed`**.

**Krytyczne Ograniczenia:**
- Twoja odpowied≈∫ to **tylko i wy≈ÇƒÖcznie** kod Pythona.
- NIE PISZ import√≥w, definicji funkcji, `plt.show()` ani kodu do zapisu plik√≥w.

Zacznij dzia≈Çaƒá, Analityku! Poka≈º nam historiƒô ukrytƒÖ w danych.
'''

    @staticmethod
    def create_meta_auditor_prompt(source_code: str, autogen_conversation: str, langgraph_log: str, final_code: str, final_report: str) -> str:
        return f"""**Persona:** G≈Ç√≥wny Audytor System√≥w AI. Twoim zadaniem jest krytyczna ocena ca≈Çego procesu AI.
**Dostƒôpne Dane do Analizy:**
1. KOD ≈πR√ìD≈ÅOWY SYSTEMU:\n```python\n{source_code}\n```
2. ZAPIS ROZMOWY (PLANOWANIE):\n```\n{autogen_conversation}\n```
3. LOGI (WYKONANIE):\n```\n{langgraph_log}\n```
4. FINALNY KOD:\n```python\n{final_code}\n```
5. FINALNY RAPORT (fragment):\n```html\n{final_report[:2000]}\n```
**Zadania Audytorskie (odpowiedz na ka≈ºde pytanie):**
1. **Ocena Planowania:** Czy dyskusja Planner-Krytyk by≈Ça efektywna? Czy Krytyk by≈Ç rygorystyczny?
2. **Ocena Wykonania:** Czy by≈Çy pƒôtle naprawcze? Jak skuteczny by≈Ç debugger?
3. **Ocena Produktu:** Czy raport HTML jest u≈ºyteczny?
4. **Ocena Prompt√≥w Agent√≥w (Analiza Meta):**
    - Na podstawie analizy log√≥w i kodu ≈∫r√≥d≈Çowego, oce≈Ñ jako≈õƒá i precyzjƒô prompt√≥w dla poszczeg√≥lnych agent√≥w (Planner, Krytyk, Debugger, Generator Raportu).
    - Czy kt√≥ry≈õ z zaobserwowanych problem√≥w (nawet tych naprawionych) m√≥g≈Ç wynikaƒá z niejasno≈õci w prompcie?
    - Czy widzisz mo≈ºliwo≈õƒá ulepszenia kt√≥rego≈õ z prompt√≥w, aby system dzia≈Ça≈Ç bardziej niezawodnie lub efektywnie w przysz≈Ço≈õci?
5. **Rekomendacje do Samodoskonalenia:** Zaproponuj 1-3 konkretne zmiany w kodzie lub promptach, kt√≥re usprawniƒÖ system.
**Format Wyj≈õciowy:** Zwiƒôz≈Çy raport tekstowy."""
    
    
class ArchitecturalRule(TypedDict):
    id: str; description: str; check: Callable[[str], bool]; error_message: str

ARCHITECTURAL_RULES: List[ArchitecturalRule] = [
    {"id": "NO_MAIN_BLOCK", "description": "≈ªadnego bloku `if __name__ == '__main__':`.", "check": lambda code: bool(re.search(r'if\s+__name__\s*==\s*["\']__main__["\']\s*:', code)), "error_message": "Wykryto niedozwolony blok `if __name__ == '__main__':`."},
    {"id": "NO_ARGPARSE", "description": "≈ªadnego `argparse` ani `sys.argv`.", "check": lambda code: bool(re.search(r'import\s+argparse', code)), "error_message": "Wykryto niedozwolony import modu≈Çu `argparse`."},
    {"id": "SINGLE_FUNCTION_LOGIC", "description": "Ca≈Ça logika musi byƒá w funkcji `process_data(input_path: str, output_path: str)`.", "check": lambda code: "def process_data(input_path: str, output_path: str)" not in code, "error_message": "Brak wymaganej definicji funkcji `process_data(input_path: str, output_path: str)`."},
    {"id": "ENDS_WITH_CALL", "description": "Skrypt musi ko≈Ñczyƒá siƒô **dok≈Çadnie jednƒÖ liniƒÖ** w formacie: `process_data(input_path, output_path)  # noqa: F821`. Komentarz `# noqa: F821` jest **obowiƒÖzkowy**.", "check": lambda code: not re.search(r'^\s*process_data\(input_path,\s*output_path\)\s*#\s*noqa:\s*F821\s*$', [line for line in code.strip().split('\n') if line.strip()][-1]), "error_message": "Skrypt nie ko≈Ñczy siƒô wymaganym wywo≈Çaniem `process_data(input_path, output_path)  # noqa: F821`."},
]

class ArchitecturalRulesManager:
    @staticmethod
    def get_rules_as_string() -> str:
        rules_text = "\n".join(f"        - {rule['description']}" for rule in ARCHITECTURAL_RULES)
        return f"<ARCHITECTURAL_RULES>\n    **Krytyczne Wymagania DotyczƒÖce Struktury Kodu:**\n{rules_text}\n</ARCHITECTURAL_RULES>"


--- FILE: tools/__init__.py ---




--- FILE: tools/langchain_tools.py ---

from pydantic import BaseModel, Field
from langchain_core.tools import tool
#--BaseModel

class DebugReport(BaseModel):
    analysis: str = Field(description="Techniczna analiza b≈Çƒôdu.")
    corrected_code: str = Field(description="Kompletny, poprawiony kod.")

    
class GeneratedPythonScript(BaseModel):
    """
    Model przechowujƒÖcy kompletny i gotowy do wykonania skrypt w Pythonie.
    """
    script_code: str = Field(description="Kompletny kod w Pythonie, gotowy do bezpo≈õredniego wykonania. Musi zawieraƒá wszystkie niezbƒôdne elementy, takie jak definicje, logikƒô i zapis pliku.")    
    

class CodeFixArgs(BaseModel):
    analysis: str = Field(description="Techniczna analiza przyczyny b≈Çƒôdu i wprowadzonej poprawki w kodzie.")
    corrected_code: str = Field(description="Pe≈Çny, kompletny i POPRAWIONY skrypt w Pythonie. Musi byƒá gotowy do wykonania.")
    
class PackageInstallArgs(BaseModel):
    package_name: str = Field(description="Nazwa pakietu, kt√≥ry nale≈ºy zainstalowaƒá, aby rozwiƒÖzaƒá b≈ÇƒÖd 'ModuleNotFoundError'. Np. 'scikit-learn', 'seaborn'.")
    analysis: str = Field(description="Kr√≥tka analiza potwierdzajƒÖca, ≈ºe przyczynƒÖ b≈Çƒôdu jest brakujƒÖcy pakiet.")
    
    
#narzƒôdzia dla langchain agent√≥w    
@tool(args_schema=CodeFixArgs)
def propose_code_fix(analysis: str, corrected_code: str) -> None:
    """U≈ºyj tego narzƒôdzia, aby zaproponowaƒá poprawionƒÖ wersjƒô kodu w odpowiedzi na b≈ÇƒÖd sk≈Çadniowy lub logiczny."""
    pass

@tool(args_schema=PackageInstallArgs)
def request_package_installation(package_name: str, analysis: str) -> None:
    """U≈ºyj tego narzƒôdzia, aby poprosiƒá o instalacjƒô brakujƒÖcej biblioteki, gdy napotkasz b≈ÇƒÖd 'ModuleNotFoundError'."""
    pass 


--- FILE: tools/utils.py ---

import os
import io
import sys
import subprocess
import tempfile
import traceback
import uuid
import json
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import datetime
import logging


def extract_python_code(response: str) -> str:
    response = response.strip()
    match = re.search(r'```python\n(.*?)\n```', response, re.DOTALL)
    if match: return match.group(1).strip()
    if response.startswith("'''") and response.endswith("'''"): return response[3:-3].strip()
    if response.startswith('"""') and response.endswith('"""'): return response[3:-3].strip()
    return response


def install_package(package_name: str, upgrade: bool = True) -> bool:
    """
    Instaluje lub aktualizuje podany pakiet u≈ºywajƒÖc pip.
    
    Args:
        package_name (str): Nazwa pakietu do instalacji.
        upgrade (bool): Je≈õli True, u≈ºywa flagi --upgrade.
    """
    try:
        command = [sys.executable, "-m", "pip", "install", package_name]
        if upgrade:
            command.insert(2, "--upgrade")
        
        action = "Aktualizacja" if upgrade else "Instalacja"
        print(f"  [INSTALATOR] Pr√≥ba: {action} pakietu {package_name}...")
        
        result = subprocess.run(command, check=True, capture_output=True, text=True)
        print(f"  [INSTALATOR] Pomy≈õlnie zako≈Ñczono. Logi pip:\n{result.stdout}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"  [INSTALATOR] B≈ÇƒÖd podczas operacji na pakiecie {package_name}.\n{e.stderr}")
        return False
    

    
#DLA report agenta
def embed_plot_to_html(figure) -> str:
    """Konwertuje figurƒô matplotlib do stringa base64 do osadzenia w HTML."""
    buffer = io.BytesIO()
    figure.savefig(buffer, format='png', bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    graphic = base64.b64encode(image_png)
    graphic = graphic.decode('utf-8')
    plt.close(figure) # Wa≈ºne: zamykamy figurƒô
    return f'<img src="data:image/png;base64,{graphic}" alt="Wykres analizy danych"/>'



#Dla meta agenta
def read_source_code(file_path: str) -> str:
    """Odczytuje zawarto≈õƒá pliku kodu ≈∫r√≥d≈Çowego."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f: return f.read()
    except Exception as e: return f"Nie uda≈Ço siƒô odczytaƒá kodu ≈∫r√≥d≈Çowego: {e}"




#Zapis planowania preprocessingu- AutoGen
def save_autogen_conversation_log(log_content: str, file_path: str):
    """Zapisuje pe≈ÇnƒÖ tre≈õƒá konwersacji agent√≥w AutoGen do pliku tekstowego."""
    print(f"INFO: Pr√≥ba zapisu pe≈Çnego logu rozmowy do pliku: {file_path}")
    try:
        # Upewniamy siƒô, ≈ºe katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PE≈ÅNY ZAPIS ROZMOWY AGENT√ìW (FAZA PLANOWANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"‚úÖ SUKCES: Log rozmowy zosta≈Ç pomy≈õlnie zapisany.")
    except Exception as e:
        print(f"‚ùå B≈ÅƒÑD: Nie uda≈Ço siƒô zapisaƒá logu rozmowy. Przyczyna: {e}")


        
#Zapis rozmowy agentow wykonowczych- LangChain        
def save_langgraph_execution_log(log_content: str, file_path: str):
    """Zapisuje pe≈Çny, szczeg√≥≈Çowy log z wykonania grafu LangGraph do pliku."""
    print(f"INFO: Pr√≥ba zapisu pe≈Çnego logu wykonania LangGraph do pliku: {file_path}")
    try:
        # Upewniamy siƒô, ≈ºe katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PE≈ÅNY ZAPIS WYKONANIA GRAFU LANGGRAPH (FAZA WYKONANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"‚úÖ SUKCES: Log wykonania LangGraph zosta≈Ç pomy≈õlnie zapisany.")
    except Exception as e:
        print(f"‚ùå B≈ÅƒÑD: Nie uda≈Ço siƒô zapisaƒá logu LangGraph. Przyczyna: {e}")       


--- FILE: agents/__init__.py ---




--- FILE: agents/autogen_agent_utils.py ---

import pandas as pd
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
from .autogen_agents import TriggerAgent,PlannerAgent,CriticAgent
import autogen
from autogen import Agent, ConversableAgent
from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent





#FUNKCJA CHATU GRUPOWEGO-WYMY≈öLANIE PLANU
def run_autogen_planning_phase(input_path: str,trigger_agent: TriggerAgent,planner_agent: PlannerAgent, critic_agent: CriticAgent, manager_agent_config:Dict,inspiration_prompt: str = "") -> Optional[str]:
    """
    Uruchamia fazƒô planowania z agentami AutoGen i zwraca finalny plan.
    """
    print("\n" + "="*80)
    print("### ### FAZA 1: URUCHAMIANIE PLANOWANIA STRATEGICZNEGO (AutoGen) ### ###")
    print("="*80 + "\n")

    try:
        df_summary = pd.read_csv(input_path, nrows=5)
        data_preview = f"Oto podglƒÖd danych:\n\nKolumny:\n{df_summary.columns.tolist()}\n\nPierwsze 5 wierszy:\n{df_summary.to_string()}"
        
        if inspiration_prompt:
            print("INFO: Do≈ÇƒÖczam inspiracje z pamiƒôci do fazy planowania.")
            data_preview += "\n\n" + inspiration_prompt
        
    except Exception as e:
        logging.error(f"Nie mo≈ºna wczytaƒá pliku wej≈õciowego {input_path}: {e}")
        return None
    
    
    
    user_proxy = autogen.UserProxyAgent(
       name="UserProxy",
       human_input_mode="NEVER",
       max_consecutive_auto_reply=10,
       is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
       code_execution_config=False,
       system_message="ZarzƒÖdzasz procesem. Przeka≈º podglƒÖd danych do TriggerAgenta, a nastƒôpnie moderuj dyskusjƒô miƒôdzy Plannerem a Krytykiem. Je≈õli w wiadomo≈õci sƒÖ inspiracje z przesz≈Ço≈õci, przeka≈º je Plannerowi."
    )

    def custom_speaker_selection_func(last_speaker: Agent, groupchat: autogen.GroupChat):
        messages = groupchat.messages

        # Warunek poczƒÖtkowy, pierwszy m√≥wi TriggerAgent
        if len(messages) <= 1:
            return trigger_agent

        # Standardowy przep≈Çyw: Trigger -> Planner -> Critic -> Planner ...
        elif last_speaker is trigger_agent:
            return planner_agent
        elif last_speaker is planner_agent:
            return critic_agent
        elif last_speaker is critic_agent:

            if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in messages[-1]['content']:
                return None # To elegancko ko≈Ñczy rozmowƒô
            else:
                # Je≈õli nie, wracamy do Plannera z uwagami
                return planner_agent
        else:
            # Sytuacja awaryjna lub koniec, nie wybieraj nikogo
            return None

    groupchat = autogen.GroupChat(
        agents=[user_proxy, trigger_agent, planner_agent, critic_agent],
        messages=[],
        max_round=15,
        speaker_selection_method=custom_speaker_selection_func
    )
    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=manager_agent_config)

    user_proxy.initiate_chat(manager, message=data_preview)

    # Ekstrakcja finalnego planu
    final_plan = None
    critic_messages = [msg['content'] for msg in groupchat.messages if msg['name'] == 'CriticAgent']
    for msg in reversed(critic_messages):
        if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in msg:
            match = re.search(r"OSTATECZNY PLAN:(.*)PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI", msg, re.DOTALL)
            if match:
                final_plan = match.group(1).strip()
                print("Faza planowania zako≈Ñczona. Ostateczny plan zosta≈Ç zaakceptowany.")
                break
    
    if not final_plan:
        print(" Faza planowania zako≈Ñczona bez akceptacji planu lub z powodu TERMINATE.")

    
    full_conversation_log = "\n\n".join([f"--- Komunikat od: {msg['name']} ---\n{msg['content']}" for msg in groupchat.messages])

    
    return final_plan, full_conversation_log



--- FILE: agents/autogen_agents.py ---

import autogen
from autogen import Agent, ConversableAgent


class TriggerAgent(ConversableAgent):
    """Agent decydujƒÖcy, czy dane nadajƒÖ siƒô do dalszego przetwarzania."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="TriggerAgent",
            llm_config=llm_config,
            system_message=prompt
        )

#PLANNER AGENT        
class PlannerAgent(ConversableAgent):
    """Agent tworzƒÖcy szczeg√≥≈Çowy plan przygotowania danych."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="PlannerAgent",
            llm_config=llm_config,
            system_message=prompt
        )

#CRITIC AGENT
class CriticAgent(ConversableAgent):
    """Agent oceniajƒÖcy plan i dbajƒÖcy o jego jako≈õƒá."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="CriticAgent",
            llm_config=llm_config,
            system_message=prompt
        )
        
        
        



--- FILE: agents/langgraph_nodes.py ---

import os
import io
import sys
import subprocess
import tempfile
import traceback
import uuid
import json
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import langchain
from langchain_google_vertexai import ChatVertexAI
from langchain_anthropic import ChatAnthropic
from .state import AgentWorkflowState
from prompts import Langchain_Agents_prompts
from tools.utils import *
from tools.langchain_tools import *
from prompts import ArchitecturalRule, ArchitecturalRulesManager,ARCHITECTURAL_RULES
from config import MAX_CORRECTION_ATTEMPTS, PROJECT_ID,LOCATION
# --- Definicje wƒôz≈Ç√≥w LangGraph ---

def schema_reader_node(state: AgentWorkflowState):
    print("--- WƒòZE≈Å: ANALIZATOR SCHEMATU DANYCH ---")
    print(f"DEBUG: Pr√≥bujƒô odczytaƒá plik ze ≈õcie≈ºki: {state.get('input_path')}")
    try:
        df_header = pd.read_csv(state['input_path'], nrows=0)
        
        #pamiƒôƒá d≈Çugotrwa≈Ça, tworzenie sygnatury
        memory_client = state['memory_client']
        dataset_signature = memory_client.create_dataset_signature(df_header)
        print(f"INFO: Wygenerowano sygnaturƒô danych: {dataset_signature}")
        #--koniec--
        
        return {"available_columns": df_header.columns.tolist(),"dataset_signature": dataset_signature}
    except Exception as e:
        return {"error_message": f"B≈ÇƒÖd odczytu pliku: {e}", "failing_node": "schema_reader"}

def code_generator_node(state: AgentWorkflowState):
    print("---  WƒòZE≈Å: GENERATOR KODU ---")
    
    
    CODE_MODEL=state['config']['CODE_MODEL']
    
    llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    prompt = Langchain_Agents_prompts.code_generator(state['plan'], state['available_columns'])
    response = llm.invoke(prompt).content
    code = extract_python_code(response)
    
    print("\nAgent-Analityk wygenerowa≈Ç nastƒôpujƒÖcy kod:")
    print("--------------------------------------------------")
    print(code)
    print("--------------------------------------------------")
    return {"generated_code": code}


def architectural_validator_node(state: AgentWorkflowState):
    print("--- üõ°Ô∏è WƒòZE≈Å: STRA≈ªNIK ARCHITEKTURY üõ°Ô∏è ---")
    code_to_check = state.get('generated_code', '')
    if not code_to_check:
        error_message = "Brak kodu do walidacji."
        print(f"  [WERDYKT] ‚ùå {error_message}")
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": "", "correction_attempts": state.get('correction_attempts', 0) + 1}

    errors = [rule["error_message"] for rule in ARCHITECTURAL_RULES if rule["check"](code_to_check)]
    
    if errors:
        error_message = "B≈ÇƒÖd Walidacji Architektonicznej: " + " ".join(errors)
        # <<< WA≈ªNY PRINT >>>
        print(f"  [WERDYKT] ‚ùå Kod ≈Çamie zasady architektury: {' '.join(errors)}")
        
        pending_session = {
            "initial_error": error_message,  # U≈ºywamy b≈Çƒôdu walidacji jako b≈Çƒôdu poczƒÖtkowego
            "initial_code": code_to_check,
            "fix_attempts": []
        }
        
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": code_to_check, "correction_attempts": state.get('correction_attempts', 0) + 1}
    else:
        # <<< WA≈ªNY PRINT >>>
        print("  [WERDYKT] Kod jest zgodny z architekturƒÖ systemu.")
        return {"error_message": None, "pending_fix_session": None}

    
def data_code_executor_node(state: AgentWorkflowState):
    """
    Wykonuje finalny kod do przetwarzania danych.
    """
    print("--- WƒòZE≈Å: WYKONANIE KODU DANYCH  ---")
    try:
        print("  [INFO] Uruchamiam ostatecznie zatwierdzony kod...")
        
        # Definiujemy ≈õrodowisko wykonawcze tylko z niezbƒôdnymi bibliotekami
        exec_scope = {
            'pd': pd,
            'input_path': state['input_path'],
            'output_path': state['output_path']
        }
        
        exec(state['generated_code'], exec_scope)
        
        print("  [WYNIK] Kod wykonany pomy≈õlnie.")
        return {"error_message": None, "correction_attempts": 0}
        
    except Exception as e:
        error_traceback = traceback.format_exc()
        print(f"  [B≈ÅƒÑD] WystƒÖpi≈Ç b≈ÇƒÖd. Przekazywanie do inteligentnego debuggera:\n{error_traceback}")
        
        #--pamiƒôƒá d≈Çugotrwa≈Ça: zapis b≈Çƒôdu, sesja tymczasowa
        
        pending_session = {
            "initial_error": error_traceback,
            "initial_code": state['generated_code'],
            "fix_attempts": []  # Pusta lista na przysz≈Çe pr√≥by naprawy
        }
        #--koniec--
        
        return {
            "failing_node": "data_code_executor", 
            "error_message": error_traceback, 
            "error_context_code": state['generated_code'], 
            "correction_attempts": state.get('correction_attempts', 0) + 1,
            "pending_fix_session": pending_session
        }

    
def universal_debugger_node(state: AgentWorkflowState):
    print(f"--- WƒòZE≈Å: INTELIGENTNY DEBUGGER (B≈ÇƒÖd w: {state.get('failing_node')}) ---")
    MAIN_AGENT=state['config']['MAIN_AGENT']
    # llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    llm = ChatVertexAI(model_name=MAIN_AGENT,temperature=0.0, project=PROJECT_ID, location=LOCATION)
    tools = [propose_code_fix, request_package_installation]
    llm_with_tools = llm.bind_tools(tools)
    prompt = Langchain_Agents_prompts.tool_based_debugger()
    error_context = f"Wadliwy Kod:\n```python\n{state['error_context_code']}\n```\n\nB≈ÇƒÖd:\n```\n{state['error_message']}\n```"
    response = llm_with_tools.invoke(prompt + error_context)
    if not response.tool_calls:
        print("  [B≈ÅƒÑD DEBUGGERA] Agent nie wybra≈Ç ≈ºadnego narzƒôdzia. Eskalacja.")
        return {"error_message": "Debugger nie by≈Ç w stanie podjƒÖƒá decyzji.", "failing_node": "universal_debugger"}
    chosen_tool = response.tool_calls[0]
    tool_name = chosen_tool['name']
    tool_args = chosen_tool['args']
    print(f"  [DIAGNOZA] Debugger wybra≈Ç narzƒôdzie: '{tool_name}' z argumentami: {tool_args}")
    return {"tool_choice": tool_name, "tool_args": tool_args, "debugger_analysis": tool_args.get("analysis", "")}


def apply_code_fix_node(state: AgentWorkflowState):
    """Aplikuje poprawkƒô kodu zaproponowanƒÖ przez debuggera."""
    print("--- WƒòZE≈Å: APLIKOWANIE POPRAWKI KODU ---")
    
    CODE_MODEL=state['config']['CODE_MODEL']
    
    analysis = state.get("debugger_analysis", "")
    corrected_code = state.get("tool_args", {}).get("corrected_code")
    
    if not corrected_code:
        print("  [OSTRZE≈ªENIE] Debugger nie dostarczy≈Ç kodu. Wymuszam jego wygenerowanie...")
        
        # Tworzymy bardzo prosty prompt, kt√≥ry ma tylko jedno zadanie
        force_prompt = f"""Na podstawie poni≈ºszej analizy i wadliwego kodu, wygeneruj PE≈ÅNY, POPRAWIONY i gotowy do uruchomienia skrypt Pythona.
        Twoja odpowied≈∫ musi zawieraƒá TYLKO i WY≈ÅƒÑCZNIE blok kodu, bez ≈ºadnych dodatkowych wyja≈õnie≈Ñ.

        [ANALIZA B≈ÅƒòDU]:
        {analysis}

        [WADLIWY KOD]:
        ```python
        {state['error_context_code']}"""
        
        
        try:
            llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
            response = llm.invoke(force_prompt).content
            corrected_code = extract_python_code(response) # U≈ºywamy istniejƒÖcej funkcji pomocniczej
            print("  [INFO] Pomy≈õlnie wymuszono wygenerowanie kodu.")
        except Exception as e:
            print(f"  [B≈ÅƒÑD KRYTYCZNY] Nie uda≈Ço siƒô wymusiƒá generacji kodu: {e}")
            return {"error_message": "Nie uda≈Ço siƒô naprawiƒá kodu nawet po eskalacji."}
        
        
    #--pamiƒôƒá d≈Çugotrwa≈Ça info dla pamieci--
    
    
    session = state.get('pending_fix_session')
    if not session:
        # Sytuacja awaryjna, nie powinno siƒô zdarzyƒá w normalnym przep≈Çywie
        print("  [OSTRZE≈ªENIE] Pr√≥ba aplikacji poprawki bez aktywnej sesji naprawczej.")
        session = {}

    # Dodajemy informacje o tej konkretnej pr√≥bie do listy w sesji
    attempt_info = {
        "debugger_analysis": state.get("debugger_analysis", "Brak analizy."),
        "corrected_code": corrected_code,
        "attempt_number": len(session.get("fix_attempts", [])) + 1
    }
    
    if "fix_attempts" in session:
        session["fix_attempts"].append(attempt_info)
    else:
        session["fix_attempts"] = [attempt_info]
    
    print(f"  [INFO] Dodano pr√≥bƒô naprawy nr {attempt_info['attempt_number']} do sesji.")
    
    
    #--koniec--
    
    return {
        "generated_code": corrected_code, 
        "error_message": None, 
        "tool_choice": None, 
        "tool_args": None,
        "pending_fix_session": session  # Aktualizujemy sesjƒô w stanie
    }


def human_approval_node(state: AgentWorkflowState):
    print("\n" + "="*80 + "\n### WYMAGANA AKCJA CZ≈ÅOWIEKA  ###\n" + "="*80)
    package_name = state.get("tool_args", {}).get("package_name")
    user_input = input(f"Agent chce zainstalowaƒá pakiet '{package_name}'. Czy zgadzasz siƒô? [y/n]: ").lower().strip()
    if user_input == 'y':
        print("Zgoda. Przechodzenie do instalacji.")
        return {"user_approval_status": "APPROVED", "package_to_install": package_name}
    else:
        print("Odrzucono. Przekazywanie do debuggera w celu znalezienia alternatywy.")
        new_error_message = f"Instalacja pakietu '{package_name}' zosta≈Ça odrzucona przez u≈ºytkownika. Zmodyfikuj kod, aby nie u≈ºywa≈Ç tej zale≈ºno≈õci."
        return {"user_approval_status": "REJECTED", "error_message": new_error_message}


def package_installer_node(state: AgentWorkflowState):
    """Instaluje lub aktualizuje pakiet po uzyskaniu zgody."""
    package_name = state.get("package_to_install")
    
    # Domy≈õlnie pr√≥bujemy aktualizacji, bo to rozwiƒÖzuje problemy z zale≈ºno≈õciami
    success = install_package(package_name, upgrade=True)
    
    if success:
        return {"package_to_install": None, "user_approval_status": None, "error_message": None}
    else:
        return {"error_message": f"Operacja na pakiecie '{package_name}' nie powiod≈Ça siƒô.", "failing_node": "package_installer"}

def commit_memory_node(state: AgentWorkflowState) -> Dict[str, Any]:
    """Zapisuje skonsolidowanƒÖ wiedzƒô do pamiƒôci po udanej naprawie kodu."""
    session = state.get('pending_fix_session')
    
    # Je≈õli nie ma sesji (np. kod zadzia≈Ça≈Ç za 1. razem), nie r√≥b nic
    if not session or not session.get("fix_attempts"):
        return {"pending_fix_session": None}

    print("--- WƒòZE≈Å: ZATWIERDZANIE WIEDZY W PAMIƒòCI ---")
    
    distilled_content = distill_full_fix_session(
        initial_error=session['initial_error'],
        fix_attempts=session['fix_attempts'],
        successful_code=state['generated_code']
    )
    
    memory_client = state['memory_client']
    final_record = MemoryRecord(
        run_id=state['run_id'],
        memory_type=MemoryType.SUCCESSFUL_FIX, # Teraz to jest prawdziwy sukces
        dataset_signature=state['dataset_signature'],
        source_node="commit_memory_node",
        content=distilled_content,
        metadata={"total_attempts": len(session['fix_attempts'])}
    )
    memory_client.add_memory(final_record)
    
    # Wyczy≈õƒá sesjƒô po udanym zapisie
    return {"pending_fix_session": None} 

    
    
def reporting_agent_node(state: AgentWorkflowState):
    """
    Wczytuje dane wej≈õciowe i przetworzone, tworzy ich podsumowania statystyczne,
    a nastƒôpnie wywo≈Çuje agenta w celu wygenerowania kodu analitycznego.
    """
    print("\n--- WƒòZE≈Å: AGENT RAPORTUJƒÑCY (ANALIZA DANYCH I GENEROWANIE KODU) ---")
    
    try:
        
        CODE_MODEL=state['config']['CODE_MODEL']
        
        # --- NOWY KROK: Wczytanie i analiza danych ---
        print("  [INFO] Wczytywanie danych do analizy por√≥wnawczej...")
        df_original = pd.read_csv(state['input_path'])
        df_processed = pd.read_csv(state['output_path'])

        # Tworzenie zwiƒôz≈Çych podsumowa≈Ñ tekstowych dla LLM
        # U≈ºywamy io.StringIO, aby przechwyciƒá 'print' z df.info() do stringa
        original_info_buf = io.StringIO()
        df_original.info(buf=original_info_buf)
        
        processed_info_buf = io.StringIO()
        df_processed.info(buf=processed_info_buf)

        original_summary = f"""
### Podsumowanie danych ORYGINALNYCH ###
Pierwsze 3 wiersze:
{df_original.head(3).to_string()}

Informacje o kolumnach:
{original_info_buf.getvalue()}
Statystyki (dla kolumn numerycznych):
{df_original.describe().to_string()}
"""
        processed_summary = f"""
### Podsumowanie danych PRZETWORZONYCH ###
Pierwsze 3 wiersze:
{df_processed.head(3).to_string()}

Informacje o kolumnach:
{processed_info_buf.getvalue()}
Statystyki (dla kolumn numerycznych):
{df_processed.describe().to_string()}
"""
        print("  [INFO] Podsumowania danych wygenerowane.")
        # --- KONIEC NOWEGO KROKU ---

        # Krok 2: Utw√≥rz precyzyjny prompt z nowym kontekstem
        prompt = PromptTemplates.create_reporting_prompt(
            plan=state['plan'],
            original_summary=original_summary,
            processed_summary=processed_summary
        )
        
        # Krok 3: Wywo≈Çaj LLM (bez zmian)
        llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
        structured_llm = llm.with_structured_output(GeneratedPythonScript)
        response_object = structured_llm.invoke(prompt)
        report_analysis_code = response_object.script_code
        
        print("  [INFO] Agent-Analityk wygenerowa≈Ç kod analityczny na podstawie danych.")
        
        return {"generated_report_code": report_analysis_code}

    except Exception as e:
        print(f"  [B≈ÅƒÑD] Krytyczny b≈ÇƒÖd w agencie raportujƒÖcym: {traceback.format_exc()}")
        return {"generated_report_code": None}

def report_executor_node(state: AgentWorkflowState):
    """
    Wczytuje zewnƒôtrzny szablon HTML, wykonuje kod analityczny od agenta,
    a nastƒôpnie wstawia wyniki do szablonu, tworzƒÖc finalny raport.
    """
    print("--- WƒòZE≈Å: WYKONANIE KODU RAPORTU (Z ZEWNƒòTRZNEGO SZABLONU) ---")
    analysis_code = state.get("generated_report_code")
    
    if not analysis_code:
        return {"error_message": "Brak kodu analitycznego do wykonania.", "failing_node": "report_executor"}

    try:
        # Krok 1: Zbuduj kompletny, wykonywalny skrypt do wygenerowania "cia≈Ça" raportu
        # Ten skrypt zawiera wszystkie potrzebne importy i funkcje pomocnicze.
        body_script_to_execute = f"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import base64
from io import BytesIO

def embed_plot_to_html(figure):
    \"\"\"Konwertuje figurƒô matplotlib do stringa base64 do osadzenia w HTML.\"\"\"
    buffer = BytesIO()
    figure.savefig(buffer, format='png', bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    graphic = base64.b64encode(image_png)
    graphic = graphic.decode('utf-8')
    plt.close(figure)
    return f'<img src="data:image/png;base64,{{graphic}}" alt="Wykres analizy danych" style="max-width: 100%; height: auto;"/>'

# --- Kod wygenerowany przez agenta-analityka ---
{analysis_code}
# ---------------------------------------------

# Przygotowanie finalnego "cia≈Ça" HTML do wstawienia w szablon
html_body_content = ""
if 'summary_text' in locals():
    html_body_content += "<h2>Podsumowanie</h2>" + summary_text
if 'figures_to_embed' in locals() and isinstance(figures_to_embed, list):
    html_body_content += "<h2>Wizualizacje</h2>"
    for fig in figures_to_embed:
        html_body_content += embed_plot_to_html(fig)
"""
        # Krok 2: Przygotuj ≈õrodowisko i wykonaj powy≈ºszy skrypt, aby uzyskaƒá tre≈õƒá raportu
        print("  [INFO] Wykonywanie kodu analitycznego w celu wygenerowania tre≈õci raportu...")
        exec_scope = {
            'df_original': pd.read_csv(state['input_path']),
            'df_processed': pd.read_csv(state['output_path']),
        }
        exec(body_script_to_execute, exec_scope)
        generated_html_body = exec_scope['html_body_content']

        # Krok 3: Wczytaj zewnƒôtrzny szablon HTML
        print("  [INFO] Wczytywanie szablonu z pliku report_template.html...")
        with open("report_template.html", "r", encoding="utf-8") as f:
            template = f.read()

        # Krok 4: Wstaw wygenerowanƒÖ tre≈õƒá do szablonu i zapisz finalny raport
        final_html = template.format(generated_html_body=generated_html_body)
        with open(state['report_output_path'], 'w', encoding='utf-8') as f:
            f.write(final_html)

        print(f"  [INFO] Raport HTML zosta≈Ç pomy≈õlnie zapisany w: {state['report_output_path']}")
        return {"error_message": None} # Sukces

    except Exception:
        error_traceback = traceback.format_exc()
        print(f"  [B≈ÅƒÑD] WystƒÖpi≈Ç b≈ÇƒÖd podczas wykonywania skryptu raportu:\n{error_traceback}")
        # Przekazujemy do debuggera tylko ten fragment, kt√≥ry zawi√≥d≈Ç (kod od agenta)
        return {
            "failing_node": "report_executor", 
            "error_message": error_traceback, 
            "error_context_code": analysis_code, 
            "correction_attempts": state.get('correction_attempts', 0) + 1
        }

    
def sync_report_code_node(state: AgentWorkflowState):
    """Synchronizuje naprawiony kod z powrotem do stanu agenta raportujƒÖcego."""
    print("--- WƒòZE≈Å: SYNCHRONIZACJA KODU RAPORTU ---")
    corrected_code = state.get("generated_code")
    return {"generated_report_code": corrected_code}   
    
    
def meta_auditor_node(state: AgentWorkflowState):
    """Uruchamia audytora ORAZ zapisuje wspomnienia o sukcesie i wnioski META."""
    print("\n" + "="*80 + "\n### ### FAZA 3: META-AUDYT I KONSOLIDACJA WIEDZY ### ###\n" + "="*80 + "\n")
    memory_client = state['memory_client']

    # 1. Zapisz wspomnienie o udanym planie (je≈õli nie by≈Ço b≈Çƒôd√≥w)
    if state.get('plan') and not state.get('error_message'):
        distilled_content = distill_success_memory(final_plan=state['plan'])
        plan_record = MemoryRecord(
            run_id=state['run_id'], memory_type=MemoryType.SUCCESSFUL_PLAN,
            dataset_signature=state['dataset_signature'], source_node="meta_auditor_node",
            content=distilled_content, metadata={"importance_score": 0.8}
        )
        memory_client.add_memory(plan_record)
    
    # 2. Uruchom audytora (logika bez zmian)
    try:
        
        CRITIC_MODEL=state['config']['CRITIC_MODEL']
        
        # ... (ca≈Ça logika generowania raportu audytora, tak jak w oryginale)
        # Za≈Ç√≥≈ºmy, ≈ºe wynikiem jest zmienna 'audit_report'
        final_report_content = "Brak raportu do analizy."
        try:
            with open(state['report_output_path'], 'r', encoding='utf-8') as f:
                final_report_content = f.read()
        except Exception: pass
        
        llm = ChatAnthropic(model_name=CRITIC_MODEL, temperature=0.0, max_tokens=2048)
        prompt = Langchain_Agents_prompts.create_meta_auditor_prompt(
            source_code=state['source_code'], autogen_conversation=state['autogen_log'],
            langgraph_log=state['langgraph_log'], final_code=state.get('generated_code', 'Brak kodu'),
            final_report=final_report_content
        )
        audit_report = llm.invoke(prompt).content
        # ... (zapis raportu do pliku)

        # 3. WYGENERUJ I ZAPISZ WNIOSEK META
        meta_insight_content = generate_meta_insight(audit_report)
        if meta_insight_content:
            insight_record = MemoryRecord(
                run_id=state['run_id'], memory_type=MemoryType.META_INSIGHT,
                dataset_signature=state['dataset_signature'], source_node="meta_auditor_node",
                content=meta_insight_content, metadata={"importance_score": 1.0}
            )
            memory_client.add_memory(insight_record)

    except Exception as e:
        print(f"B≈ÅƒÑD KRYTYCZNY podczas meta-audytu: {e}")
    return {}

    
    
def human_escalation_node(state: AgentWorkflowState):
    """Wƒôze≈Ç eskalacji (bez zmian)."""
    print("\n==================================================")
    print(f"--- WƒòZE≈Å: ESKALACJA DO CZ≈ÅOWIEKA---")
    print("==================================================")
    # ... (reszta kodu bez zmian)
    report_content = f"""
Data: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Problem: Przekroczono maksymalny limit ({MAX_CORRECTION_ATTEMPTS}) pr√≥b automatycznej naprawy.

Ostatnia analiza debuggera:
{state.get('debugger_analysis', 'Brak analizy.')}

Ostatni kod, kt√≥ry zawi√≥d≈Ç:
```python
{state.get('error_context_code', 'Brak kodu.')}
```

Pe≈Çny traceback ostatniego b≈Çƒôdu:
{state.get('error_message', 'Brak b≈Çƒôdu.')}
"""
    file_name = f"human_escalation_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(file_name, "w", encoding="utf-8") as f: f.write(report_content)
    print(f"  [INFO] Raport dla cz≈Çowieka zosta≈Ç zapisany w pliku: {file_name}")
    return {}



--- FILE: agents/state.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
from memory.memory_bank_client import MemoryBankClient

#Zmienne przekazywane do grafu LangChian
class AgentWorkflowState(TypedDict):
    config: Dict[str, Any]
    plan: str; input_path: str; output_path: str; report_output_path: str
    available_columns: List[str]; generated_code: str; generated_report_code: str
    correction_attempts: int; error_message: Optional[str]; failing_node: Optional[str]
    error_context_code: Optional[str]; debugger_analysis: Optional[str]
    package_to_install: Optional[str]; user_approval_status: Optional[str]
    tool_choice: Optional[str]; tool_args: Optional[Dict]
    source_code: str
    autogen_log: str
    langgraph_log: str
    # --- Pola pamiƒôci ---
    run_id: str
    dataset_signature: str
    error_record_id: Optional[str]
    memory_client: MemoryBankClient
    pending_fix_session: Optional[Dict[str, Any]]


--- FILE: memory/__init__.py ---




--- FILE: memory/memory_bank_client.py ---

import json
import hashlib
import pandas as pd
from typing import Dict, List, Optional
import vertexai
from vertexai import agent_engines
from .memory_models import MemoryRecord


class MemoryBankClient:
    def __init__(self, client: vertexai.Client, agent_engine):
        """
        Inicjalizuje klienta z g≈Ç√≥wnym obiektem klienta Vertex AI 
        oraz z gotowym obiektem agent_engine.
        """
        if not client or not agent_engine:
            raise ValueError("Klient Vertex AI oraz Agent Engine muszƒÖ byƒá poprawnie zainicjalizowane.")
        
        self.client = client
        self.agent_engine = agent_engine
        self.engine_name = agent_engine.resource_name
        print(f"INFO: MemoryBankClient gotowy do pracy z silnikiem: {self.engine_name}")
        
    
    
    
    def create_dataset_signature(self, df_preview: pd.DataFrame) -> str:
        """Tworzy unikalny identyfikator dla zbioru danych."""
        s = "".join(df_preview.columns) + str(df_preview.shape)
        return hashlib.md5(s.encode()).hexdigest()

    def add_memory(self, record: MemoryRecord):
        """Zapisuje ustrukturyzowane wspomnienie w Agent Engine."""
        try:
            fact_to_remember = record.model_dump_json()
            scope = {"dataset_signature": record.dataset_signature}
            
            
            self.client.agent_engines.create_memory(
                name=self.engine_name,
                fact=fact_to_remember, 
                scope=scope
            )
            print(f"INFO: Zapisano wspomnienie typu '{record.memory_type}' w zakresie {scope}")
        except Exception as e:
            print(f"B≈ÅƒÑD ZAPISU PAMIƒòCI: {e}")

#     def query_memory(self, query_text: str, scope: Dict, top_k: int = 5) -> List[MemoryRecord]:
#         """
#         Odpytuje pamiƒôƒá semantycznie i zwraca listƒô ustrukturyzowanych wspomnie≈Ñ.
#         """
#         retrieved_mems = []
#         try:
#             print(f"INFO: Odpytujƒô pamiƒôƒá semantycznie z zapytaniem '{query_text}' w zakresie {scope}")

#             # Tworzymy s≈Çownik z parametrami wyszukiwania, zgodnie z Twoim znaleziskiem
#             search_params = {
#                 "search_query": query_text,
#                 "top_k": top_k
#             }

#             # Wywo≈Çujemy API z poprawnym argumentem: similarity_search_params
#             memories_iterator = self.client.agent_engines.retrieve_memories(
#                 name=self.engine_name,
#                 scope=scope,
#                 similarity_search_params=search_params
#             )

#             for mem in memories_iterator:
#                 print("mem", dir(mem))
#                 record = MemoryRecord.model_validate_json(mem.memory)
#                 retrieved_mems.append(record)

#             print(f"INFO: Znaleziono {len(retrieved_mems)} pasujƒÖcych wspomnie≈Ñ.")
#             return retrieved_mems

#         except Exception as e:
#             print(f"B≈ÅƒÑD ODCZYTU PAMIƒòCI: {e}")
#             return []
        
        
    def query_memory(self, query_text: str, scope: Dict, top_k: int = 5) -> List[MemoryRecord]:
        """
        Odpytuje pamiƒôƒá semantycznie, poprawnie odczytujƒÖc zagnie≈ºd≈ºonƒÖ tre≈õƒá wspomnienia.
        """
        retrieved_mems = []
        try:
            print(f"INFO: Odpytujƒô pamiƒôƒá semantycznie z zapytaniem '{query_text}' w zakresie {scope}")

            search_params = {
                "search_query": query_text,
                "top_k": top_k
            }

            memories_iterator = self.client.agent_engines.retrieve_memories(
                name=self.engine_name,
                scope=scope,
                similarity_search_params=search_params
            )

            for i, mem in enumerate(memories_iterator):
                try:

                    json_string_to_parse = mem.memory.fact

                    record = MemoryRecord.model_validate_json(json_string_to_parse)
                    retrieved_mems.append(record)
                    print("udany plan:", record)
                except Exception as e:
                    print(f"‚ö†Ô∏è OSTRZE≈ªENIE: Pominiƒôto uszkodzony lub niekompatybilny rekord pamiƒôci (pozycja {i}). B≈ÇƒÖd: {e}")
                    continue

            print(f"INFO: Znaleziono i poprawnie przetworzono {len(retrieved_mems)} pasujƒÖcych wspomnie≈Ñ.")
            return retrieved_mems

        except Exception as e:
            print(f"KRYTYCZNY B≈ÅƒÑD ODCZYTU PAMIƒòCI: Nie uda≈Ço siƒô wykonaƒá zapytania. B≈ÇƒÖd: {e}")
            return []


--- FILE: memory/memory_models.py ---

from datetime import datetime
from enum import Enum
from typing import Dict, Any, List, Optional
from pydantic import BaseModel, Field
import uuid

class MemoryType(str, Enum):
    SUCCESSFUL_PLAN = "SUCCESSFUL_PLAN"
    EXECUTION_ERROR = "EXECUTION_ERROR"
    SUCCESSFUL_FIX = "SUCCESSFUL_FIX"
    META_INSIGHT = "META_INSIGHT"

    

class MemoryRecord(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    run_id: str # Dodajemy ID bie≈ºƒÖcego uruchomienia
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    memory_type: MemoryType
    dataset_signature: str
    source_node: str
    content: Dict[str, Any]
    metadata: Dict[str, Any] = Field(default_factory=dict)

class DistilledMemory(BaseModel):
    """Ustrukturyzowany, 'ekspercki' format dla przedestylowanego wspomnienia."""
    problem_summary: str = Field(description="Opis problemu w jednym, zwiƒôz≈Çym zdaniu.")
    solution_summary: str = Field(description="Opis rozwiƒÖzania w jednym, zwiƒôz≈Çym zdaniu.")
    applicability_context: str = Field(description="Opis w jednym zdaniu, w jakim kontek≈õcie (np. typ danych, operacja) ta lekcja jest najbardziej u≈ºyteczna.")
    key_takeaway: str = Field(description="Uniwersalna 'z≈Çota my≈õl' lub regu≈Ça na przysz≈Ço≈õƒá, aby uniknƒÖƒá podobnych b≈Çƒôd√≥w.")
    reusable_code_snippet: Optional[str] = Field(description="Generyczny fragment kodu w Pythonie (do 10 linijek), kt√≥ry implementuje 'key_takeaway'. Je≈õli nie ma zastosowania, zwr√≥ƒá null.")
    tags: List[str] = Field(description="Lista 3-5 s≈Ç√≥w kluczowych (tag√≥w) opisujƒÖcych ten problem.")
    
    
 #--czysty zapis o sukcesie   
class DistilledSuccessMemory(BaseModel):
    """Ustrukturyzowany format dla wspomnienia o udanym przebiegu."""
    plan_summary: str = Field(description="Podsumowanie celu i kluczowych krok√≥w zrealizowanego planu w jednym zdaniu.")
    key_insight: str = Field(description="Najwa≈ºniejszy wniosek lub 'trick', kt√≥ry przyczyni≈Ç siƒô do sukcesu tego planu.")
    full_plan_text: str = Field(description="Pe≈Çny, szczeg√≥≈Çowy, numerowany tekst udanego planu.")
    tags: List[str] = Field(description="Lista 3-5 s≈Ç√≥w kluczowych (tag√≥w) opisujƒÖcych ten plan.")
    
class MetaInsightMemory(BaseModel):
    """Ustrukturyzowany format dla WNIOSKU NA POZIOMIE SYSTEMU."""
    observation: str = Field(description="Zwiƒôz≈Çe opisanie zaobserwowanego zjawiska, np. 'Agent generujƒÖcy raporty czƒôsto pope≈Çnia≈Ç b≈Çƒôdy w wizualizacji danych szereg√≥w czasowych'.")
    recommendation: str = Field(description="Konkretna, pojedyncza propozycja zmiany w prompcie lub logice systemu, np. 'Do promptu agenta raportujƒÖcego nale≈ºy dodaƒá konkretny przyk≈Çad u≈ºycia      `plt.xticks(rotation=45)`'.")
    target_agent_or_node: str = Field(description="Nazwa agenta lub wƒôz≈Ça, kt√≥rego dotyczy rekomendacja, np. 'reporting_agent_node'.")
    tags: List[str] = Field(description="Lista 3-5 s≈Ç√≥w kluczowych, np. ['prompt-engineering', 'reporting', 'visualization'].")
    
    
    


--- FILE: memory/memory_utils.py ---

#--narzedzie do przetwarzania info dla pamieci dlugotrwalej, llm agent uzywa llm!!
def distill_memory_content(failing_code: str, error_traceback: str, debugger_analysis: str, corrected_code: str) -> dict:
    """U≈ºywa LLM do 'przedestylowania' surowych danych o b≈Çƒôdzie i jego naprawie do zwiƒôz≈Çego, ustrukturyzowanego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia (wersja ekspercka)...")
    
    prompt_template = f"""
    Persona: Jeste≈õ starszym in≈ºynierem oprogramowania, kt√≥ry pisze zwiƒôz≈Çe post-mortemy do wewnƒôtrznej bazy wiedzy. Twoim celem jest stworzenie notatki, kt√≥ra bƒôdzie maksymalnie u≈ºyteczna dla innych agent√≥w w przysz≈Ço≈õci.
    Przeanalizuj poni≈ºszy kontekst i wyciƒÖgnij z niego kluczowe, gotowe do u≈ºycia wnioski.
    Kontekst:
    [WADLIWY KOD]: {failing_code}
    [PE≈ÅNY B≈ÅƒÑD]: {error_traceback}
    [ANALIZA PROBLEMU]: {debugger_analysis}
    [POPRAWIONY KOD]: {corrected_code}
    Zadanie: Na podstawie powy≈ºszego kontekstu, wygeneruj obiekt, kt√≥ry bƒôdzie pasowa≈Ç do zdefiniowanej struktury.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomy≈õlnie przedestylowano wspomnienie (wersja ekspercka).")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZE≈ªENIE: Destylacja (ekspercka) nie powiod≈Ça siƒô: {e}. Zapisujƒô surowe dane.")
        return {
            "problem_summary": debugger_analysis,
            "key_takeaway": "N/A - distillation failed",
            "raw_error": intelligent_truncate(error_traceback, 500)
        }
#pamiec dlugotrwala-zapis w meta agent, sukces 
def distill_success_memory(final_plan: str) -> dict:
    """U≈ºywa LLM do podsumowania udanego planu w zwiƒôz≈ÇƒÖ notatkƒô."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o sukcesie...")
    prompt_template = f"""
    Persona: Jeste≈õ starszym in≈ºynierem AI, kt√≥ry dokumentuje udane strategie.
    Kontekst: Przeanalizuj poni≈ºszy plan, kt√≥ry zako≈Ñczy≈Ç siƒô sukcesem i stw√≥rz zwiƒôz≈Çe podsumowanie w formacie JSON.
    [FINALNY PLAN]: {final_plan}
    """
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        # U≈ºywamy nowego, l≈ºejszego modelu DistilledSuccessMemory
        structured_llm = llm.with_structured_output(DistilledSuccessMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomy≈õlnie przedestylowano wspomnienie o sukcesie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZE≈ªENIE: Destylacja sukcesu nie powiod≈Ça siƒô: {e}.")
        return {"plan_summary": "N/A - distillation failed"}
    
    
def distill_memory_content(debugger_analysis: str, failing_code: str, corrected_code: str) -> dict:
    """U≈ºywa LLM do 'przedestylowania' analizy debuggera i zmian w kodzie do zwiƒôz≈Çego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o naprawie...")
    
    # Zamiast pe≈Çnego b≈Çƒôdu, u≈ºywamy zwiƒôz≈Çej analizy od debuggera!
    prompt_template = f"""
    Persona: Jeste≈õ starszym in≈ºynierem oprogramowania, kt√≥ry pisze zwiƒôz≈Çe post-mortemy.
    Przeanalizuj poni≈ºszy kontekst dotyczƒÖcy naprawy b≈Çƒôdu i wyciƒÖgnij z niego kluczowe, gotowe do u≈ºycia wnioski.
    Kontekst:
    [ANALIZA PROBLEMU WG DEBUGGERA]: {debugger_analysis}
    [WADLIWY FRAGMENT KODU]: {intelligent_truncate(failing_code, 500)}
    [POPRAWIONY KOD]: {intelligent_truncate(corrected_code, 500)}
    Zadanie: Na podstawie powy≈ºszego kontekstu, wygeneruj obiekt JSON zgodny ze strukturƒÖ DistilledMemory.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomy≈õlnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZE≈ªENIE: Destylacja (naprawa) nie powiod≈Ça siƒô: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}
    
    
    
    

    
def distill_full_fix_session(initial_error: str, fix_attempts: List[Dict], successful_code: str) -> Dict[str, Any]:
    """U≈ºywa LLM, aby podsumowaƒá ca≈ÇƒÖ sesjƒô naprawczƒÖ w jedno zwiƒôz≈Çe wspomnienie."""
    print("  [INFO] Uruchamiam destylacjƒô ca≈Çej sesji naprawczej...")

    # Tworzymy skonsolidowanƒÖ historiƒô analiz debuggera
    consolidated_analysis = "\n".join(
        [f"Pr√≥ba {i+1}: {attempt.get('debugger_analysis', 'Brak analizy.')}" for i, attempt in enumerate(fix_attempts)]
    )

    prompt_template = f"""
Persona: Jeste≈õ starszym in≈ºynierem, kt√≥ry pisze ekstremalnie zwiƒôz≈Çe post-mortemy. Priorytetem jest gƒôsto≈õƒá informacji przy minimalnej liczbie s≈Ç√≥w.

Przeanalizuj ca≈ÇƒÖ sesjƒô naprawy b≈Çƒôdu i wyciƒÖgnij z niej kluczowe wnioski.

[PIERWOTNY B≈ÅƒÑD]:
{initial_error}

[HISTORIA ANALIZ Z NIEUDANYCH PR√ìB NAPRAWY]:
{consolidated_analysis}

[KOD, KT√ìRY OSTATECZNIE ZADZIA≈ÅA≈Å]:
{successful_code}

Zadanie: Wygeneruj obiekt JSON. Ka≈ºde pole tekstowe musi byƒá pojedynczym, klarownym zdaniem. Ca≈Ço≈õƒá nie mo≈ºe przekroczyƒá 150 s≈Ç√≥w.
"""
    try:
        llm = ChatVertexAI(
            model_name=MAIN_AGENT, 
            project_id=PROJECT_ID, 
            location=LOCATION,
            max_output_tokens=512
        )
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("  [INFO] Pomy≈õlnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"  [OSTRZE≈ªENIE] Destylacja sesji nie powiod≈Ça siƒô: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}



    
def generate_meta_insight(audit_report: str) -> Optional[dict]:
    """U≈ºywa LLM do wyciƒÖgniƒôcia z raportu audytora jednego, kluczowego wniosku."""
    print("INFO: Uruchamiam proces generowania wniosku META...")
    prompt = f"""
    Przeanalizuj poni≈ºszy raport audytora. Twoim zadaniem jest znalezienie JEDNEJ, najwa≈ºniejszej i najbardziej konkretnej rekomendacji dotyczƒÖcej ulepszenia systemu.
    Je≈õli znajdziesz takƒÖ rekomendacjƒô, przekszta≈Çƒá jƒÖ w obiekt JSON zgodny ze strukturƒÖ MetaInsightMemory. Je≈õli raport jest og√≥lnikowy i nie zawiera konkretnych propozycji, zwr√≥ƒá null.
    [RAPORT AUDYTORA]:\n{audit_report}
    """
    try:
        llm = ChatVertexAI(model_name=CRITIC_MODEL, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(MetaInsightMemory)
        insight_object = structured_llm.invoke(prompt)
        print("INFO: Pomy≈õlnie wygenerowano wniosek META.")
        return insight_object.dict()
    except Exception:
        print("OSTRZE≈ªENIE: Nie uda≈Ço siƒô wygenerowaƒá wniosku META z raportu audytora.")
        return None


