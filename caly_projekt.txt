--- FILE: __init__.py ---




--- FILE: config.py ---

import os
import logging
from enum import Enum
from google.cloud import secretmanager
import langchain
from langchain.cache import SQLiteCache





def get_secret(project_id: str, secret_id: str, version_id: str = "latest") -> str:
    """Pobiera warto≈õƒá sekretu z Google Secret Manager."""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"
    response = client.access_secret_version(request={"name": name})
   
    return response.payload.data.decode("UTF-8")


class ApiType(Enum):
    GOOGLE = "google"
    ANTHROPIC = "anthropic"
    def __str__(self):
        return self.value


LOCATION="us-central1"
PROJECT_ID="dark-data-discovery"

#---------AGENTS--------:
MAIN_AGENT="gemini-2.5-pro"
API_TYPE_GEMINI=str(ApiType.GOOGLE)

CRITIC_MODEL="claude-3-7-sonnet-20250219"
CODE_MODEL="claude-sonnet-4-20250514"
API_TYPE_SONNET = str(ApiType.ANTHROPIC)

LANGCHAIN_API_KEY = get_secret(PROJECT_ID,"LANGCHAIN_API_KEY")
ANTHROPIC_API_KEY=get_secret(PROJECT_ID,"ANTHROPIC_API_KEY")

MEMORY_ENGINE_DISPLAY_NAME="memory-gamma-way"

INPUT_FILE_PATH = "gs://super_model/data/structural_data/synthetic_fraud_dataset.csv"

MAX_CORRECTION_ATTEMPTS=5



os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = LANGCHAIN_API_KEY
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_PROJECT"] = "Projekt Multi-Agent-System v9.0-Integrated"
os.environ["ANTHROPIC_API_KEY"] =ANTHROPIC_API_KEY


#---cache-------
langchain.llm_cache = SQLiteCache(database_path=".langchain.db")



    
#FUNKCJA KONFIGURACYJNA AGENTOW AUTOGEN
def basic_config_agent(agent_name:str, api_type:str, location:str=None, project_id:str=None, api_key:str=None):
    try:
        configuration = {"model": agent_name, "api_type": api_type}
        if api_key: configuration["api_key"] = api_key
        if project_id: configuration["project_id"] = project_id
        if location: configuration["location"] = location
        logging.info(f"Model configuration: {configuration}")
        return [configuration]

    except Exception as e:
        logging.error(f"Failed to initialize Vertex AI or configure LLM: {e}")
        print(f"Error: Failed to initialize Vertex AI or configure LLM. Please check your project ID, region, and permissions. Details: {e}")
        exit()


--- FILE: main.ipynb ---

import os
import pandas as pd
import uuid
import json
import vertexai
from vertexai import agent_engines
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
# Importy z w≈Çasnych modu≈Ç√≥w
from config import PROJECT_ID, LOCATION, MEMORY_ENGINE_DISPLAY_NAME, INPUT_FILE_PATH,MAIN_AGENT,CRITIC_MODEL,CODE_MODEL, API_TYPE_GEMINI,API_TYPE_SONNET, ANTHROPIC_API_KEY,basic_config_agent
from agents.state import AgentWorkflowState
from agents.autogen_agents import TriggerAgent,PlannerAgent,CriticAgent
from prompts import LangchainAgentsPrompts,AutoGenAgentsPrompts
from agents.langgraph_nodes import * 
from agents.autogen_agent_utils import run_autogen_planning_phase
from memory.memory_bank_client import MemoryBankClient
from tools.utils import *
# --- Koniec kom√≥rki ---
AGENT_ENGINE_NAME = "" # Zostanie wype≈Çniona po pobraniu lub utworzeniu silnika

# Inicjalizacja g≈Ç√≥wnego klienta Vertex AI
client = vertexai.Client(project=PROJECT_ID, location=LOCATION)
# --- Koniec kom√≥rki ---
def get_or_create_agent_engine(display_name: str) :
    """
    Pobiera istniejƒÖcy Agent Engine po nazwie wy≈õwietlanej lub tworzy nowy, je≈õli nie istnieje.
    """
    # 1. Pobierz listƒô wszystkich istniejƒÖcych silnik√≥w w projekcie
    all_engines = agent_engines.list()
    
    # 2. Sprawd≈∫, czy kt√≥ry≈õ z nich ma pasujƒÖcƒÖ nazwƒô
    for engine in all_engines:
        if engine.display_name == display_name:
            print(f"INFO: Znaleziono i po≈ÇƒÖczono z istniejƒÖcym Agent Engine: '{display_name}'")
            return engine
            
    # 3. Je≈õli pƒôtla siƒô zako≈Ñczy≈Ça i nic nie znaleziono, stw√≥rz nowy silnik
    print(f"INFO: Nie znaleziono Agent Engine o nazwie '{display_name}'. Tworzenie nowego...")
    try:
        new_engine = agent_engines.create(
            display_name=display_name
        )
        print(f"INFO: Pomy≈õlnie utworzono nowy Agent Engine.")
        return new_engine
    except Exception as e:
        print(f"KRYTYCZNY B≈ÅƒÑD: Nie mo≈ºna utworzyƒá Agent Engine. Sprawd≈∫ konfiguracjƒô i uprawnienia. B≈ÇƒÖd: {e}")
        exit()

# --- Koniec kom√≥rki ---
agent_engine =get_or_create_agent_engine(MEMORY_ENGINE_DISPLAY_NAME)
AGENT_ENGINE_NAME = agent_engine.resource_name
print(AGENT_ENGINE_NAME)

# --- Koniec kom√≥rki ---
# --- Konfiguracja czatu grupowego ---
main_agent_configuration={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(agent_name=MAIN_AGENT, api_type=API_TYPE_GEMINI, location=LOCATION, project_id=PROJECT_ID)}
critic_agent_configuration ={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(api_key=ANTHROPIC_API_KEY,agent_name=CRITIC_MODEL, api_type=API_TYPE_SONNET)}
trigger_prompt = str(AutoGenAgentsPrompts.Trigger_prompt())
planner_prompt = str(AutoGenAgentsPrompts.Planner_prompt())
critic_prompt = str(AutoGenAgentsPrompts.Critic_prompt())
#---WYWO≈ÅANIE AGENT√ìW
trigger_agent = TriggerAgent(llm_config=main_agent_configuration, prompt=trigger_prompt)
planner_agent = PlannerAgent(llm_config=main_agent_configuration,prompt=planner_prompt)
critic_agent = CriticAgent(llm_config=main_agent_configuration,prompt=critic_prompt)
# --- Koniec kom√≥rki ---

# --- Koniec kom√≥rki ---
if __name__ == "__main__":
    
    files_to_exclude = {'Agents_beta (10).py','pack_project.ipynb', 'caly_projekt.txt'}
    system_source_code = read_project_source_code(".", exclude_files=files_to_exclude)

    # --- Inicjalizacja Pamiƒôci i Uruchomienia ---
    memory_client = MemoryBankClient(client=client, agent_engine=agent_engine)
    run_id = str(uuid.uuid4())
    
    print("\n--- ODPYTYWANIE PAMIƒòCI O INSPIRACJE ---")
    inspiration_prompt = ""
    dataset_signature = ""
    try:
        df_preview = pd.read_csv(INPUT_FILE_PATH, nrows=0)
        dataset_signature = memory_client.create_dataset_signature(df_preview)
        past_memories = memory_client.query_memory(
            query_text="Najlepsze strategie i kluczowe wnioski dotyczƒÖce przetwarzania danych",
            scope={"dataset_signature": dataset_signature},
            top_k=3
        )
        if past_memories:
            inspirations = []
            for mem in past_memories:
                if mem.memory_type == MemoryType.SUCCESSFUL_PLAN and 'key_insight' in mem.content:
                    inspirations.append(f"SPRAWDZONY WNIOSEK Z PLANU: {mem.content['key_insight']}")
                elif mem.memory_type == MemoryType.SUCCESSFUL_FIX and 'key_takeaway' in mem.content:
                    inspirations.append(f"NAUCZKA Z NAPRAWIONEGO B≈ÅƒòDU: {mem.content['key_takeaway']}")
            if inspirations:
                inspiration_prompt = "--- INSPIRACJE Z POPRZEDNICH URUCHOMIE≈É ---\n" + "\n".join(inspirations)
                print("INFO: Pomy≈õlnie pobrano inspiracje z pamiƒôci.")
        else:
            print("INFO: Nie znaleziono inspiracji w pamiƒôci dla tego typu danych.")
    except Exception as e:
        print(f"OSTRZE≈ªENIE: Nie uda≈Ço siƒô pobraƒá inspiracji z pamiƒôci: {e}")

        
        
    active_policies = get_active_policies_from_memory(memory_client, dataset_signature)    
    
    # --- Krok 1: Faza planowania (AutoGen) ---
    final_plan, autogen_log = run_autogen_planning_phase(
        input_path=INPUT_FILE_PATH, 
        inspiration_prompt=inspiration_prompt,
        trigger_agent=trigger_agent,
        planner_agent=planner_agent,
        critic_agent=critic_agent,
        manager_agent_config=main_agent_configuration,
        active_policies=active_policies
    )
    save_autogen_conversation_log(log_content=autogen_log, file_path="reports/autogen_planning_conversation.log")

    # --- Krok 2: Faza wykonania (LangGraph) ---
    if final_plan:
        print("\n" + "="*80)
        print("### ### FAZA 2: URUCHAMIANIE WYKONANIA PLANU (LangGraph) ### ###")
        print("="*80 + "\n")
        
        workflow = StateGraph(AgentWorkflowState)
        
        # <<< ZMIANA TUTAJ: Zaktualizowana lista wƒôz≈Ç√≥w >>>
        nodes = [
            "schema_reader", "code_generator", "architectural_validator", 
            "data_code_executor", "universal_debugger", "apply_code_fix", 
            "human_approval", "package_installer", "human_escalation", 
            "sync_report_code", "commit_memory","meta_auditor",
            # Nowe, wyspecjalizowane wƒôz≈Çy raportujƒÖce:
            "summary_analyst", "plot_generator", "report_composer" 
        ]
        for name in nodes: workflow.add_node(name, globals()[f"{name}_node"])

        # Definicja krawƒôdzi
        workflow.set_entry_point("schema_reader")
        
        # ≈öcie≈ºka przetwarzania danych
        workflow.add_edge("schema_reader", "code_generator")
        workflow.add_edge("code_generator", "architectural_validator")
        
        def should_continue_or_debug(state: AgentWorkflowState) -> str:
            if state.get("error_message"):
                if state.get("correction_attempts", 0) >= MAX_CORRECTION_ATTEMPTS:
                    return "request_human_help"
                return "call_debugger"
            return "continue"

        workflow.add_conditional_edges(
            "architectural_validator",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "data_code_executor"}
        )
        workflow.add_conditional_edges(
            "data_code_executor",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "commit_memory"}
        )
        
        # <<< ZMIANA TUTAJ: Nowa ≈õcie≈ºka raportowania >>>
        workflow.add_edge("commit_memory", "summary_analyst")
        workflow.add_conditional_edges(
            "summary_analyst",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "plot_generator"}
        )
        workflow.add_conditional_edges(
            "plot_generator",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "report_composer"}
        )
        workflow.add_conditional_edges(
            "report_composer",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "meta_auditor"}
        )

        # ≈öcie≈ºki naprawcze
        workflow.add_edge("human_escalation", "meta_auditor")
        workflow.add_edge("package_installer", "data_code_executor")

        def route_after_fix(state):
            failing_node = state.get("failing_node")
            # Po naprawie wraca do wƒôz≈Ça, kt√≥ry zawi√≥d≈Ç
            if failing_node:
                return failing_node
            # Domy≈õlnie wraca do walidacji
            return "architectural_validator"

        workflow.add_conditional_edges("apply_code_fix", route_after_fix)

        def route_from_debugger(state):
            if state.get("tool_choice") == "propose_code_fix":
                return "apply_code_fix"
            if state.get("tool_choice") == "request_package_installation":
                return "human_approval"
            return "human_escalation"

        workflow.add_conditional_edges("universal_debugger", route_from_debugger)
        workflow.add_conditional_edges("human_approval", lambda s: s.get("user_approval_status"), {
            "APPROVED": "package_installer", "REJECTED": "universal_debugger"
        })

        app = workflow.compile()
        
        app_config = {"MAIN_AGENT": MAIN_AGENT, "CODE_MODEL": CODE_MODEL, "CRITIC_MODEL": CRITIC_MODEL}
        
        initial_state = {
            "config": app_config,
            "plan": final_plan, 
            "input_path": INPUT_FILE_PATH,
            "output_path": "reports/processed_data.csv",
            "report_output_path": "reports/transformation_report.html",
            "correction_attempts": 0, 
            "correction_history": [],
            "source_code": system_source_code,
            "autogen_log": autogen_log,
            "memory_client": memory_client,
            "run_id": run_id,
            "dataset_signature": dataset_signature,
            "pending_fix_session": None,
            "active_policies": active_policies
        }
        
        langgraph_log = ""
        final_run_state = initial_state.copy()
        
        for event in app.stream(initial_state, {"recursion_limit": 50}):
            for node_name, state_update in event.items():
                if "__end__" not in node_name:
                    print(f"--- Krok: '{node_name}' ---")
                    if state_update:
                        printable_update = state_update.copy()
                        for key in ["generated_code", "corrected_code", "generated_report_code", "error_context_code", "plot_generation_code", "summary_html"]:
                            if key in printable_update and printable_update[key]:
                                print(f"--- {key.upper()} ---")
                                print(printable_update[key])
                                print("-" * (len(key) + 8))
                                del printable_update[key]
                        if printable_update:
                            print(json.dumps(printable_update, indent=2, default=str))
                        
                        log_line = f"--- Krok: '{node_name}' ---\n{json.dumps(state_update, indent=2, default=str)}\n"
                        langgraph_log += log_line
                        final_run_state.update(state_update)
                    else:
                        print("  [INFO] Wƒôze≈Ç zako≈Ñczy≈Ç pracƒô bez aktualizacji stanu.")
                    print("-" * 20 + "\n")

        save_langgraph_execution_log(log_content=langgraph_log, file_path="reports/langgraph_execution.log")

        final_run_state['langgraph_log'] = langgraph_log
        meta_auditor_node(final_run_state)

        print("\n\n--- ZAKO≈ÉCZONO PRACƒò GRAFU I AUDYT ---")
    else:
        print("Proces zako≈Ñczony. Brak planu do wykonania.")
# --- Koniec kom√≥rki ---

# --- Koniec kom√≥rki ---



--- FILE: prompts.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import json
import re

class AutoGenAgentsPrompts:
    
    @staticmethod
    def Trigger_prompt() -> str:
        
        return f"""Jeste≈õ 'Stra≈ºnikiem Danych'. Twoim jedynym zadaniem jest analiza podsumowania danych (nazwy kolumn, pierwsze wiersze).
Na tej podstawie musisz podjƒÖƒá decyzjƒô: czy te dane majƒÖ charakter **tabularyczny** (jak plik CSV lub tabela bazy danych)?
- Je≈õli TAK: odpowiedz **tylko i wy≈ÇƒÖcznie**: 'Dane sƒÖ tabularyczne. Przekazujƒô do PlannerAgent w celu stworzenia planu analizy.'. Nie dodawaj nic wiƒôcej.
- Je≈õli NIE (np. sƒÖ to logi serwera, obrazy, czysty tekst): Twoja wiadomo≈õƒá MUSI ko≈Ñczyƒá siƒô s≈Çowem 'TERMINATE'. Wyja≈õnij kr√≥tko, dlaczego dane nie sƒÖ tabularyczne, np. 
'Dane nie sƒÖ tabularyczne, to zbi√≥r artyku≈Ç√≥w tekstowych. TERMINATE'. """
    
    
    @staticmethod
    def Planner_prompt()->str:
        
        return f"""Jeste≈õ 'Architektem Planu'. Otrzyma≈Çe≈õ potwierdzenie, ≈ºe dane sƒÖ tabularyczne.
Twoim zadaniem jest stworzenie szczeg√≥≈Çowego, numerowanego planu czyszczenia i przygotowania danych do og√≥lnej analizy i modelowania. Plan musi byƒá praktyczny i zgodny z najlepszymi praktykami.
Twoje zadanie sk≈Çada siƒô z dw√≥ch czƒô≈õci:
1.  **Analiza Inspiracji:** Je≈õli w wiadomo≈õci od u≈ºytkownika znajduje siƒô sekcja '--- INSPIRACJE Z POPRZEDNICH URUCHOMIE≈É ---', 
potraktuj jƒÖ jako cennƒÖ inspiracjƒô i punkt wyj≈õcia. Zawiera ona sprawdzonƒÖ strategiƒô ("z≈ÇotƒÖ my≈õl") i mo≈ºe r√≥wnie≈º zawieraƒá konkretne kroki. Twoim zadaniem jest **krytyczna adaptacja** tego planu. 
**Sprawd≈∫, czy ka≈ºdy krok z inspiracji ma sens w kontek≈õcie AKTUALNEGO podglƒÖdu danych.** Mo≈ºesz usunƒÖƒá, dodaƒá lub zmodyfikowaƒá kroki, aby idealnie pasowa≈Çy do obecnego problemu.
2.  **Tworzenie Planu:** Je≈õli nie ma inspiracji, stw√≥rz nowy, solidny plan od podstaw.
Plan powinien zawieraƒá kroki takie jak:
1.  Weryfikacja i obs≈Çuga brakujƒÖcych warto≈õci (np. strategia imputacji dla ka≈ºdej istotnej kolumny).
2.  Weryfikacja i korekta typ√≥w danych (np. konwersja string√≥w na daty lub liczby).
3.  In≈ºynieria cech (np. tworzenie nowych, u≈ºytecznych kolumn jak 'dzien_tygodnia' z daty lub kategoryzacja warto≈õci liczbowych).
4.  Wykrywanie i obs≈Çuga warto≈õci odstajƒÖcych (outlier√≥w).
5.  Normalizacja lub skalowanie danych (je≈õli to konieczne, wyja≈õnij kr√≥tko dlaczego).

Po przedstawieniu pierwszej wersji planu, oczekuj na recenzjƒô od CriticAgenta.
- Je≈õli CriticAgent prze≈õle uwagi, stw√≥rz **NOWƒÑ, KOMPLETNƒÑ WERSJƒò** planu, kt√≥ra uwzglƒôdnia **WSZYSTKIE** jego sugestie.
- W poprawionym planie zaznacz, co zosta≈Ço zmienione. Prze≈õlij zaktualizowany plan z powrotem do CriticAgenta.
Kontynuuj ten proces, a≈º CriticAgent ostatecznie zaakceptuje Tw√≥j plan. """
    
    
    @staticmethod
    def Critic_prompt() ->str:
        
        return f"""Jeste≈õ 'Recenzentem Jako≈õci'. Twoim zadaniem jest konstruktywna krytyka planu od PlannerAgenta. Oce≈Ñ go pod kƒÖtem praktyczno≈õci, realizmu i efektywno≈õci.
Twoje Z≈Çote Zasady:
1.  **PROSTOTA JEST KLUCZEM:** Agresywnie kwestionuj nadmiernie skomplikowane kroki. Czy naprawdƒô potrzebujemy KNNImputer, gdy prosta mediana wystarczy?
2.  **JEDNA ZMIANA NA RAZ:** Je≈õli plan proponuje stworzenie kilku z≈Ço≈ºonych cech w jednym kroku, odrzuƒá to. Zarekomenduj podzielenie tego na osobne, ≈Çatwiejsze do weryfikacji kroki. 
Plan musi byƒá odporny na b≈Çƒôdy.
3.  **KONKRETNE SUGESTIE:** Zawsze podawaj konkretnƒÖ alternatywƒô. Zamiast 'To jest z≈Çe', napisz 'Krok X jest nieoptymalny. Sugerujƒô Y, poniewa≈º Z.'

**PROCES ZATWIERDZANIA (KRYTYCZNIE WA≈ªNE):**
- Je≈õli plan wymaga jakichkolwiek poprawek, jasno je opisz i ode≈õlij do PlannerAgenta. **NIE U≈ªYWAJ** poni≈ºszych fraz kluczowych.
- Je≈õli plan jest **doskona≈Çy** i nie wymaga ≈ºadnych zmian, Twoja odpowied≈∫ **MUSI** mieƒá nastƒôpujƒÖcƒÖ, ≈õcis≈ÇƒÖ strukturƒô:
Najpierw napisz liniƒô:
`OSTATECZNY PLAN:`
Poni≈ºej wklej **CA≈ÅY, KOMPLETNY** plan od PlannerAgenta.
Na samym ko≈Ñcu wiadomo≈õci dodaj frazƒô:
`PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI` """
    
    
    
class LangchainAgentsPrompts:
    
    SYSTEM_PROMPT_NEXUS_ENGINEER = """
# ===================================================================
# ### G≈Å√ìWNA DYREKTYWA: PERSONA I CEL ###
# ===================================================================
Jeste≈õ "Nexus" ‚Äì ≈õwiatowej klasy, autonomicznym in≈ºynierem oprogramowania AI. TwojƒÖ specjalizacjƒÖ jest pisanie czystego, wydajnego i solidnego kodu w Pythonie. Twoim nadrzƒôdnym celem jest rozwiƒÖzywanie problem√≥w poprzez dostarczanie kompletnych, gotowych do wdro≈ºenia i samowystarczalnych skrypt√≥w.

# ===================================================================
# ### ZASADY PODSTAWOWE (CORE PRINCIPLES) ###
# ===================================================================
Zawsze przestrzegaj nastƒôpujƒÖcych zasad:

1.  **My≈õlenie Krok po Kroku (Chain of Thought):** Zanim napiszesz jakikolwiek kod, najpierw przeanalizuj problem i stw√≥rz plan dzia≈Çania. Zapisz ten plan w formie komentarzy w kodzie. To porzƒÖdkuje TwojƒÖ logikƒô i prowadzi do lepszych rozwiƒÖza≈Ñ.
2.  **Solidno≈õƒá i Odporno≈õƒá (Robustness):** Przewiduj potencjalne problemy i skrajne przypadki (edge cases). Je≈õli to stosowne, u≈ºywaj blok√≥w `try...except` do obs≈Çugi b≈Çƒôd√≥w. Upewnij siƒô, ≈ºe kod nie zawiedzie przy nieoczekiwanych danych wej≈õciowych.
3.  **Samowystarczalno≈õƒá (Self-Containment):** Tw√≥j kod musi byƒá w pe≈Çni kompletny. Nie zak≈Çadaj istnienia ≈ºadnych zewnƒôtrznych zmiennych, plik√≥w czy funkcji, o ile nie zosta≈Çy one jawnie wymienione jako "Dostƒôpne Zasoby".
4.  **Przejrzysto≈õƒá ponad Spryt (Clarity over Cleverness):** Pisz kod, kt√≥ry jest ≈Çatwy do zrozumienia dla cz≈Çowieka. U≈ºywaj czytelnych nazw zmiennych i dodawaj komentarze tam, gdzie logika jest z≈Ço≈ºona. Unikaj nadmiernie skomplikowanych, jednowierszowych rozwiƒÖza≈Ñ.

# ===================================================================
# ### PROCES ROZWIƒÑZYWANIA PROBLEM√ìW ###
# ===================================================================
Gdy otrzymujesz zadanie, postƒôpuj wed≈Çug nastƒôpujƒÖcego schematu:

1.  **ANALIZA CELU:** W pe≈Çni zrozum, co ma zostaƒá osiƒÖgniƒôte. Zidentyfikuj dane wej≈õciowe i oczekiwany rezultat.
2.  **TWORZENIE PLANU:** WewnƒÖtrz bloku kodu, stw√≥rz plan dzia≈Çania w formie komentarzy (`# Krok 1: ...`, `# Krok 2: ...`).
3.  **IMPLEMENTACJA KODU:** Napisz kod, kt√≥ry realizuje Tw√≥j plan.
4.  **AUTOKOREKTA I WERYFIKACJA:** Zanim zako≈Ñczysz, dokonaj krytycznego przeglƒÖdu w≈Çasnego kodu. Zadaj sobie pytania: "Czy ten kod jest kompletny?", "Czy obs≈Çu≈ºy≈Çem przypadki brzegowe?", "Czy jest zgodny ze wszystkimi zasadami?". Popraw wszelkie znalezione niedociƒÖgniƒôcia.

"""
    
    
    
    
    
    @staticmethod
    def code_generator(plan: str, available_columns: List[str]) -> str:
        task_prompt = f"""
# ===================================================================
# ### AKTUALNE ZADANIE: GENEROWANIE KODU ###
# ===================================================================
**Cel:** Na podstawie poni≈ºszego planu biznesowego i dostƒôpnych danych, napisz kompletny i samowystarczalny skrypt w Pythonie.

**Plan Biznesowy do Implementacji:**
{plan}

**Dostƒôpne Kolumny w Danych:**
{available_columns}

**Wymagania Architektoniczne (Bezwzglƒôdnie Przestrzegaj):**
{ArchitecturalRulesManager.get_rules_as_string()}
""" 
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER+ task_prompt
    
    @staticmethod
    def tool_based_debugger(failing_node: str,active_policies: Optional[str] = None) -> str:
        
        policy_section = ""
        if active_policies:
            policy_section = active_policies
        
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER+ f"""Jeste≈õ 'G≈Ç√≥wnym In≈ºynierem Jako≈õci Kodu'.
        {policy_section}
        Twoim zadaniem jest nie tylko naprawienie zg≈Çoszonego b≈Çƒôdu, ale zapewnienie, ≈ºe kod bƒôdzie dzia≈Ça≈Ç poprawnie.
        --- KONTEKST ZADANIA ---
B≈ÇƒÖd wystƒÖpi≈Ç w wƒô≈∫le o nazwie: '{failing_node}'. Twoje zadanie zale≈ºy od tego kontekstu:
- Je≈õli `failing_node` to 'data_code_executor' lub 'architectural_validator', Twoim zadaniem jest naprawa G≈Å√ìWNEGO skryptu do przetwarzania danych.
- Je≈õli `failing_node` to 'plot_generator_node', Twoim zadaniem jest napisanie FRAGMENTU KODU W PYTHONIE, kt√≥ry generuje wykresy.
- Je≈õli `failing_node` to 'summary_analyst_node', Twoim zadaniem jest napisanie kodu HTML z podsumowaniem analitycznym.
**Bezwzglƒôdnie przestrzegaj tych zasad:**
     - U≈ºywaj WY≈ÅƒÑCZNIE biblioteki `matplotlib.pyplot`. Nie u≈ºywaj `plotly` ani `seaborn`.
    - NIE importuj bibliotek.
    - U≈ºywaj tylko ramek danych `df_original` i `df_processed`.
    - NIE u≈ºywaj `plt.show()`.
    - Ka≈ºdƒÖ figurƒô (`fig`) MUSISZ dodaƒá do listy `figures_to_embed`.
---
--- NOWA ZDOLNO≈öƒÜ: DIAGNOZA NARZƒòDZI ---
Je≈õli traceback b≈Çƒôdu (np. NameError, AttributeError) wskazuje na funkcjƒô, kt√≥ra jest wewnƒôtrznym narzƒôdziem systemu, a nie na kod, kt√≥ry masz naprawiƒá, u≈ºyj narzƒôdzia `inspect_tool_code`, aby przeczytaƒá kod ≈∫r√≥d≈Çowy tego narzƒôdzia. Przeanalizuj go i, je≈õli znajdziesz w nim b≈ÇƒÖd (np. brakujƒÖcy import), w swojej finalnej poprawce do `corrected_code` do≈ÇƒÖcz brakujƒÖce importy lub logikƒô, aby naprawiƒá r√≥wnie≈º ten b≈ÇƒÖd.
- Je≈õli b≈ÇƒÖd to `ModuleNotFoundError`, u≈ºyj `request_package_installation`.
- Je≈õli b≈ÇƒÖd to `ImportError` wskazujƒÖcy na konflikt wersji, r√≥wnie≈º u≈ºyj `request_package_installation`, aby zasugerowaƒá aktualizacjƒô pakietu, kt√≥ry jest ≈∫r√≥d≈Çem b≈Çƒôdu.
- Dla wszystkich innych b≈Çƒôd√≥w w kodzie (np. `SyntaxError`, `KeyError`), u≈ºyj `propose_code_fix` a nastƒôpnie przeanalizuj poni≈ºszy b≈ÇƒÖd i wadliwy kod. Twoja praca sk≈Çada siƒô z dw√≥ch krok√≥w:
1.  **Analiza i Naprawa:** Zidentyfikuj przyczynƒô b≈Çƒôdu i stw√≥rz kompletnƒÖ, poprawionƒÖ wersjƒô ca≈Çego skryptu.
2.  **Wywo≈Çanie Narzƒôdzia:** Wywo≈Çaj narzƒôdzie `propose_code_fix`, podajƒÖc **OBOWIƒÑZKOWO** dwa argumenty: `analysis` (twoja analiza) oraz `corrected_code` (pe≈Çny, naprawiony kod).
Przeanalizuj poni≈ºszy b≈ÇƒÖd i wadliwy kod. """

    @staticmethod
    def summary_analyst_prompt(plan: str, original_summary: str, processed_summary: str) -> str:
        """
        Tworzy prompt dla agenta, kt√≥rego JEDYNYM zadaniem jest analiza
        i napisanie tekstowego podsumowania w HTML.
        """
        return f"""
        Jeste≈õ analitykiem danych. Twoim jedynym zadaniem jest napisanie zwiƒôz≈Çego, mened≈ºerskiego podsumowania w formacie HTML, kt√≥re podkre≈õla kluczowe korzy≈õci z transformacji danych.
        Skup siƒô na zmianach w brakujƒÖcych danych, warto≈õciach odstajƒÖcych i liczbie kolumn.
        
        PLAN TRANSFORMACJI, KT√ìRY MASZ OPISAƒÜ: 
        {plan}
        
        DANE PRZED TRANSFORMACJƒÑ (PODSUMOWANIE): 
        {original_summary}
        
        DANE PO TRANSFORMACJI (PODSUMOWANIE): 
        {processed_summary}
        
        Twoja odpowied≈∫ musi byƒá tylko i wy≈ÇƒÖcznie kodem HTML, gotowym do wstawienia do raportu.
        """

    @staticmethod
    def plot_generator_prompt(plan: str,available_columns: List[str]) -> str:
        """
        Tworzy prompt dla agenta, kt√≥rego JEDYNYM zadaniem jest napisanie
        kodu w Pythonie do generowania wykres√≥w.
        """
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER + f"""
        Jeste≈õ ekspertem od wizualizacji danych w Pythonie przy u≈ºyciu biblioteki Matplotlib.
        Twoim jedynym zadaniem jest napisanie fragmentu kodu w Pythonie.
        
        PLAN, KT√ìRY MASZ ZILUSTROWAƒÜ:
        {plan}

        --- KRYTYCZNE INFORMACJE ---
        DOSTƒòPNE KOLUMNY W DANYCH `df_processed`, KT√ìRYCH MO≈ªESZ U≈ªYƒÜ:
        {available_columns}
        --- KONIEC KRYTYCZNYCH INFORMACJI ---
        
        WA≈ªNE ZASADY:
        1.  **Generuj wykresy TYLKO dla kolumn, kt√≥re znajdujƒÖ siƒô na powy≈ºszej li≈õcie dostƒôpnych kolumn.**
        2.  Ka≈ºdy wykres musi mieƒá tytu≈Ç i czytelne etykiety osi.
        3.  U≈ºyj `fig.tight_layout()` przed dodaniem figury do listy.
        4.  **U≈ºywaj WY≈ÅƒÑCZNIE biblioteki `matplotlib.pyplot`. Nie u≈ºywaj `plotly` ani `seaborn`.**
        5.  NIE importuj bibliotek. Zak≈Çadaj, ≈ºe `matplotlib.pyplot as plt` i `pandas as pd` sƒÖ ju≈º dostƒôpne.
        6.  NIE tw√≥rz w≈Çasnych danych. U≈ºywaj wy≈ÇƒÖcznie ramek danych `df_original` i `df_processed`.
        7.  NIE u≈ºywaj `plt.show()`. Twoim zadaniem jest tylko stworzenie obiekt√≥w figur.
        8.  Ka≈ºdƒÖ stworzonƒÖ figurƒô (`fig`) MUSISZ dodaƒá do listy o nazwie `figures_to_embed`.
        9.  Twoja odpowied≈∫ musi zawieraƒá TYLKO i WY≈ÅƒÑCZNIE kod Pythona.
        10. **Twoja odpowied≈∫ MUSI byƒá obiektem JSON zawierajƒÖcym jeden klucz: "code", kt√≥rego warto≈õciƒÖ jest skrypt Pythona jako string.**
        """

    @staticmethod
    def create_meta_auditor_prompt(source_code: str, autogen_conversation: str, langgraph_log: str, final_code: str, final_report: str, escalation_report: Optional[str] = None) -> str:
        
        escalation_section = ""
        if escalation_report:
            escalation_section = f"""
# ===================================================================
# ### RAPORT Z ESKALACJI DO CZ≈ÅOWIEKA ###
# ===================================================================
UWAGA: System nie zdo≈Ça≈Ç samodzielnie rozwiƒÖzaƒá problemu i wymaga≈Ç interwencji. To jest najwa≈ºniejszy element do analizy.
{escalation_report}
"""
        
        return f"""**Persona:** G≈Ç√≥wny Audytor System√≥w AI. Twoim zadaniem jest krytyczna ocena ca≈Çego procesu AI.
        {escalation_section}
**Dostƒôpne Dane do Analizy:**
1. KOD ≈πR√ìD≈ÅOWY SYSTEMU:\n```python\n{source_code}\n```
2. ZAPIS ROZMOWY (PLANOWANIE):\n```\n{autogen_conversation}\n```
3. LOGI (WYKONANIE):\n```\n{langgraph_log}\n```
4. FINALNY KOD:\n```python\n{final_code}\n```
5. FINALNY RAPORT (fragment):\n```html\n{final_report[:2000]}\n```
**Zadania Audytorskie (odpowiedz na ka≈ºde pytanie):**
1. **Ocena Planowania:** Czy dyskusja Planner-Krytyk by≈Ça efektywna? Czy Krytyk by≈Ç rygorystyczny?
2. **Ocena Wykonania:** Czy by≈Çy pƒôtle naprawcze? Jak skuteczny by≈Ç debugger?
3. **Ocena Produktu:** Czy raport HTML jest u≈ºyteczny?
4. **Ocena Prompt√≥w Agent√≥w (Analiza Meta):**
    - Na podstawie analizy log√≥w i kodu ≈∫r√≥d≈Çowego, oce≈Ñ jako≈õƒá i precyzjƒô prompt√≥w dla poszczeg√≥lnych agent√≥w (Planner, Krytyk, Debugger, Generator Raportu).
    - Czy kt√≥ry≈õ z zaobserwowanych problem√≥w (nawet tych naprawionych) m√≥g≈Ç wynikaƒá z niejasno≈õci w prompcie?
    - Czy widzisz mo≈ºliwo≈õƒá ulepszenia kt√≥rego≈õ z prompt√≥w, aby system dzia≈Ça≈Ç bardziej niezawodnie lub efektywnie w przysz≈Ço≈õci?
5. **Rekomendacje do Samodoskonalenia:** Zaproponuj 1-3 konkretne zmiany w kodzie lub promptach, kt√≥re usprawniƒÖ system.
**Format Wyj≈õciowy:** Zwiƒôz≈Çy raport tekstowy."""
    
    
class ArchitecturalRule(TypedDict):
    id: str; description: str; check: Callable[[str], bool]; error_message: str

ARCHITECTURAL_RULES: List[ArchitecturalRule] = [
    {"id": "NO_MAIN_BLOCK", "description": "≈ªadnego bloku `if __name__ == '__main__':`.", "check": lambda code: bool(re.search(r'if\s+__name__\s*==\s*["\']__main__["\']\s*:', code)), "error_message": "Wykryto niedozwolony blok `if __name__ == '__main__':`."},
    {"id": "NO_ARGPARSE", "description": "≈ªadnego `argparse` ani `sys.argv`.", "check": lambda code: bool(re.search(r'import\s+argparse', code)), "error_message": "Wykryto niedozwolony import modu≈Çu `argparse`."},
    {"id": "SINGLE_FUNCTION_LOGIC", "description": "Ca≈Ça logika musi byƒá w funkcji `process_data(input_path: str, output_path: str)`.", "check": lambda code: "def process_data(input_path: str, output_path: str)" not in code, "error_message": "Brak wymaganej definicji funkcji `process_data(input_path: str, output_path: str)`."},
    {"id": "ENDS_WITH_CALL", "description": "Skrypt musi ko≈Ñczyƒá siƒô **dok≈Çadnie jednƒÖ liniƒÖ** w formacie: `process_data(input_path, output_path)  # noqa: F821`. Komentarz `# noqa: F821` jest **obowiƒÖzkowy**.", "check": lambda code: not re.search(r'^\s*process_data\(input_path,\s*output_path\)\s*#\s*noqa:\s*F821\s*$', [line for line in code.strip().split('\n') if line.strip()][-1]), "error_message": "Skrypt nie ko≈Ñczy siƒô wymaganym wywo≈Çaniem `process_data(input_path, output_path)  # noqa: F821`."},
]

class ArchitecturalRulesManager:
    @staticmethod
    def get_rules_as_string() -> str:
        rules_text = "\n".join(f"        - {rule['description']}" for rule in ARCHITECTURAL_RULES)
        return f"<ARCHITECTURAL_RULES>\n    **Krytyczne Wymagania DotyczƒÖce Struktury Kodu:**\n{rules_text}\n</ARCHITECTURAL_RULES>"


--- FILE: tools/__init__.py ---




--- FILE: tools/langchain_tools.py ---

from pydantic import BaseModel, Field
from langchain_core.tools import tool
from .utils import TOOL_REGISTRY
#--BaseModel

class DebugReport(BaseModel):
    analysis: str = Field(description="Techniczna analiza b≈Çƒôdu.")
    corrected_code: str = Field(description="Kompletny, poprawiony kod.")

    
class GeneratedPythonScript(BaseModel):
    """
    Model przechowujƒÖcy kompletny i gotowy do wykonania skrypt w Pythonie.
    """
    script_code: str = Field(description="Kompletny kod w Pythonie, gotowy do bezpo≈õredniego wykonania. Musi zawieraƒá wszystkie niezbƒôdne elementy, takie jak definicje, logikƒô i zapis pliku.")    
    

class CodeFixArgs(BaseModel):
    analysis: str = Field(description="Techniczna analiza przyczyny b≈Çƒôdu i wprowadzonej poprawki w kodzie.")
    corrected_code: str = Field(description="Pe≈Çny, kompletny i POPRAWIONY skrypt w Pythonie. Musi byƒá gotowy do wykonania.")
    
class PackageInstallArgs(BaseModel):
    package_name: str = Field(description="Nazwa pakietu, kt√≥ry nale≈ºy zainstalowaƒá, aby rozwiƒÖzaƒá b≈ÇƒÖd 'ModuleNotFoundError'. Np. 'scikit-learn', 'seaborn'.")
    analysis: str = Field(description="Kr√≥tka analiza potwierdzajƒÖca, ≈ºe przyczynƒÖ b≈Çƒôdu jest brakujƒÖcy pakiet.")

class ReportSummary(BaseModel):
    """Przechowuje podsumowanie analityczne w formacie HTML."""
    summary_html: str = Field(description="Tekst podsumowania w formacie HTML, zawierajƒÖcy tagi takie jak <h2> i <ul>.")

class PlottingCode(BaseModel):
    """Przechowuje kod Pythona do generowania wizualizacji."""
    code: str = Field(description="Czysty kod w Pythonie do generowania figur matplotlib.")


    
class InspectToolArgs(BaseModel):
    tool_name: str = Field(description="Nazwa funkcji/narzƒôdzia do inspekcji, np. 'embed_plot_to_html'.")
    
#narzƒôdzia dla langchain agent√≥w    
@tool(args_schema=CodeFixArgs)
def propose_code_fix(analysis: str, corrected_code: str) -> None:
    """U≈ºyj tego narzƒôdzia, aby zaproponowaƒá poprawionƒÖ wersjƒô kodu w odpowiedzi na b≈ÇƒÖd sk≈Çadniowy lub logiczny."""
    pass

@tool(args_schema=PackageInstallArgs)
def request_package_installation(package_name: str, analysis: str) -> None:
    """U≈ºyj tego narzƒôdzia, aby poprosiƒá o instalacjƒô brakujƒÖcej biblioteki, gdy napotkasz b≈ÇƒÖd 'ModuleNotFoundError'."""
    pass 


@tool(args_schema=InspectToolArgs)
def inspect_tool_code(tool_name: str) -> str:
    """U≈ºyj tego narzƒôdzia, aby przeczytaƒá kod ≈∫r√≥d≈Çowy wewnƒôtrznej funkcji systemowej.
    Jest to przydatne, gdy podejrzewasz, ≈ºe b≈ÇƒÖd (np. NameError) le≈ºy w narzƒôdziu, a nie w kodzie, kt√≥ry analizujesz."""
    if tool_name in TOOL_REGISTRY:
        source_code = inspect.getsource(TOOL_REGISTRY[tool_name])
        return f"Oto kod ≈∫r√≥d≈Çowy narzƒôdzia '{tool_name}':\n```python\n{source_code}\n```"
    return f"B≈ÅƒÑD: Nie znaleziono narzƒôdzia o nazwie '{tool_name}'."


--- FILE: tools/utils.py ---

import os
import io
import sys
import subprocess
import inspect
import matplotlib.pyplot as plt
import base64 
import tempfile
import traceback
import uuid
import json
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import datetime
import logging
from memory.memory_models import MemoryType

#--funkcja dla pamieci--
def intelligent_truncate(text: str, max_len: int) -> str:
    """Skraca tekst, zachowujƒÖc jego poczƒÖtek i koniec."""
    if not isinstance(text, str) or len(text) <= max_len:
        return text
    half_len = (max_len - 25) // 2
    start = text[:half_len]
    end = text[-half_len:]
    return f"{start}\n\n[... tre≈õƒá skr√≥cona ...]\n\n{end}"

def extract_python_code(response: str) -> str:
    response = response.strip()
    match = re.search(r'```python\n(.*?)\n```', response, re.DOTALL)
    if match: return match.group(1).strip()
    if response.startswith("'''") and response.endswith("'''"): return response[3:-3].strip()
    if response.startswith('"""') and response.endswith('"""'): return response[3:-3].strip()
    return response


def install_package(package_name: str, upgrade: bool = True) -> bool:
    """
    Instaluje lub aktualizuje podany pakiet u≈ºywajƒÖc pip.
    
    Args:
        package_name (str): Nazwa pakietu do instalacji.
        upgrade (bool): Je≈õli True, u≈ºywa flagi --upgrade.
    """
    try:
        command = [sys.executable, "-m", "pip", "install", package_name]
        if upgrade:
            command.insert(2, "--upgrade")
        
        action = "Aktualizacja" if upgrade else "Instalacja"
        print(f"  [INSTALATOR] Pr√≥ba: {action} pakietu {package_name}...")
        
        result = subprocess.run(command, check=True, capture_output=True, text=True)
        print(f"  [INSTALATOR] Pomy≈õlnie zako≈Ñczono. Logi pip:\n{result.stdout}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"  [INSTALATOR] B≈ÇƒÖd podczas operacji na pakiecie {package_name}.\n{e.stderr}")
        return False
    

    
#DLA report agenta
def embed_plot_to_html(figure) -> str:
    """Konwertuje figurƒô matplotlib do stringa base64 do osadzenia w HTML."""
    buffer = io.BytesIO()
    figure.savefig(buffer, format='png', bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    graphic = base64.b64encode(image_png)
    graphic = graphic.decode('utf-8')
    plt.close(figure) # Wa≈ºne: zamykamy figurƒô
    return f'<img src="data:image/png;base64,{graphic}" alt="Wykres analizy danych"/>'



#Dla meta agenta
def read_source_code(file_path: str) -> str:
    """Odczytuje zawarto≈õƒá pliku kodu ≈∫r√≥d≈Çowego."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f: return f.read()
    except Exception as e: return f"Nie uda≈Ço siƒô odczytaƒá kodu ≈∫r√≥d≈Çowego: {e}"


def read_project_source_code(root_dir=".", exclude_dirs=None, exclude_files=None): # <-- Dodaj nowy argument
    """
    Rekursywnie skanuje katalog projektu, odczytuje zawarto≈õƒá plik√≥w .py i .ipynb,
    i ≈ÇƒÖczy je w jeden, sformatowany string dla meta-audytora.
    """
    if exclude_dirs is None:
        exclude_dirs = {'__pycache__', '.ipynb_checkpoints', 'reports', '.git'}
    
    if exclude_files is None: # <-- Dodaj tƒô sekcjƒô
        exclude_files = set()

    full_source_code = ""
    for dirpath, dirnames, filenames in os.walk(root_dir):
        dirnames[:] = [d for d in dirnames if d not in exclude_dirs]
        
        for filename in filenames:
            if filename in exclude_files: # <-- Dodaj tƒô liniƒô, aby pomijaƒá pliki
                continue
            
            if filename.endswith(".py") or filename.endswith(".ipynb"):
                file_path = os.path.join(dirpath, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        full_source_code += f"--- FILE: {file_path} ---\n\n{content}\n\n"
                except Exception as e:
                    full_source_code += f"--- FILE: {file_path} ---\n\n[B≈ÅƒÑD ODCZYTU: {e}]\n\n"
                    
    return full_source_code

#Zapis planowania preprocessingu- AutoGen
def save_autogen_conversation_log(log_content: str, file_path: str):
    """Zapisuje pe≈ÇnƒÖ tre≈õƒá konwersacji agent√≥w AutoGen do pliku tekstowego."""
    print(f"INFO: Pr√≥ba zapisu pe≈Çnego logu rozmowy do pliku: {file_path}")
    try:
        # Upewniamy siƒô, ≈ºe katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PE≈ÅNY ZAPIS ROZMOWY AGENT√ìW (FAZA PLANOWANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"‚úÖ SUKCES: Log rozmowy zosta≈Ç pomy≈õlnie zapisany.")
    except Exception as e:
        print(f"‚ùå B≈ÅƒÑD: Nie uda≈Ço siƒô zapisaƒá logu rozmowy. Przyczyna: {e}")


        
#Zapis rozmowy agentow wykonowczych- LangChain        
def save_langgraph_execution_log(log_content: str, file_path: str):
    """Zapisuje pe≈Çny, szczeg√≥≈Çowy log z wykonania grafu LangGraph do pliku."""
    print(f"INFO: Pr√≥ba zapisu pe≈Çnego logu wykonania LangGraph do pliku: {file_path}")
    try:
        # Upewniamy siƒô, ≈ºe katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PE≈ÅNY ZAPIS WYKONANIA GRAFU LANGGRAPH (FAZA WYKONANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"‚úÖ SUKCES: Log wykonania LangGraph zosta≈Ç pomy≈õlnie zapisany.")
    except Exception as e:
        print(f"‚ùå B≈ÅƒÑD: Nie uda≈Ço siƒô zapisaƒá logu LangGraph. Przyczyna: {e}")  


def get_active_policies_from_memory(memory_client, dataset_signature: str) -> Optional[str]:
    """Odpytuje pamiƒôƒá o META_INSIGHTS i tworzy z nich tekst polityk."""
    print("--- DORADCA POLITYKI SYSTEMOWEJ: Sprawdzanie pamiƒôci... ---")
    
    meta_insights = memory_client.query_memory(
        query_text="Najwa≈ºniejsze rekomendacje dotyczƒÖce ulepszenia prompt√≥w lub logiki systemu",
        scope={"dataset_signature": dataset_signature},
        top_k=3
    )
    
    active_policies = []
    if meta_insights:
        for mem in meta_insights:
            if mem.memory_type == MemoryType.META_INSIGHT and 'recommendation' in mem.content:
                active_policies.append(f"- {mem.content['recommendation']}")
    
    if active_policies:
        policy_text = "--- AKTYWNE POLITYKI SYSTEMOWE (NAJWY≈ªSZY PRIORYTET) ---\n" + "\n".join(active_policies)
        print(f"  [INFO] Aktywowano polityki:\n{policy_text}")
        return policy_text
    
    print("  [INFO] Brak aktywnych polityk systemowych.")
    return None

        
TOOL_REGISTRY = {
    "embed_plot_to_html": embed_plot_to_html
}


--- FILE: agents/__init__.py ---




--- FILE: agents/autogen_agent_utils.py ---

import pandas as pd
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
from .autogen_agents import TriggerAgent,PlannerAgent,CriticAgent
import autogen
from autogen import Agent, ConversableAgent
from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent





#FUNKCJA CHATU GRUPOWEGO-WYMY≈öLANIE PLANU
def run_autogen_planning_phase(input_path: str,trigger_agent: TriggerAgent,planner_agent: PlannerAgent, critic_agent: CriticAgent, manager_agent_config:Dict,inspiration_prompt: str = "",active_policies: Optional[str] = None) -> Optional[str]:
    """
    Uruchamia fazƒô planowania z agentami AutoGen i zwraca finalny plan.
    """
    print("\n" + "="*80)
    print("### ### FAZA 1: URUCHAMIANIE PLANOWANIA STRATEGICZNEGO (AutoGen) ### ###")
    print("="*80 + "\n")

    try:
        df_summary = pd.read_csv(input_path, nrows=5)
        data_preview = f"Oto podglƒÖd danych:\n\nKolumny:\n{df_summary.columns.tolist()}\n\nPierwsze 5 wierszy:\n{df_summary.to_string()}"
        
        
        if active_policies:
            print("INFO: Do≈ÇƒÖczam aktywne polityki systemowe do fazy planowania.")
            data_preview += "\n\n" + active_policies
        
        
        if inspiration_prompt:
            print("INFO: Do≈ÇƒÖczam inspiracje z pamiƒôci do fazy planowania.")
            data_preview += "\n\n" + inspiration_prompt
        
    except Exception as e:
        logging.error(f"Nie mo≈ºna wczytaƒá pliku wej≈õciowego {input_path}: {e}")
        return None, ""
    
    
    
    user_proxy = autogen.UserProxyAgent(
       name="UserProxy",
       human_input_mode="NEVER",
       max_consecutive_auto_reply=10,
       is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
       code_execution_config=False,
       system_message="ZarzƒÖdzasz procesem. Przeka≈º podglƒÖd danych do TriggerAgenta. Nastƒôpnie moderuj dyskusjƒô miƒôdzy Plannerem a Krytykiem. Je≈õli w wiadomo≈õci znajdujƒÖ siƒô 'AKTYWNE POLITYKI SYSTEMOWE' lub 'INSPIRACJE Z POPRZEDNICH URUCHOMIE≈É', upewnij siƒô, ≈ºe przeka≈ºesz je w ca≈Ço≈õci Plannerowi."
    )

    def custom_speaker_selection_func(last_speaker: Agent, groupchat: autogen.GroupChat):
        messages = groupchat.messages

        # Warunek poczƒÖtkowy, pierwszy m√≥wi TriggerAgent
        if len(messages) <= 1:
            return trigger_agent

        # Standardowy przep≈Çyw: Trigger -> Planner -> Critic -> Planner ...
        elif last_speaker is trigger_agent:
            return planner_agent
        elif last_speaker is planner_agent:
            return critic_agent
        elif last_speaker is critic_agent:

            if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in messages[-1]['content']:
                return None # To elegancko ko≈Ñczy rozmowƒô
            else:
                # Je≈õli nie, wracamy do Plannera z uwagami
                return planner_agent
        else:
            # Sytuacja awaryjna lub koniec, nie wybieraj nikogo
            return None

    groupchat = autogen.GroupChat(
        agents=[user_proxy, trigger_agent, planner_agent, critic_agent],
        messages=[],
        max_round=15,
        speaker_selection_method=custom_speaker_selection_func
    )
    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=manager_agent_config)

    user_proxy.initiate_chat(manager, message=data_preview)

    # Ekstrakcja finalnego planu
    final_plan = None
    critic_messages = [msg['content'] for msg in groupchat.messages if msg['name'] == 'CriticAgent']
    for msg in reversed(critic_messages):
        if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in msg:
            match = re.search(r"OSTATECZNY PLAN:(.*)PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI", msg, re.DOTALL)
            if match:
                final_plan = match.group(1).strip()
                print("Faza planowania zako≈Ñczona. Ostateczny plan zosta≈Ç zaakceptowany.")
                break
    
    if not final_plan:
        print(" Faza planowania zako≈Ñczona bez akceptacji planu lub z powodu TERMINATE.")

    
    full_conversation_log = "\n\n".join([f"--- Komunikat od: {msg['name']} ---\n{msg['content']}" for msg in groupchat.messages])

    
    return final_plan, full_conversation_log



--- FILE: agents/autogen_agents.py ---

import autogen
from autogen import Agent, ConversableAgent


class TriggerAgent(ConversableAgent):
    """Agent decydujƒÖcy, czy dane nadajƒÖ siƒô do dalszego przetwarzania."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="TriggerAgent",
            llm_config=llm_config,
            system_message=prompt
        )

#PLANNER AGENT        
class PlannerAgent(ConversableAgent):
    """Agent tworzƒÖcy szczeg√≥≈Çowy plan przygotowania danych."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="PlannerAgent",
            llm_config=llm_config,
            system_message=prompt
        )

#CRITIC AGENT
class CriticAgent(ConversableAgent):
    """Agent oceniajƒÖcy plan i dbajƒÖcy o jego jako≈õƒá."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="CriticAgent",
            llm_config=llm_config,
            system_message=prompt
        )
        
        
        



--- FILE: agents/langgraph_nodes.py ---

import os
import io
import sys
import subprocess
import tempfile
import traceback
import uuid
import json
import re
import matplotlib.pyplot as plt
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import langchain
from langchain_google_vertexai import ChatVertexAI
from langchain_anthropic import ChatAnthropic
from .state import AgentWorkflowState
from prompts import LangchainAgentsPrompts
from tools.utils import *
from tools.langchain_tools import *
from prompts import ArchitecturalRule, ArchitecturalRulesManager,ARCHITECTURAL_RULES
from config import MAX_CORRECTION_ATTEMPTS, PROJECT_ID,LOCATION
from memory.memory_utils import *
from memory.memory_models import *
# --- Definicje wƒôz≈Ç√≥w LangGraph ---

def schema_reader_node(state: AgentWorkflowState):
    print("--- WƒòZE≈Å: ANALIZATOR SCHEMATU DANYCH ---")
    print(f"DEBUG: Pr√≥bujƒô odczytaƒá plik ze ≈õcie≈ºki: {state.get('input_path')}")
    try:
        df_header = pd.read_csv(state['input_path'], nrows=0)
        
        #pamiƒôƒá d≈Çugotrwa≈Ça, tworzenie sygnatury
        memory_client = state['memory_client']
        dataset_signature = memory_client.create_dataset_signature(df_header)
        print(f"INFO: Wygenerowano sygnaturƒô danych: {dataset_signature}")
        #--koniec--
        
        return {"available_columns": df_header.columns.tolist(),"dataset_signature": dataset_signature}
    except Exception as e:
        return {"error_message": f"B≈ÇƒÖd odczytu pliku: {e}", "failing_node": "schema_reader"}

def code_generator_node(state: AgentWorkflowState):
    print("---  WƒòZE≈Å: GENERATOR KODU ---")
    
    
    CODE_MODEL=state['config']['CODE_MODEL']
    
    llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    prompt = LangchainAgentsPrompts.code_generator(state['plan'], state['available_columns'])
    response = llm.invoke(prompt).content
    code = extract_python_code(response)
    
    print("\nAgent-Analityk wygenerowa≈Ç nastƒôpujƒÖcy kod:")
    print("--------------------------------------------------")
    print(code)
    print("--------------------------------------------------")
    return {"generated_code": code}


def architectural_validator_node(state: AgentWorkflowState):
    print("--- üõ°Ô∏è WƒòZE≈Å: STRA≈ªNIK ARCHITEKTURY üõ°Ô∏è ---")
    code_to_check = state.get('generated_code', '')
    if not code_to_check:
        error_message = "Brak kodu do walidacji."
        print(f"  [WERDYKT] ‚ùå {error_message}")
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": "", "correction_attempts": state.get('correction_attempts', 0) + 1}

    errors = [rule["error_message"] for rule in ARCHITECTURAL_RULES if rule["check"](code_to_check)]
    
    if errors:
        error_message = "B≈ÇƒÖd Walidacji Architektonicznej: " + " ".join(errors)
        # <<< WA≈ªNY PRINT >>>
        print(f"  [WERDYKT] ‚ùå Kod ≈Çamie zasady architektury: {' '.join(errors)}")
        
        pending_session = {
            "initial_error": error_message,  # U≈ºywamy b≈Çƒôdu walidacji jako b≈Çƒôdu poczƒÖtkowego
            "initial_code": code_to_check,
            "fix_attempts": []
        }
        
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": code_to_check, "correction_attempts": state.get('correction_attempts', 0) + 1}
    else:
        # <<< WA≈ªNY PRINT >>>
        print("  [WERDYKT] Kod jest zgodny z architekturƒÖ systemu.")
        return {"error_message": None, "pending_fix_session": None}

    
def data_code_executor_node(state: AgentWorkflowState):
    """
    Wykonuje finalny kod do przetwarzania danych.
    """
    print("--- WƒòZE≈Å: WYKONANIE KODU DANYCH  ---")
    try:
        print("  [INFO] Uruchamiam ostatecznie zatwierdzony kod...")
        
        # Definiujemy ≈õrodowisko wykonawcze tylko z niezbƒôdnymi bibliotekami
        exec_scope = {
            'pd': pd,
            'input_path': state['input_path'],
            'output_path': state['output_path']
        }
        
        exec(state['generated_code'], exec_scope)
        
        print("  [WYNIK] Kod wykonany pomy≈õlnie.")
        return {"error_message": None, "correction_attempts": 0}
        
    except Exception as e:
        error_traceback = traceback.format_exc()
        print(f"  [B≈ÅƒÑD] WystƒÖpi≈Ç b≈ÇƒÖd. Przekazywanie do inteligentnego debuggera:\n{error_traceback}")
        
        #--pamiƒôƒá d≈Çugotrwa≈Ça: zapis b≈Çƒôdu, sesja tymczasowa
        
        pending_session = {
            "initial_error": error_traceback,
            "initial_code": state['generated_code'],
            "fix_attempts": []  # Pusta lista na przysz≈Çe pr√≥by naprawy
        }
        #--koniec--
        
        return {
            "failing_node": "data_code_executor", 
            "error_message": error_traceback, 
            "error_context_code": state['generated_code'], 
            "correction_attempts": state.get('correction_attempts', 0) + 1,
            "pending_fix_session": pending_session
        }

    
def universal_debugger_node(state: AgentWorkflowState):
    print(f"--- WƒòZE≈Å: INTELIGENTNY DEBUGGER (B≈ÇƒÖd w: {state.get('failing_node')}) ---")
    failing_node_name = state.get('failing_node', 'unknown')
    
    
    
    MAIN_AGENT=state['config']['MAIN_AGENT']
    # llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    llm = ChatVertexAI(model_name=MAIN_AGENT,temperature=0.0, project=PROJECT_ID, location=LOCATION)
    tools = [propose_code_fix, request_package_installation, inspect_tool_code]
    llm_with_tools = llm.bind_tools(tools)
    prompt = LangchainAgentsPrompts.tool_based_debugger(failing_node=failing_node_name,active_policies=state.get("active_policies"))
    error_context = f"Wadliwy Kontekst:\n```\n{state['error_context_code']}\n```\n\nB≈ÇƒÖd:\n```\n{state['error_message']}\n```"
    response = llm_with_tools.invoke(prompt + error_context)
    if not response.tool_calls:
        print("  [B≈ÅƒÑD DEBUGGERA] Agent nie wybra≈Ç ≈ºadnego narzƒôdzia. Eskalacja.")
        return {"error_message": "Debugger nie by≈Ç w stanie podjƒÖƒá decyzji.", "failing_node": "universal_debugger"}
    chosen_tool = response.tool_calls[0]
    tool_name = chosen_tool['name']
    tool_args = chosen_tool['args']
    print(f"  [DIAGNOZA] Debugger wybra≈Ç narzƒôdzie: '{tool_name}' z argumentami: {tool_args}")
    return {"tool_choice": tool_name, "tool_args": tool_args, "debugger_analysis": tool_args.get("analysis", "")}


def apply_code_fix_node(state: AgentWorkflowState):
    """Aplikuje poprawkƒô kodu zaproponowanƒÖ przez debuggera."""
    print("--- WƒòZE≈Å: APLIKOWANIE POPRAWKI KODU ---")
    
    CODE_MODEL=state['config']['CODE_MODEL']
    
    analysis = state.get("debugger_analysis", "")
    corrected_code = state.get("tool_args", {}).get("corrected_code")
    failing_node = state.get("failing_node")
    
    
    if not corrected_code:
        print("  [OSTRZE≈ªENIE] Debugger nie dostarczy≈Ç kodu. Wymuszam jego wygenerowanie...")
        
        # Tworzymy bardzo prosty prompt, kt√≥ry ma tylko jedno zadanie
        force_prompt = f"""Na podstawie poni≈ºszej analizy i wadliwego kodu, wygeneruj PE≈ÅNY, POPRAWIONY i gotowy do uruchomienia skrypt Pythona.
        Twoja odpowied≈∫ musi zawieraƒá TYLKO i WY≈ÅƒÑCZNIE blok kodu, bez ≈ºadnych dodatkowych wyja≈õnie≈Ñ.

        [ANALIZA B≈ÅƒòDU]:
        {analysis}

        [WADLIWY KOD]:
        ```python
        {state['error_context_code']}"""
        
        
        try:
            llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
            response = llm.invoke(force_prompt).content
            corrected_code = extract_python_code(response) # U≈ºywamy istniejƒÖcej funkcji pomocniczej
            print("  [INFO] Pomy≈õlnie wymuszono wygenerowanie kodu.")
        except Exception as e:
            print(f"  [B≈ÅƒÑD KRYTYCZNY] Nie uda≈Ço siƒô wymusiƒá generacji kodu: {e}")
            return {"error_message": "Nie uda≈Ço siƒô naprawiƒá kodu nawet po eskalacji."}
        
        
    #--pamiƒôƒá d≈Çugotrwa≈Ça info dla pamieci--
    
    update = {
        "error_message": None, 
        "tool_choice": None, 
        "tool_args": None
    }

    if failing_node == "plot_generator_node":
        print("  [INFO] Aplikowanie poprawki do kodu generujƒÖcego wykresy.")
        update["plot_generation_code"] = corrected_code
    elif failing_node == "summary_analyst_node":
        print("  [INFO] Aplikowanie poprawki do podsumowania HTML.")
        update["summary_html"] = corrected_code
    else: # Domy≈õlnie traktuj jako g≈Ç√≥wny kod
        print("  [INFO] Aplikowanie poprawki do g≈Ç√≥wnego kodu przetwarzania danych.")
        update["generated_code"] = corrected_code

    session = state.get('pending_fix_session')
    if not session:
        # Sytuacja awaryjna, nie powinno siƒô zdarzyƒá w normalnym przep≈Çywie
        print("  [OSTRZE≈ªENIE] Pr√≥ba aplikacji poprawki bez aktywnej sesji naprawczej.")
        session = {}

    # Dodajemy informacje o tej konkretnej pr√≥bie do listy w sesji
    attempt_info = {
        "debugger_analysis": state.get("debugger_analysis", "Brak analizy."),
        "corrected_code": corrected_code,
        "attempt_number": len(session.get("fix_attempts", [])) + 1
    }
    
    if "fix_attempts" in session:
        session["fix_attempts"].append(attempt_info)
    else:
        session["fix_attempts"] = [attempt_info]
    
    print(f"  [INFO] Dodano pr√≥bƒô naprawy nr {attempt_info['attempt_number']} do sesji.")
    
    
    #--koniec--
    
    return {
        "generated_code": corrected_code, 
        "error_message": None, 
        "tool_choice": None, 
        "tool_args": None,
        "pending_fix_session": session  # Aktualizujemy sesjƒô w stanie
    }


def human_approval_node(state: AgentWorkflowState):
    print("\n" + "="*80 + "\n### WYMAGANA AKCJA CZ≈ÅOWIEKA  ###\n" + "="*80)
    package_name = state.get("tool_args", {}).get("package_name")
    user_input = input(f"Agent chce zainstalowaƒá pakiet '{package_name}'. Czy zgadzasz siƒô? [y/n]: ").lower().strip()
    if user_input == 'y':
        print("Zgoda. Przechodzenie do instalacji.")
        return {"user_approval_status": "APPROVED", "package_to_install": package_name}
    else:
        print("Odrzucono. Przekazywanie do debuggera w celu znalezienia alternatywy.")
        new_error_message = f"Instalacja pakietu '{package_name}' zosta≈Ça odrzucona przez u≈ºytkownika. Zmodyfikuj kod, aby nie u≈ºywa≈Ç tej zale≈ºno≈õci."
        return {"user_approval_status": "REJECTED", "error_message": new_error_message}


def package_installer_node(state: AgentWorkflowState):
    """Instaluje lub aktualizuje pakiet po uzyskaniu zgody."""
    package_name = state.get("package_to_install")
    
    # Domy≈õlnie pr√≥bujemy aktualizacji, bo to rozwiƒÖzuje problemy z zale≈ºno≈õciami
    success = install_package(package_name, upgrade=True)
    
    if success:
        return {"package_to_install": None, "user_approval_status": None, "error_message": None}
    else:
        return {"error_message": f"Operacja na pakiecie '{package_name}' nie powiod≈Ça siƒô.", "failing_node": "package_installer"}

def commit_memory_node(state: AgentWorkflowState) -> Dict[str, Any]:
    """Zapisuje skonsolidowanƒÖ wiedzƒô do pamiƒôci po udanej naprawie kodu."""
    session = state.get('pending_fix_session')
    
    # Je≈õli nie ma sesji (np. kod zadzia≈Ça≈Ç za 1. razem), nie r√≥b nic
    if not session or not session.get("fix_attempts"):
        return {"pending_fix_session": None}

    print("--- WƒòZE≈Å: ZATWIERDZANIE WIEDZY W PAMIƒòCI ---")
    
    distilled_content = distill_full_fix_session(
        initial_error=session['initial_error'],
        fix_attempts=session['fix_attempts'],
        successful_code=state['generated_code']
    )
    
    memory_client = state['memory_client']
    final_record = MemoryRecord(
        run_id=state['run_id'],
        memory_type=MemoryType.SUCCESSFUL_FIX, # Teraz to jest prawdziwy sukces
        dataset_signature=state['dataset_signature'],
        source_node="commit_memory_node",
        content=distilled_content,
        metadata={"total_attempts": len(session['fix_attempts'])}
    )
    memory_client.add_memory(final_record)
    
    # Wyczy≈õƒá sesjƒô po udanym zapisie
    return {"pending_fix_session": None} 

    
    
def summary_analyst_node(state: AgentWorkflowState) -> Dict[str, str]:
    """
    Agent, kt√≥rego jedynym zadaniem jest analiza i stworzenie podsumowania tekstowego w HTML.
    """
    print("--- WƒòZE≈Å: ANALITYK PODSUMOWANIA ---")
    try:
        # Krok 1: Przygotuj dane wej≈õciowe dla promptu
        df_original = pd.read_csv(state['input_path'])
        df_processed = pd.read_csv(state['output_path'])

        original_info_buf = io.StringIO()
        df_original.info(buf=original_info_buf)
        processed_info_buf = io.StringIO()
        df_processed.info(buf=processed_info_buf)

        original_summary = f"Podsumowanie danych ORYGINALNYCH:\n{df_original.describe().to_string()}\n{original_info_buf.getvalue()}"
        processed_summary = f"Podsumowanie danych PRZETWORZONYCH:\n{df_processed.describe().to_string()}\n{processed_info_buf.getvalue()}"

        # === POPRAWKA: U≈ºycie dedykowanego promptu ===
        prompt = LangchainAgentsPrompts.summary_analyst_prompt(
            plan=state['plan'],
            original_summary=original_summary,
            processed_summary=processed_summary
        )
        
        llm = ChatAnthropic(model_name=state['config']['CODE_MODEL'], temperature=0.0, max_tokens=1024)
        structured_llm = llm.with_structured_output(ReportSummary)
        response = structured_llm.invoke(prompt)
        
        print("  [INFO] Analityk wygenerowa≈Ç podsumowanie HTML.")
        return {"summary_html": response.summary_html}
        
    except Exception as e:
        error_msg = f"B≈ÇƒÖd w analityku podsumowania: {traceback.format_exc()}"
        print(f"  [B≈ÅƒÑD] {error_msg}")
        return {
            "error_message": error_msg,
            "failing_node": "summary_analyst_node",
            "error_context_code": state.get('plan', 'Brak planu w stanie do analizy.'),
            "correction_attempts": state.get("correction_attempts", 0) + 1  # <-- DODAJ Tƒò LINIƒò
        }


def plot_generator_node(state: AgentWorkflowState) -> Dict[str, str]:
    """
    Agent, kt√≥rego jedynym zadaniem jest wygenerowanie KODU do tworzenia wykres√≥w.
    """
    print("--- WƒòZE≈Å: GENERATOR WIZUALIZACJI ---")
    try:
        # --- NOWY KROK: POBIERZ AKTUALNE KOLUMNY Z PRZETWORZONEGO PLIKU ---
        df_processed_cols = pd.read_csv(state['output_path'], nrows=0).columns.tolist()

        # Przeka≈º aktualne kolumny do promptu, aby agent wiedzia≈Ç, na czym pracuje
        prompt = LangchainAgentsPrompts.plot_generator_prompt(
            plan=state['plan'],
            available_columns=df_processed_cols  # Przekazanie nowej informacji
        )
        
        MAIN_AGENT = state['config']['MAIN_AGENT']
        llm = ChatVertexAI(model_name=MAIN_AGENT, temperature=0.0, project=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(PlottingCode)
        
        response = structured_llm.invoke(prompt)
        cleaned_code = extract_python_code(response.code)
        
        print("  [INFO] Generator stworzy≈Ç kod do wizualizacji.")
        return {"plot_generation_code": cleaned_code}
        

    except Exception as e:
        error_msg = f"B≈ÇƒÖd w generatorze wizualizacji: {traceback.format_exc()}"
        print(f"  [B≈ÅƒÑD] {error_msg}")
        return {
            "error_message": error_msg,
            "failing_node": "plot_generator_node",
            "error_context_code": state.get('plan', 'Brak planu w stanie do analizy.'),
            "correction_attempts": state.get("correction_attempts", 0) + 1
        }


def report_composer_node(state: AgentWorkflowState) -> Dict[str, Any]:
    """
    Wƒôze≈Ç, kt√≥ry sk≈Çada podsumowanie i wykresy w finalny raport HTML. Nie u≈ºywa LLM.
    """
    print("--- WƒòZE≈Å: KOMPOZYTOR RAPORTU ---")
    try:
        summary_html = state.get("summary_html")
        plot_code = state.get("plot_generation_code")
        
        if not summary_html or not plot_code:
            raise ValueError("Brak podsumowania lub kodu do generowania wykres√≥w w stanie.")

        # 1. Przygotuj ≈õrodowisko wykonawcze dla kodu z wykresami
        exec_scope = {
            'pd': pd,
            'plt': plt,
            'df_original': pd.read_csv(state['input_path']),
            'df_processed': pd.read_csv(state['output_path']),
            'figures_to_embed': []
        }

        # 2. Wykonaj kod od agenta, aby wygenerowaƒá obiekty figur
        exec(plot_code, exec_scope)
        figures = exec_scope['figures_to_embed']
        print(f"  [INFO] Wykonano kod i wygenerowano {len(figures)} wykres(y).")

        # 3. Skonwertuj figury na tagi <img> z base64
        figures_html = ""
        for i, fig in enumerate(figures):
            figures_html += f"<h3>Wykres {i+1}</h3>{embed_plot_to_html(fig)}"

        # 4. Z≈Ç√≥≈º finalny raport HTML
        final_html = f"""
        <!DOCTYPE html>
        <html lang="pl">
        <head>
            <meta charset="UTF-8">
            <title>Raport z Analizy Danych</title>
            <style>
                body {{ font-family: sans-serif; margin: 2em; background-color: #f9f9f9; }}
                .container {{ max-width: 1000px; margin: auto; background: #fff; padding: 2em; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                h1, h2, h3 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 5px;}}
                img {{ max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px; border-radius: 4px; margin-top: 1em; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Raport z Przetwarzania Danych</h1>
                {summary_html}
                <h2>Wizualizacje</h2>
                {figures_html}
            </div>
        </body>
        </html>
        """

        # 5. Zapisz plik
        with open(state['report_output_path'], 'w', encoding='utf-8') as f:
            f.write(final_html)
            
        print(f"‚úÖ Raport zosta≈Ç pomy≈õlnie wygenerowany w {state['report_output_path']}")
        return {}

    except Exception as e:
        error_msg = f"B≈ÇƒÖd w kompozytorze raportu: {traceback.format_exc()}"
        print(f"  [B≈ÅƒÑD] {error_msg}")
        return {
            "error_message": error_msg, 
            "failing_node": "report_composer_node",
            "error_context_code": state.get("plot_generation_code", "Brak kodu do analizy."),
            "correction_attempts": state.get("correction_attempts", 0) + 1
        }
    
    
    
    

    
def sync_report_code_node(state: AgentWorkflowState):
    """Synchronizuje naprawiony kod z powrotem do stanu agenta raportujƒÖcego."""
    print("--- WƒòZE≈Å: SYNCHRONIZACJA KODU RAPORTU ---")
    corrected_code = state.get("generated_code")
    return {"generated_report_code": corrected_code}   
    
    
def meta_auditor_node(state: AgentWorkflowState):
    """Uruchamia audytora ORAZ zapisuje wspomnienia o sukcesie i wnioski META."""
    print("\n" + "="*80 + "\n### ### FAZA 3: META-AUDYT I KONSOLIDACJA WIEDZY ### ###\n" + "="*80 + "\n")
    memory_client = state['memory_client']

    if not state.get("escalation_report_path"):
        try:
            print("  [INFO] Uruchamiam proces destylacji wspomnienia o sukcesie...")
            # --- ZMIANA 2: Zabezpieczenie przed limitem token√≥w ---
            truncated_plan = intelligent_truncate(state.get('plan', ''), 3000)
            distilled_content = distill_success_memory(final_plan=truncated_plan)
            
            if distilled_content and distilled_content.get("key_insight"):
                # Dodatkowe zabezpieczenie dla wyniku destylacji
                distilled_content["key_insight"] = intelligent_truncate(distilled_content["key_insight"], 2000)

                plan_record = MemoryRecord(
                    run_id=state['run_id'],
                    memory_type=MemoryType.SUCCESSFUL_PLAN,
                    dataset_signature=state['dataset_signature'],
                    source_node="meta_auditor_node",
                    content=distilled_content,
                    metadata={"importance_score": 0.8}
                )
                memory_client.add_memory(plan_record)
        except Exception as e:
            print(f"  [B≈ÅƒÑD ZAPISU PAMIƒòCI] Nie uda≈Ço siƒô zapisaƒá udanego planu: {e}")
    
    # 2. Uruchom audytora (logika bez zmian)
    try:
        
        CRITIC_MODEL=state['config']['CRITIC_MODEL']
        
        escalation_report_content = None
        escalation_path = state.get("escalation_report_path")
        if escalation_path:
            print(f"  [INFO] Wykryto raport z eskalacji. Wczytywanie pliku: {escalation_path}")
            try:
                with open(escalation_path, 'r', encoding='utf-8') as f:
                    escalation_report_content = f.read()
            except Exception as e:
                print(f"  [OSTRZE≈ªENIE] Nie uda≈Ço siƒô wczytaƒá pliku z eskalacjƒÖ: {e}")
        
        
        
        # ... (ca≈Ça logika generowania raportu audytora, tak jak w oryginale)
        # Za≈Ç√≥≈ºmy, ≈ºe wynikiem jest zmienna 'audit_report'
        final_report_content = "Brak raportu do analizy."
        try:
            with open(state['report_output_path'], 'r', encoding='utf-8') as f:
                final_report_content = f.read()
        except Exception: pass
        
        llm = ChatAnthropic(model_name=CRITIC_MODEL, temperature=0.0, max_tokens=2048)
        prompt = LangchainAgentsPrompts.create_meta_auditor_prompt(
            source_code=intelligent_truncate(state['source_code'], 8000),
            autogen_conversation=intelligent_truncate(state['autogen_log'], 6000),
            langgraph_log=intelligent_truncate(state.get('langgraph_log', ''), 6000),
            final_code=state.get('generated_code', 'Brak kodu'),
            final_report=final_report_content,
            escalation_report=escalation_report_content
        )
        audit_report = llm.invoke(prompt).content
        # ... (zapis raportu do pliku)

        
        
        try:
            audit_report_path = "reports/meta_audit_report.txt"
            print(f"  [INFO] Zapisywanie raportu z audytu do: {audit_report_path}")
            with open(audit_report_path, "w", encoding="utf-8") as f:
                f.write("="*50 + "\n")
                f.write("### RAPORT Z META-AUDYTU SYSTEMU AI ###\n")
                f.write("="*50 + "\n\n")
                f.write(audit_report)
            print(f"  [SUKCES] Pomy≈õlnie zapisano raport z audytu.")
        except Exception as e:
            print(f"  [B≈ÅƒÑD] Nie uda≈Ço siƒô zapisaƒá raportu z audytu: {e}")
        
        # 3. WYGENERUJ I ZAPISZ WNIOSEK META
        meta_insight_content = generate_meta_insight(audit_report)
        if meta_insight_content:
            insight_record = MemoryRecord(
                run_id=state['run_id'], memory_type=MemoryType.META_INSIGHT,
                dataset_signature=state['dataset_signature'], source_node="meta_auditor_node",
                content=meta_insight_content, metadata={"importance_score": 1.0}
            )
            memory_client.add_memory(insight_record)

    except Exception as e:
        print(f"B≈ÅƒÑD KRYTYCZNY podczas meta-audytu: {e}")
    return {}

    
    
def human_escalation_node(state: AgentWorkflowState):
    """Wƒôze≈Ç eskalacji (bez zmian)."""
    print("\n==================================================")
    print(f"--- WƒòZE≈Å: ESKALACJA DO CZ≈ÅOWIEKA---")
    print("==================================================")
    # ... (reszta kodu bez zmian)
    report_content = f"""
Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Problem: Przekroczono maksymalny limit ({MAX_CORRECTION_ATTEMPTS}) pr√≥b automatycznej naprawy.

Ostatnia analiza debuggera:
{state.get('debugger_analysis', 'Brak analizy.')}

Ostatni kod, kt√≥ry zawi√≥d≈Ç:
```python
{state.get('error_context_code', 'Brak kodu.')}
```

Pe≈Çny traceback ostatniego b≈Çƒôdu:
{state.get('error_message', 'Brak b≈Çƒôdu.')}
"""
    file_name = f"reports/human_escalation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(file_name, "w", encoding="utf-8") as f: f.write(report_content)
    print(f"  [INFO] Raport dla cz≈Çowieka zosta≈Ç zapisany w pliku: {file_name}")
    return {"escalation_report_path": file_name}



--- FILE: agents/state.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
from memory.memory_bank_client import MemoryBankClient

#Zmienne przekazywane do grafu LangChian
class AgentWorkflowState(TypedDict):
    config: Dict[str, Any]
    plan: str; input_path: str; output_path: str; report_output_path: str
    available_columns: List[str]; generated_code: str; generated_report_code: str
    correction_attempts: int; error_message: Optional[str]; failing_node: Optional[str]
    error_context_code: Optional[str]; debugger_analysis: Optional[str]
    package_to_install: Optional[str]; user_approval_status: Optional[str]
    tool_choice: Optional[str]; tool_args: Optional[Dict]
    source_code: str
    autogen_log: str
    langgraph_log: str
    # --- Pola pamiƒôci ---
    run_id: str
    dataset_signature: str
    error_record_id: Optional[str]
    memory_client: MemoryBankClient
    pending_fix_session: Optional[Dict[str, Any]]
    generated_code: str # Dla g≈Ç√≥wnego kodu
    summary_html: str # Wynik z summary_analyst
    plot_generation_code: str # Wynik z plot_generator
    escalation_report_path: Optional[str]


--- FILE: memory/__init__.py ---




--- FILE: memory/memory_bank_client.py ---

import json
import hashlib
import pandas as pd
from typing import Dict, List, Optional
import vertexai
from vertexai import agent_engines
from .memory_models import MemoryRecord


class MemoryBankClient:
    def __init__(self, client: vertexai.Client, agent_engine):
        """
        Inicjalizuje klienta z g≈Ç√≥wnym obiektem klienta Vertex AI 
        oraz z gotowym obiektem agent_engine.
        """
        if not client or not agent_engine:
            raise ValueError("Klient Vertex AI oraz Agent Engine muszƒÖ byƒá poprawnie zainicjalizowane.")
        
        self.client = client
        self.agent_engine = agent_engine
        self.engine_name = agent_engine.resource_name
        print(f"INFO: MemoryBankClient gotowy do pracy z silnikiem: {self.engine_name}")
        
    
    
    
    def create_dataset_signature(self, df_preview: pd.DataFrame) -> str:
        """Tworzy unikalny identyfikator dla zbioru danych."""
        s = "".join(df_preview.columns) + str(df_preview.shape)
        return hashlib.md5(s.encode()).hexdigest()

    def add_memory(self, record: MemoryRecord):
        """Zapisuje ustrukturyzowane wspomnienie w Agent Engine."""
        try:
            fact_to_remember = record.model_dump_json()
            scope = {"dataset_signature": record.dataset_signature}
            
            
            self.client.agent_engines.create_memory(
                name=self.engine_name,
                fact=fact_to_remember, 
                scope=scope
            )
            print(f"INFO: Zapisano wspomnienie typu '{record.memory_type}' w zakresie {scope}")
        except Exception as e:
            print(f"B≈ÅƒÑD ZAPISU PAMIƒòCI: {e}")

#     def query_memory(self, query_text: str, scope: Dict, top_k: int = 5) -> List[MemoryRecord]:
#         """
#         Odpytuje pamiƒôƒá semantycznie i zwraca listƒô ustrukturyzowanych wspomnie≈Ñ.
#         """
#         retrieved_mems = []
#         try:
#             print(f"INFO: Odpytujƒô pamiƒôƒá semantycznie z zapytaniem '{query_text}' w zakresie {scope}")

#             # Tworzymy s≈Çownik z parametrami wyszukiwania, zgodnie z Twoim znaleziskiem
#             search_params = {
#                 "search_query": query_text,
#                 "top_k": top_k
#             }

#             # Wywo≈Çujemy API z poprawnym argumentem: similarity_search_params
#             memories_iterator = self.client.agent_engines.retrieve_memories(
#                 name=self.engine_name,
#                 scope=scope,
#                 similarity_search_params=search_params
#             )

#             for mem in memories_iterator:
#                 print("mem", dir(mem))
#                 record = MemoryRecord.model_validate_json(mem.memory)
#                 retrieved_mems.append(record)

#             print(f"INFO: Znaleziono {len(retrieved_mems)} pasujƒÖcych wspomnie≈Ñ.")
#             return retrieved_mems

#         except Exception as e:
#             print(f"B≈ÅƒÑD ODCZYTU PAMIƒòCI: {e}")
#             return []
        
        
    def query_memory(self, query_text: str, scope: Dict, top_k: int = 5) -> List[MemoryRecord]:
        """
        Odpytuje pamiƒôƒá semantycznie, poprawnie odczytujƒÖc zagnie≈ºd≈ºonƒÖ tre≈õƒá wspomnienia.
        """
        retrieved_mems = []
        try:
            print(f"INFO: Odpytujƒô pamiƒôƒá semantycznie z zapytaniem '{query_text}' w zakresie {scope}")

            search_params = {
                "search_query": query_text,
                "top_k": top_k
            }

            memories_iterator = self.client.agent_engines.retrieve_memories(
                name=self.engine_name,
                scope=scope,
                similarity_search_params=search_params
            )

            for i, mem in enumerate(memories_iterator):
                try:

                    json_string_to_parse = mem.memory.fact

                    record = MemoryRecord.model_validate_json(json_string_to_parse)
                    retrieved_mems.append(record)
                    print("udany plan:", record)
                except Exception as e:
                    print(f"‚ö†Ô∏è OSTRZE≈ªENIE: Pominiƒôto uszkodzony lub niekompatybilny rekord pamiƒôci (pozycja {i}). B≈ÇƒÖd: {e}")
                    continue

            print(f"INFO: Znaleziono i poprawnie przetworzono {len(retrieved_mems)} pasujƒÖcych wspomnie≈Ñ.")
            return retrieved_mems

        except Exception as e:
            print(f"KRYTYCZNY B≈ÅƒÑD ODCZYTU PAMIƒòCI: Nie uda≈Ço siƒô wykonaƒá zapytania. B≈ÇƒÖd: {e}")
            return []


--- FILE: memory/memory_models.py ---

from datetime import datetime
from enum import Enum
from typing import Dict, Any, List, Optional
from pydantic import BaseModel, Field
import uuid

class MemoryType(str, Enum):
    SUCCESSFUL_PLAN = "SUCCESSFUL_PLAN"
    EXECUTION_ERROR = "EXECUTION_ERROR"
    SUCCESSFUL_FIX = "SUCCESSFUL_FIX"
    META_INSIGHT = "META_INSIGHT"

    

class MemoryRecord(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    run_id: str # Dodajemy ID bie≈ºƒÖcego uruchomienia
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    memory_type: MemoryType
    dataset_signature: str
    source_node: str
    content: Dict[str, Any]
    metadata: Dict[str, Any] = Field(default_factory=dict)

class DistilledMemory(BaseModel):
    """Ustrukturyzowany, 'ekspercki' format dla przedestylowanego wspomnienia."""
    problem_summary: str = Field(description="Opis problemu w jednym, zwiƒôz≈Çym zdaniu.")
    solution_summary: str = Field(description="Opis rozwiƒÖzania w jednym, zwiƒôz≈Çym zdaniu.")
    applicability_context: str = Field(description="Opis w jednym zdaniu, w jakim kontek≈õcie (np. typ danych, operacja) ta lekcja jest najbardziej u≈ºyteczna.")
    key_takeaway: str = Field(description="Uniwersalna 'z≈Çota my≈õl' lub regu≈Ça na przysz≈Ço≈õƒá, aby uniknƒÖƒá podobnych b≈Çƒôd√≥w.")
    reusable_code_snippet: Optional[str] = Field(description="Generyczny fragment kodu w Pythonie (do 10 linijek), kt√≥ry implementuje 'key_takeaway'. Je≈õli nie ma zastosowania, zwr√≥ƒá null.")
    tags: List[str] = Field(description="Lista 3-5 s≈Ç√≥w kluczowych (tag√≥w) opisujƒÖcych ten problem.")
    
    
 #--czysty zapis o sukcesie   
class DistilledSuccessMemory(BaseModel):
    """Ustrukturyzowany format dla wspomnienia o udanym przebiegu."""
    plan_summary: str = Field(description="Podsumowanie celu i kluczowych krok√≥w zrealizowanego planu w jednym zdaniu.")
    key_insight: str = Field(description="Najwa≈ºniejszy wniosek lub 'trick', kt√≥ry przyczyni≈Ç siƒô do sukcesu tego planu.")
    full_plan_text: str = Field(description="Pe≈Çny, szczeg√≥≈Çowy, numerowany tekst udanego planu.")
    tags: List[str] = Field(description="Lista 3-5 s≈Ç√≥w kluczowych (tag√≥w) opisujƒÖcych ten plan.")
    
class MetaInsightMemory(BaseModel):
    """Ustrukturyzowany format dla WNIOSKU NA POZIOMIE SYSTEMU."""
    observation: str = Field(description="Zwiƒôz≈Çe opisanie zaobserwowanego zjawiska, np. 'Agent generujƒÖcy raporty czƒôsto pope≈Çnia≈Ç b≈Çƒôdy w wizualizacji danych szereg√≥w czasowych'.")
    recommendation: str = Field(description="Konkretna, pojedyncza propozycja zmiany w prompcie lub logice systemu, np. 'Do promptu agenta raportujƒÖcego nale≈ºy dodaƒá konkretny przyk≈Çad u≈ºycia      `plt.xticks(rotation=45)`'.")
    target_agent_or_node: str = Field(description="Nazwa agenta lub wƒôz≈Ça, kt√≥rego dotyczy rekomendacja, np. 'reporting_agent_node'.")
    tags: List[str] = Field(description="Lista 3-5 s≈Ç√≥w kluczowych, np. ['prompt-engineering', 'reporting', 'visualization'].")
    
    
    


--- FILE: memory/memory_utils.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import vertexai
import langchain
from langchain_google_vertexai import ChatVertexAI
from langchain_anthropic import ChatAnthropic
from tools.utils import intelligent_truncate
from config import MAIN_AGENT,LOCATION,PROJECT_ID,CRITIC_MODEL
from .memory_models import *

#--narzedzie do przetwarzania info dla pamieci dlugotrwalej, llm agent uzywa llm!!
def distill_memory_content(failing_code: str, error_traceback: str, debugger_analysis: str, corrected_code: str) -> dict:
    """U≈ºywa LLM do 'przedestylowania' surowych danych o b≈Çƒôdzie i jego naprawie do zwiƒôz≈Çego, ustrukturyzowanego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia (wersja ekspercka)...")
    
    prompt_template = f"""
    Persona: Jeste≈õ starszym in≈ºynierem oprogramowania, kt√≥ry pisze zwiƒôz≈Çe post-mortemy do wewnƒôtrznej bazy wiedzy. Twoim celem jest stworzenie notatki, kt√≥ra bƒôdzie maksymalnie u≈ºyteczna dla innych agent√≥w w przysz≈Ço≈õci.
    Przeanalizuj poni≈ºszy kontekst i wyciƒÖgnij z niego kluczowe, gotowe do u≈ºycia wnioski.
    Kontekst:888888888888888
    [WADLIWY KOD]: {failing_code}
    [PE≈ÅNY B≈ÅƒÑD]: {error_traceback}
    [ANALIZA PROBLEMU]: {debugger_analysis}
    [POPRAWIONY KOD]: {corrected_code}
    Zadanie: Na podstawie powy≈ºszego kontekstu, wygeneruj obiekt, kt√≥ry bƒôdzie pasowa≈Ç do zdefiniowanej struktury.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomy≈õlnie przedestylowano wspomnienie (wersja ekspercka).")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZE≈ªENIE: Destylacja (ekspercka) nie powiod≈Ça siƒô: {e}. Zapisujƒô surowe dane.")
        return {
            "problem_summary": debugger_analysis,
            "key_takeaway": "N/A - distillation failed",
            "raw_error": intelligent_truncate(error_traceback, 500)
        }
#pamiec dlugotrwala-zapis w meta agent, sukces 
def distill_success_memory(final_plan: str) -> dict:
    """U≈ºywa LLM do podsumowania udanego planu w zwiƒôz≈ÇƒÖ notatkƒô."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o sukcesie...")
    prompt_template = f"""
    Persona: Jeste≈õ starszym in≈ºynierem AI, kt√≥ry dokumentuje udane strategie.
    Kontekst: Przeanalizuj poni≈ºszy plan, kt√≥ry zako≈Ñczy≈Ç siƒô sukcesem i stw√≥rz zwiƒôz≈Çe podsumowanie w formacie JSON.
    [FINALNY PLAN]: {final_plan}
    """
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        # U≈ºywamy nowego, l≈ºejszego modelu DistilledSuccessMemory
        structured_llm = llm.with_structured_output(DistilledSuccessMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomy≈õlnie przedestylowano wspomnienie o sukcesie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZE≈ªENIE: Destylacja sukcesu nie powiod≈Ça siƒô: {e}.")
        return {"plan_summary": "N/A - distillation failed"}
    
    
def distill_memory_content(debugger_analysis: str, failing_code: str, corrected_code: str) -> dict:
    """U≈ºywa LLM do 'przedestylowania' analizy debuggera i zmian w kodzie do zwiƒôz≈Çego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o naprawie...")
    
    # Zamiast pe≈Çnego b≈Çƒôdu, u≈ºywamy zwiƒôz≈Çej analizy od debuggera!
    prompt_template = f"""
    Persona: Jeste≈õ starszym in≈ºynierem oprogramowania, kt√≥ry pisze zwiƒôz≈Çe post-mortemy.
    Przeanalizuj poni≈ºszy kontekst dotyczƒÖcy naprawy b≈Çƒôdu i wyciƒÖgnij z niego kluczowe, gotowe do u≈ºycia wnioski.
    Kontekst:
    [ANALIZA PROBLEMU WG DEBUGGERA]: {debugger_analysis}
    [WADLIWY FRAGMENT KODU]: {intelligent_truncate(failing_code, 500)}
    [POPRAWIONY KOD]: {intelligent_truncate(corrected_code, 500)}
    Zadanie: Na podstawie powy≈ºszego kontekstu, wygeneruj obiekt JSON zgodny ze strukturƒÖ DistilledMemory.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomy≈õlnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZE≈ªENIE: Destylacja (naprawa) nie powiod≈Ça siƒô: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}
    
    
    
    

    
def distill_full_fix_session(initial_error: str, fix_attempts: List[Dict], successful_code: str) -> Dict[str, Any]:
    """U≈ºywa LLM, aby podsumowaƒá ca≈ÇƒÖ sesjƒô naprawczƒÖ w jedno zwiƒôz≈Çe wspomnienie."""
    print("  [INFO] Uruchamiam destylacjƒô ca≈Çej sesji naprawczej...")

    # Tworzymy skonsolidowanƒÖ historiƒô analiz debuggera
    consolidated_analysis = "\n".join(
        [f"Pr√≥ba {i+1}: {attempt.get('debugger_analysis', 'Brak analizy.')}" for i, attempt in enumerate(fix_attempts)]
    )

    prompt_template = f"""
Persona: Jeste≈õ starszym in≈ºynierem, kt√≥ry pisze ekstremalnie zwiƒôz≈Çe post-mortemy. Priorytetem jest gƒôsto≈õƒá informacji przy minimalnej liczbie s≈Ç√≥w.

Przeanalizuj ca≈ÇƒÖ sesjƒô naprawy b≈Çƒôdu i wyciƒÖgnij z niej kluczowe wnioski.

[PIERWOTNY B≈ÅƒÑD]:
{initial_error}

[HISTORIA ANALIZ Z NIEUDANYCH PR√ìB NAPRAWY]:
{consolidated_analysis}

[KOD, KT√ìRY OSTATECZNIE ZADZIA≈ÅA≈Å]:
{successful_code}

Zadanie: Wygeneruj obiekt JSON. Ka≈ºde pole tekstowe musi byƒá pojedynczym, klarownym zdaniem. Ca≈Ço≈õƒá nie mo≈ºe przekroczyƒá 150 s≈Ç√≥w.
"""
    try:
        llm = ChatVertexAI(
            model_name=MAIN_AGENT, 
            project_id=PROJECT_ID, 
            location=LOCATION,
            max_output_tokens=512
        )
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("  [INFO] Pomy≈õlnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"  [OSTRZE≈ªENIE] Destylacja sesji nie powiod≈Ça siƒô: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}



    
def generate_meta_insight(audit_report: str) -> Optional[dict]:
    """U≈ºywa LLM do wyciƒÖgniƒôcia z raportu audytora jednego, kluczowego wniosku."""
    print("INFO: Uruchamiam proces generowania wniosku META...")
    prompt = f"""
    Przeanalizuj poni≈ºszy raport audytora. Twoim zadaniem jest znalezienie JEDNEJ, najwa≈ºniejszej i najbardziej konkretnej rekomendacji dotyczƒÖcej ulepszenia systemu.
    Je≈õli znajdziesz takƒÖ rekomendacjƒô, przekszta≈Çƒá jƒÖ w obiekt JSON zgodny ze strukturƒÖ MetaInsightMemory. Je≈õli raport jest og√≥lnikowy i nie zawiera konkretnych propozycji, zwr√≥ƒá null.
    [RAPORT AUDYTORA]:\n{audit_report}
    """
    try:
        llm = ChatAnthropic(model_name=CRITIC_MODEL, temperature=0.2)
        structured_llm = llm.with_structured_output(MetaInsightMemory)
        insight_object = structured_llm.invoke(prompt)
        print("INFO: Pomy≈õlnie wygenerowano wniosek META.")
        return insight_object.dict()
    except Exception:
        print("OSTRZE≈ªENIE: Nie uda≈Ço siƒô wygenerowaƒá wniosku META z raportu audytora.")
        return None


