--- FILE: __init__.py ---




--- FILE: config.py ---

import os
import logging
from enum import Enum
from google.cloud import secretmanager
import langchain
from langchain.cache import SQLiteCache





def get_secret(project_id: str, secret_id: str, version_id: str = "latest") -> str:
    """Pobiera wartość sekretu z Google Secret Manager."""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"
    response = client.access_secret_version(request={"name": name})
   
    return response.payload.data.decode("UTF-8")


class ApiType(Enum):
    GOOGLE = "google"
    ANTHROPIC = "anthropic"
    def __str__(self):
        return self.value


LOCATION="us-central1"
PROJECT_ID="dark-data-discovery"

#---------AGENTS--------:
MAIN_AGENT="gemini-2.5-pro"
API_TYPE_GEMINI=str(ApiType.GOOGLE)

CRITIC_MODEL="claude-3-7-sonnet-20250219"
CODE_MODEL="claude-sonnet-4-20250514"
API_TYPE_SONNET = str(ApiType.ANTHROPIC)

LANGCHAIN_API_KEY = get_secret(PROJECT_ID,"LANGCHAIN_API_KEY")
ANTHROPIC_API_KEY=get_secret(PROJECT_ID,"ANTHROPIC_API_KEY")

MEMORY_ENGINE_DISPLAY_NAME="memory-gamma-way"

INPUT_FILE_PATH = "gs://super_model/data/structural_data/synthetic_fraud_dataset.csv"

MAX_CORRECTION_ATTEMPTS=5



os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = LANGCHAIN_API_KEY
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_PROJECT"] = "Projekt Multi-Agent-System v9.0-Integrated"
os.environ["ANTHROPIC_API_KEY"] =ANTHROPIC_API_KEY


#---cache-------
langchain.llm_cache = SQLiteCache(database_path=".langchain.db")



    
#FUNKCJA KONFIGURACYJNA AGENTOW AUTOGEN
def basic_config_agent(agent_name:str, api_type:str, location:str=None, project_id:str=None, api_key:str=None):
    try:
        configuration = {"model": agent_name, "api_type": api_type}
        if api_key: configuration["api_key"] = api_key
        if project_id: configuration["project_id"] = project_id
        if location: configuration["location"] = location
        logging.info(f"Model configuration: {configuration}")
        return [configuration]

    except Exception as e:
        logging.error(f"Failed to initialize Vertex AI or configure LLM: {e}")
        print(f"Error: Failed to initialize Vertex AI or configure LLM. Please check your project ID, region, and permissions. Details: {e}")
        exit()


--- FILE: main.ipynb ---

import os
import pandas as pd
import uuid
import json
import vertexai
from vertexai import agent_engines
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
# Importy z własnych modułów
from config import PROJECT_ID, LOCATION, MEMORY_ENGINE_DISPLAY_NAME, INPUT_FILE_PATH,MAIN_AGENT,CRITIC_MODEL,CODE_MODEL, API_TYPE_GEMINI,API_TYPE_SONNET, ANTHROPIC_API_KEY,basic_config_agent
from agents.state import AgentWorkflowState
from agents.autogen_agents import TriggerAgent,PlannerAgent,CriticAgent
from prompts import LangchainAgentsPrompts,AutoGenAgentsPrompts
from agents.langgraph_nodes import * 
from agents.autogen_agent_utils import run_autogen_planning_phase
from memory.memory_bank_client import MemoryBankClient
from tools.utils import *
# --- Koniec komórki ---
AGENT_ENGINE_NAME = "" # Zostanie wypełniona po pobraniu lub utworzeniu silnika

# Inicjalizacja głównego klienta Vertex AI
client = vertexai.Client(project=PROJECT_ID, location=LOCATION)
# --- Koniec komórki ---
def get_or_create_agent_engine(display_name: str) :
    """
    Pobiera istniejący Agent Engine po nazwie wyświetlanej lub tworzy nowy, jeśli nie istnieje.
    """
    # 1. Pobierz listę wszystkich istniejących silników w projekcie
    all_engines = agent_engines.list()
    
    # 2. Sprawdź, czy któryś z nich ma pasującą nazwę
    for engine in all_engines:
        if engine.display_name == display_name:
            print(f"INFO: Znaleziono i połączono z istniejącym Agent Engine: '{display_name}'")
            return engine
            
    # 3. Jeśli pętla się zakończyła i nic nie znaleziono, stwórz nowy silnik
    print(f"INFO: Nie znaleziono Agent Engine o nazwie '{display_name}'. Tworzenie nowego...")
    try:
        new_engine = agent_engines.create(
            display_name=display_name
        )
        print(f"INFO: Pomyślnie utworzono nowy Agent Engine.")
        return new_engine
    except Exception as e:
        print(f"KRYTYCZNY BŁĄD: Nie można utworzyć Agent Engine. Sprawdź konfigurację i uprawnienia. Błąd: {e}")
        exit()

# --- Koniec komórki ---
agent_engine =get_or_create_agent_engine(MEMORY_ENGINE_DISPLAY_NAME)
AGENT_ENGINE_NAME = agent_engine.resource_name
print(AGENT_ENGINE_NAME)

# --- Koniec komórki ---
# --- Konfiguracja czatu grupowego ---
main_agent_configuration={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(agent_name=MAIN_AGENT, api_type=API_TYPE_GEMINI, location=LOCATION, project_id=PROJECT_ID)}
critic_agent_configuration ={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(api_key=ANTHROPIC_API_KEY,agent_name=CRITIC_MODEL, api_type=API_TYPE_SONNET)}
trigger_prompt = str(AutoGenAgentsPrompts.Trigger_prompt())
planner_prompt = str(AutoGenAgentsPrompts.Planner_prompt())
critic_prompt = str(AutoGenAgentsPrompts.Critic_prompt())
#---WYWOŁANIE AGENTÓW
trigger_agent = TriggerAgent(llm_config=main_agent_configuration, prompt=trigger_prompt)
planner_agent = PlannerAgent(llm_config=main_agent_configuration,prompt=planner_prompt)
critic_agent = CriticAgent(llm_config=main_agent_configuration,prompt=critic_prompt)
# --- Koniec komórki ---

# --- Koniec komórki ---
if __name__ == "__main__":
    
    files_to_exclude = {'Agents_beta (10).py','pack_project.ipynb', 'caly_projekt.txt'}
    system_source_code = read_project_source_code(".", exclude_files=files_to_exclude)

    # --- Inicjalizacja Pamięci i Uruchomienia ---
    memory_client = MemoryBankClient(client=client, agent_engine=agent_engine)
    run_id = str(uuid.uuid4())
    
    print("\n--- ODPYTYWANIE PAMIĘCI O INSPIRACJE ---")
    inspiration_prompt = ""
    dataset_signature = ""
    try:
        df_preview = pd.read_csv(INPUT_FILE_PATH, nrows=0)
        dataset_signature = memory_client.create_dataset_signature(df_preview)
        past_memories = memory_client.query_memory(
            query_text="Najlepsze strategie i kluczowe wnioski dotyczące przetwarzania danych",
            scope={"dataset_signature": dataset_signature},
            top_k=3
        )
        if past_memories:
            inspirations = []
            for mem in past_memories:
                if mem.memory_type == MemoryType.SUCCESSFUL_PLAN and 'key_insight' in mem.content:
                    inspirations.append(f"SPRAWDZONY WNIOSEK Z PLANU: {mem.content['key_insight']}")
                elif mem.memory_type == MemoryType.SUCCESSFUL_FIX and 'key_takeaway' in mem.content:
                    inspirations.append(f"NAUCZKA Z NAPRAWIONEGO BŁĘDU: {mem.content['key_takeaway']}")
            if inspirations:
                inspiration_prompt = "--- INSPIRACJE Z POPRZEDNICH URUCHOMIEŃ ---\n" + "\n".join(inspirations)
                print("INFO: Pomyślnie pobrano inspiracje z pamięci.")
        else:
            print("INFO: Nie znaleziono inspiracji w pamięci dla tego typu danych.")
    except Exception as e:
        print(f"OSTRZEŻENIE: Nie udało się pobrać inspiracji z pamięci: {e}")

        
        
    active_policies = get_active_policies_from_memory(memory_client, dataset_signature)    
    
    # --- Krok 1: Faza planowania (AutoGen) ---
    final_plan, autogen_log = run_autogen_planning_phase(
        input_path=INPUT_FILE_PATH, 
        inspiration_prompt=inspiration_prompt,
        trigger_agent=trigger_agent,
        planner_agent=planner_agent,
        critic_agent=critic_agent,
        manager_agent_config=main_agent_configuration,
        active_policies=active_policies
    )
    save_autogen_conversation_log(log_content=autogen_log, file_path="reports/autogen_planning_conversation.log")

    # --- Krok 2: Faza wykonania (LangGraph) ---
    if final_plan:
        print("\n" + "="*80)
        print("### ### FAZA 2: URUCHAMIANIE WYKONANIA PLANU (LangGraph) ### ###")
        print("="*80 + "\n")
        
        workflow = StateGraph(AgentWorkflowState)
        
        # <<< ZMIANA TUTAJ: Zaktualizowana lista węzłów >>>
        nodes = [
            "schema_reader", "code_generator", "architectural_validator", 
            "data_code_executor", "universal_debugger", "apply_code_fix", 
            "human_approval", "package_installer", "human_escalation", 
            "sync_report_code", "commit_memory","meta_auditor",
            # Nowe, wyspecjalizowane węzły raportujące:
            "summary_analyst", "plot_generator", "report_composer" 
        ]
        for name in nodes: workflow.add_node(name, globals()[f"{name}_node"])

        # Definicja krawędzi
        workflow.set_entry_point("schema_reader")
        
        # Ścieżka przetwarzania danych
        workflow.add_edge("schema_reader", "code_generator")
        workflow.add_edge("code_generator", "architectural_validator")
        
        def should_continue_or_debug(state: AgentWorkflowState) -> str:
            if state.get("error_message"):
                if state.get("correction_attempts", 0) >= MAX_CORRECTION_ATTEMPTS:
                    return "request_human_help"
                return "call_debugger"
            return "continue"

        workflow.add_conditional_edges(
            "architectural_validator",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "data_code_executor"}
        )
        workflow.add_conditional_edges(
            "data_code_executor",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "commit_memory"}
        )
        
        # <<< ZMIANA TUTAJ: Nowa ścieżka raportowania >>>
        workflow.add_edge("commit_memory", "summary_analyst")
        workflow.add_conditional_edges(
            "summary_analyst",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "plot_generator"}
        )
        workflow.add_conditional_edges(
            "plot_generator",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "report_composer"}
        )
        workflow.add_conditional_edges(
            "report_composer",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "meta_auditor"}
        )

        # Ścieżki naprawcze
        workflow.add_edge("human_escalation", "meta_auditor")
        workflow.add_edge("package_installer", "data_code_executor")

        def route_after_fix(state):
            failing_node = state.get("failing_node")
            # Po naprawie wraca do węzła, który zawiódł
            if failing_node:
                return failing_node
            # Domyślnie wraca do walidacji
            return "architectural_validator"

        workflow.add_conditional_edges("apply_code_fix", route_after_fix)

        def route_from_debugger(state):
            if state.get("tool_choice") == "propose_code_fix":
                return "apply_code_fix"
            if state.get("tool_choice") == "request_package_installation":
                return "human_approval"
            return "human_escalation"

        workflow.add_conditional_edges("universal_debugger", route_from_debugger)
        workflow.add_conditional_edges("human_approval", lambda s: s.get("user_approval_status"), {
            "APPROVED": "package_installer", "REJECTED": "universal_debugger"
        })

        app = workflow.compile()
        
        app_config = {"MAIN_AGENT": MAIN_AGENT, "CODE_MODEL": CODE_MODEL, "CRITIC_MODEL": CRITIC_MODEL}
        
        initial_state = {
            "config": app_config,
            "plan": final_plan, 
            "input_path": INPUT_FILE_PATH,
            "output_path": "reports/processed_data.csv",
            "report_output_path": "reports/transformation_report.html",
            "correction_attempts": 0, 
            "correction_history": [],
            "source_code": system_source_code,
            "autogen_log": autogen_log,
            "memory_client": memory_client,
            "run_id": run_id,
            "dataset_signature": dataset_signature,
            "pending_fix_session": None,
            "active_policies": active_policies
        }
        
        langgraph_log = ""
        final_run_state = initial_state.copy()
        
        for event in app.stream(initial_state, {"recursion_limit": 50}):
            for node_name, state_update in event.items():
                if "__end__" not in node_name:
                    print(f"--- Krok: '{node_name}' ---")
                    if state_update:
                        printable_update = state_update.copy()
                        for key in ["generated_code", "corrected_code", "generated_report_code", "error_context_code", "plot_generation_code", "summary_html"]:
                            if key in printable_update and printable_update[key]:
                                print(f"--- {key.upper()} ---")
                                print(printable_update[key])
                                print("-" * (len(key) + 8))
                                del printable_update[key]
                        if printable_update:
                            print(json.dumps(printable_update, indent=2, default=str))
                        
                        log_line = f"--- Krok: '{node_name}' ---\n{json.dumps(state_update, indent=2, default=str)}\n"
                        langgraph_log += log_line
                        final_run_state.update(state_update)
                    else:
                        print("  [INFO] Węzeł zakończył pracę bez aktualizacji stanu.")
                    print("-" * 20 + "\n")

        save_langgraph_execution_log(log_content=langgraph_log, file_path="reports/langgraph_execution.log")

        final_run_state['langgraph_log'] = langgraph_log
        meta_auditor_node(final_run_state)

        print("\n\n--- ZAKOŃCZONO PRACĘ GRAFU I AUDYT ---")
    else:
        print("Proces zakończony. Brak planu do wykonania.")
# --- Koniec komórki ---

# --- Koniec komórki ---



--- FILE: prompts.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import json
import re

class AutoGenAgentsPrompts:
    
    @staticmethod
    def Trigger_prompt() -> str:
        
        return f"""Jesteś 'Strażnikiem Danych'. Twoim jedynym zadaniem jest analiza podsumowania danych (nazwy kolumn, pierwsze wiersze).
Na tej podstawie musisz podjąć decyzję: czy te dane mają charakter **tabularyczny** (jak plik CSV lub tabela bazy danych)?
- Jeśli TAK: odpowiedz **tylko i wyłącznie**: 'Dane są tabularyczne. Przekazuję do PlannerAgent w celu stworzenia planu analizy.'. Nie dodawaj nic więcej.
- Jeśli NIE (np. są to logi serwera, obrazy, czysty tekst): Twoja wiadomość MUSI kończyć się słowem 'TERMINATE'. Wyjaśnij krótko, dlaczego dane nie są tabularyczne, np. 
'Dane nie są tabularyczne, to zbiór artykułów tekstowych. TERMINATE'. """
    
    
    @staticmethod
    def Planner_prompt()->str:
        
        return f"""Jesteś 'Architektem Planu'. Otrzymałeś potwierdzenie, że dane są tabularyczne.
Twoim zadaniem jest stworzenie szczegółowego, numerowanego planu czyszczenia i przygotowania danych do ogólnej analizy i modelowania. Plan musi być praktyczny i zgodny z najlepszymi praktykami.
Twoje zadanie składa się z dwóch części:
1.  **Analiza Inspiracji:** Jeśli w wiadomości od użytkownika znajduje się sekcja '--- INSPIRACJE Z POPRZEDNICH URUCHOMIEŃ ---', 
potraktuj ją jako cenną inspirację i punkt wyjścia. Zawiera ona sprawdzoną strategię ("złotą myśl") i może również zawierać konkretne kroki. Twoim zadaniem jest **krytyczna adaptacja** tego planu. 
**Sprawdź, czy każdy krok z inspiracji ma sens w kontekście AKTUALNEGO podglądu danych.** Możesz usunąć, dodać lub zmodyfikować kroki, aby idealnie pasowały do obecnego problemu.
2.  **Tworzenie Planu:** Jeśli nie ma inspiracji, stwórz nowy, solidny plan od podstaw.
Plan powinien zawierać kroki takie jak:
1.  Weryfikacja i obsługa brakujących wartości (np. strategia imputacji dla każdej istotnej kolumny).
2.  Weryfikacja i korekta typów danych (np. konwersja stringów na daty lub liczby).
3.  Inżynieria cech (np. tworzenie nowych, użytecznych kolumn jak 'dzien_tygodnia' z daty lub kategoryzacja wartości liczbowych).
4.  Wykrywanie i obsługa wartości odstających (outlierów).
5.  Normalizacja lub skalowanie danych (jeśli to konieczne, wyjaśnij krótko dlaczego).

Po przedstawieniu pierwszej wersji planu, oczekuj na recenzję od CriticAgenta.
- Jeśli CriticAgent prześle uwagi, stwórz **NOWĄ, KOMPLETNĄ WERSJĘ** planu, która uwzględnia **WSZYSTKIE** jego sugestie.
- W poprawionym planie zaznacz, co zostało zmienione. Prześlij zaktualizowany plan z powrotem do CriticAgenta.
Kontynuuj ten proces, aż CriticAgent ostatecznie zaakceptuje Twój plan. """
    
    
    @staticmethod
    def Critic_prompt() ->str:
        
        return f"""Jesteś 'Recenzentem Jakości'. Twoim zadaniem jest konstruktywna krytyka planu od PlannerAgenta. Oceń go pod kątem praktyczności, realizmu i efektywności.
Twoje Złote Zasady:
1.  **PROSTOTA JEST KLUCZEM:** Agresywnie kwestionuj nadmiernie skomplikowane kroki. Czy naprawdę potrzebujemy KNNImputer, gdy prosta mediana wystarczy?
2.  **JEDNA ZMIANA NA RAZ:** Jeśli plan proponuje stworzenie kilku złożonych cech w jednym kroku, odrzuć to. Zarekomenduj podzielenie tego na osobne, łatwiejsze do weryfikacji kroki. 
Plan musi być odporny na błędy.
3.  **KONKRETNE SUGESTIE:** Zawsze podawaj konkretną alternatywę. Zamiast 'To jest złe', napisz 'Krok X jest nieoptymalny. Sugeruję Y, ponieważ Z.'

**PROCES ZATWIERDZANIA (KRYTYCZNIE WAŻNE):**
- Jeśli plan wymaga jakichkolwiek poprawek, jasno je opisz i odeślij do PlannerAgenta. **NIE UŻYWAJ** poniższych fraz kluczowych.
- Jeśli plan jest **doskonały** i nie wymaga żadnych zmian, Twoja odpowiedź **MUSI** mieć następującą, ścisłą strukturę:
Najpierw napisz linię:
`OSTATECZNY PLAN:`
Poniżej wklej **CAŁY, KOMPLETNY** plan od PlannerAgenta.
Na samym końcu wiadomości dodaj frazę:
`PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI` """
    
    
    
class LangchainAgentsPrompts:
    
    SYSTEM_PROMPT_NEXUS_ENGINEER = """
# ===================================================================
# ### GŁÓWNA DYREKTYWA: PERSONA I CEL ###
# ===================================================================
Jesteś "Nexus" – światowej klasy, autonomicznym inżynierem oprogramowania AI. Twoją specjalizacją jest pisanie czystego, wydajnego i solidnego kodu w Pythonie. Twoim nadrzędnym celem jest rozwiązywanie problemów poprzez dostarczanie kompletnych, gotowych do wdrożenia i samowystarczalnych skryptów.

# ===================================================================
# ### ZASADY PODSTAWOWE (CORE PRINCIPLES) ###
# ===================================================================
Zawsze przestrzegaj następujących zasad:

1.  **Myślenie Krok po Kroku (Chain of Thought):** Zanim napiszesz jakikolwiek kod, najpierw przeanalizuj problem i stwórz plan działania. Zapisz ten plan w formie komentarzy w kodzie. To porządkuje Twoją logikę i prowadzi do lepszych rozwiązań.
2.  **Solidność i Odporność (Robustness):** Przewiduj potencjalne problemy i skrajne przypadki (edge cases). Jeśli to stosowne, używaj bloków `try...except` do obsługi błędów. Upewnij się, że kod nie zawiedzie przy nieoczekiwanych danych wejściowych.
3.  **Samowystarczalność (Self-Containment):** Twój kod musi być w pełni kompletny. Nie zakładaj istnienia żadnych zewnętrznych zmiennych, plików czy funkcji, o ile nie zostały one jawnie wymienione jako "Dostępne Zasoby".
4.  **Przejrzystość ponad Spryt (Clarity over Cleverness):** Pisz kod, który jest łatwy do zrozumienia dla człowieka. Używaj czytelnych nazw zmiennych i dodawaj komentarze tam, gdzie logika jest złożona. Unikaj nadmiernie skomplikowanych, jednowierszowych rozwiązań.

# ===================================================================
# ### PROCES ROZWIĄZYWANIA PROBLEMÓW ###
# ===================================================================
Gdy otrzymujesz zadanie, postępuj według następującego schematu:

1.  **ANALIZA CELU:** W pełni zrozum, co ma zostać osiągnięte. Zidentyfikuj dane wejściowe i oczekiwany rezultat.
2.  **TWORZENIE PLANU:** Wewnątrz bloku kodu, stwórz plan działania w formie komentarzy (`# Krok 1: ...`, `# Krok 2: ...`).
3.  **IMPLEMENTACJA KODU:** Napisz kod, który realizuje Twój plan.
4.  **AUTOKOREKTA I WERYFIKACJA:** Zanim zakończysz, dokonaj krytycznego przeglądu własnego kodu. Zadaj sobie pytania: "Czy ten kod jest kompletny?", "Czy obsłużyłem przypadki brzegowe?", "Czy jest zgodny ze wszystkimi zasadami?". Popraw wszelkie znalezione niedociągnięcia.

"""
    
    
    
    
    
    @staticmethod
    def code_generator(plan: str, available_columns: List[str]) -> str:
        task_prompt = f"""
# ===================================================================
# ### AKTUALNE ZADANIE: GENEROWANIE KODU ###
# ===================================================================
**Cel:** Na podstawie poniższego planu biznesowego i dostępnych danych, napisz kompletny i samowystarczalny skrypt w Pythonie.

**Plan Biznesowy do Implementacji:**
{plan}

**Dostępne Kolumny w Danych:**
{available_columns}

**Wymagania Architektoniczne (Bezwzględnie Przestrzegaj):**
{ArchitecturalRulesManager.get_rules_as_string()}
""" 
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER+ task_prompt
    
    @staticmethod
    def tool_based_debugger(failing_node: str,active_policies: Optional[str] = None) -> str:
        
        policy_section = ""
        if active_policies:
            policy_section = active_policies
        
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER+ f"""Jesteś 'Głównym Inżynierem Jakości Kodu'.
        {policy_section}
        Twoim zadaniem jest nie tylko naprawienie zgłoszonego błędu, ale zapewnienie, że kod będzie działał poprawnie.
        --- KONTEKST ZADANIA ---
Błąd wystąpił w węźle o nazwie: '{failing_node}'. Twoje zadanie zależy od tego kontekstu:
- Jeśli `failing_node` to 'data_code_executor' lub 'architectural_validator', Twoim zadaniem jest naprawa GŁÓWNEGO skryptu do przetwarzania danych.
- Jeśli `failing_node` to 'plot_generator_node', Twoim zadaniem jest napisanie FRAGMENTU KODU W PYTHONIE, który generuje wykresy.
- Jeśli `failing_node` to 'summary_analyst_node', Twoim zadaniem jest napisanie kodu HTML z podsumowaniem analitycznym.
**Bezwzględnie przestrzegaj tych zasad:**
     - Używaj WYŁĄCZNIE biblioteki `matplotlib.pyplot`. Nie używaj `plotly` ani `seaborn`.
    - NIE importuj bibliotek.
    - Używaj tylko ramek danych `df_original` i `df_processed`.
    - NIE używaj `plt.show()`.
    - Każdą figurę (`fig`) MUSISZ dodać do listy `figures_to_embed`.
---
--- NOWA ZDOLNOŚĆ: DIAGNOZA NARZĘDZI ---
Jeśli traceback błędu (np. NameError, AttributeError) wskazuje na funkcję, która jest wewnętrznym narzędziem systemu, a nie na kod, który masz naprawić, użyj narzędzia `inspect_tool_code`, aby przeczytać kod źródłowy tego narzędzia. Przeanalizuj go i, jeśli znajdziesz w nim błąd (np. brakujący import), w swojej finalnej poprawce do `corrected_code` dołącz brakujące importy lub logikę, aby naprawić również ten błąd.
- Jeśli błąd to `ModuleNotFoundError`, użyj `request_package_installation`.
- Jeśli błąd to `ImportError` wskazujący na konflikt wersji, również użyj `request_package_installation`, aby zasugerować aktualizację pakietu, który jest źródłem błędu.
- Dla wszystkich innych błędów w kodzie (np. `SyntaxError`, `KeyError`), użyj `propose_code_fix` a następnie przeanalizuj poniższy błąd i wadliwy kod. Twoja praca składa się z dwóch kroków:
1.  **Analiza i Naprawa:** Zidentyfikuj przyczynę błędu i stwórz kompletną, poprawioną wersję całego skryptu.
2.  **Wywołanie Narzędzia:** Wywołaj narzędzie `propose_code_fix`, podając **OBOWIĄZKOWO** dwa argumenty: `analysis` (twoja analiza) oraz `corrected_code` (pełny, naprawiony kod).
Przeanalizuj poniższy błąd i wadliwy kod. """

    @staticmethod
    def summary_analyst_prompt(plan: str, original_summary: str, processed_summary: str) -> str:
        """
        Tworzy prompt dla agenta, którego JEDYNYM zadaniem jest analiza
        i napisanie tekstowego podsumowania w HTML.
        """
        return f"""
        Jesteś analitykiem danych. Twoim jedynym zadaniem jest napisanie zwięzłego, menedżerskiego podsumowania w formacie HTML, które podkreśla kluczowe korzyści z transformacji danych.
        Skup się na zmianach w brakujących danych, wartościach odstających i liczbie kolumn.
        
        PLAN TRANSFORMACJI, KTÓRY MASZ OPISAĆ: 
        {plan}
        
        DANE PRZED TRANSFORMACJĄ (PODSUMOWANIE): 
        {original_summary}
        
        DANE PO TRANSFORMACJI (PODSUMOWANIE): 
        {processed_summary}
        
        Twoja odpowiedź musi być tylko i wyłącznie kodem HTML, gotowym do wstawienia do raportu.
        """

    @staticmethod
    def plot_generator_prompt(plan: str,available_columns: List[str]) -> str:
        """
        Tworzy prompt dla agenta, którego JEDYNYM zadaniem jest napisanie
        kodu w Pythonie do generowania wykresów.
        """
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER + f"""
        Jesteś ekspertem od wizualizacji danych w Pythonie przy użyciu biblioteki Matplotlib.
        Twoim jedynym zadaniem jest napisanie fragmentu kodu w Pythonie.
        
        PLAN, KTÓRY MASZ ZILUSTROWAĆ:
        {plan}

        --- KRYTYCZNE INFORMACJE ---
        DOSTĘPNE KOLUMNY W DANYCH `df_processed`, KTÓRYCH MOŻESZ UŻYĆ:
        {available_columns}
        --- KONIEC KRYTYCZNYCH INFORMACJI ---
        
        WAŻNE ZASADY:
        1.  **Generuj wykresy TYLKO dla kolumn, które znajdują się na powyższej liście dostępnych kolumn.**
        2.  Każdy wykres musi mieć tytuł i czytelne etykiety osi.
        3.  Użyj `fig.tight_layout()` przed dodaniem figury do listy.
        4.  **Używaj WYŁĄCZNIE biblioteki `matplotlib.pyplot`. Nie używaj `plotly` ani `seaborn`.**
        5.  NIE importuj bibliotek. Zakładaj, że `matplotlib.pyplot as plt` i `pandas as pd` są już dostępne.
        6.  NIE twórz własnych danych. Używaj wyłącznie ramek danych `df_original` i `df_processed`.
        7.  NIE używaj `plt.show()`. Twoim zadaniem jest tylko stworzenie obiektów figur.
        8.  Każdą stworzoną figurę (`fig`) MUSISZ dodać do listy o nazwie `figures_to_embed`.
        9.  Twoja odpowiedź musi zawierać TYLKO i WYŁĄCZNIE kod Pythona.
        10. **Twoja odpowiedź MUSI być obiektem JSON zawierającym jeden klucz: "code", którego wartością jest skrypt Pythona jako string.**
        """

    @staticmethod
    def create_meta_auditor_prompt(source_code: str, autogen_conversation: str, langgraph_log: str, final_code: str, final_report: str, escalation_report: Optional[str] = None) -> str:
        
        escalation_section = ""
        if escalation_report:
            escalation_section = f"""
# ===================================================================
# ### RAPORT Z ESKALACJI DO CZŁOWIEKA ###
# ===================================================================
UWAGA: System nie zdołał samodzielnie rozwiązać problemu i wymagał interwencji. To jest najważniejszy element do analizy.
{escalation_report}
"""
        
        return f"""**Persona:** Główny Audytor Systemów AI. Twoim zadaniem jest krytyczna ocena całego procesu AI.
        {escalation_section}
**Dostępne Dane do Analizy:**
1. KOD ŹRÓDŁOWY SYSTEMU:\n```python\n{source_code}\n```
2. ZAPIS ROZMOWY (PLANOWANIE):\n```\n{autogen_conversation}\n```
3. LOGI (WYKONANIE):\n```\n{langgraph_log}\n```
4. FINALNY KOD:\n```python\n{final_code}\n```
5. FINALNY RAPORT (fragment):\n```html\n{final_report[:2000]}\n```
**Zadania Audytorskie (odpowiedz na każde pytanie):**
1. **Ocena Planowania:** Czy dyskusja Planner-Krytyk była efektywna? Czy Krytyk był rygorystyczny?
2. **Ocena Wykonania:** Czy były pętle naprawcze? Jak skuteczny był debugger?
3. **Ocena Produktu:** Czy raport HTML jest użyteczny?
4. **Ocena Promptów Agentów (Analiza Meta):**
    - Na podstawie analizy logów i kodu źródłowego, oceń jakość i precyzję promptów dla poszczególnych agentów (Planner, Krytyk, Debugger, Generator Raportu).
    - Czy któryś z zaobserwowanych problemów (nawet tych naprawionych) mógł wynikać z niejasności w prompcie?
    - Czy widzisz możliwość ulepszenia któregoś z promptów, aby system działał bardziej niezawodnie lub efektywnie w przyszłości?
5. **Rekomendacje do Samodoskonalenia:** Zaproponuj 1-3 konkretne zmiany w kodzie lub promptach, które usprawnią system.
**Format Wyjściowy:** Zwięzły raport tekstowy."""
    
    
class ArchitecturalRule(TypedDict):
    id: str; description: str; check: Callable[[str], bool]; error_message: str

ARCHITECTURAL_RULES: List[ArchitecturalRule] = [
    {"id": "NO_MAIN_BLOCK", "description": "Żadnego bloku `if __name__ == '__main__':`.", "check": lambda code: bool(re.search(r'if\s+__name__\s*==\s*["\']__main__["\']\s*:', code)), "error_message": "Wykryto niedozwolony blok `if __name__ == '__main__':`."},
    {"id": "NO_ARGPARSE", "description": "Żadnego `argparse` ani `sys.argv`.", "check": lambda code: bool(re.search(r'import\s+argparse', code)), "error_message": "Wykryto niedozwolony import modułu `argparse`."},
    {"id": "SINGLE_FUNCTION_LOGIC", "description": "Cała logika musi być w funkcji `process_data(input_path: str, output_path: str)`.", "check": lambda code: "def process_data(input_path: str, output_path: str)" not in code, "error_message": "Brak wymaganej definicji funkcji `process_data(input_path: str, output_path: str)`."},
    {"id": "ENDS_WITH_CALL", "description": "Skrypt musi kończyć się **dokładnie jedną linią** w formacie: `process_data(input_path, output_path)  # noqa: F821`. Komentarz `# noqa: F821` jest **obowiązkowy**.", "check": lambda code: not re.search(r'^\s*process_data\(input_path,\s*output_path\)\s*#\s*noqa:\s*F821\s*$', [line for line in code.strip().split('\n') if line.strip()][-1]), "error_message": "Skrypt nie kończy się wymaganym wywołaniem `process_data(input_path, output_path)  # noqa: F821`."},
]

class ArchitecturalRulesManager:
    @staticmethod
    def get_rules_as_string() -> str:
        rules_text = "\n".join(f"        - {rule['description']}" for rule in ARCHITECTURAL_RULES)
        return f"<ARCHITECTURAL_RULES>\n    **Krytyczne Wymagania Dotyczące Struktury Kodu:**\n{rules_text}\n</ARCHITECTURAL_RULES>"


--- FILE: tools/__init__.py ---




--- FILE: tools/langchain_tools.py ---

from pydantic import BaseModel, Field
from langchain_core.tools import tool
from .utils import TOOL_REGISTRY
#--BaseModel

class DebugReport(BaseModel):
    analysis: str = Field(description="Techniczna analiza błędu.")
    corrected_code: str = Field(description="Kompletny, poprawiony kod.")

    
class GeneratedPythonScript(BaseModel):
    """
    Model przechowujący kompletny i gotowy do wykonania skrypt w Pythonie.
    """
    script_code: str = Field(description="Kompletny kod w Pythonie, gotowy do bezpośredniego wykonania. Musi zawierać wszystkie niezbędne elementy, takie jak definicje, logikę i zapis pliku.")    
    

class CodeFixArgs(BaseModel):
    analysis: str = Field(description="Techniczna analiza przyczyny błędu i wprowadzonej poprawki w kodzie.")
    corrected_code: str = Field(description="Pełny, kompletny i POPRAWIONY skrypt w Pythonie. Musi być gotowy do wykonania.")
    
class PackageInstallArgs(BaseModel):
    package_name: str = Field(description="Nazwa pakietu, który należy zainstalować, aby rozwiązać błąd 'ModuleNotFoundError'. Np. 'scikit-learn', 'seaborn'.")
    analysis: str = Field(description="Krótka analiza potwierdzająca, że przyczyną błędu jest brakujący pakiet.")

class ReportSummary(BaseModel):
    """Przechowuje podsumowanie analityczne w formacie HTML."""
    summary_html: str = Field(description="Tekst podsumowania w formacie HTML, zawierający tagi takie jak <h2> i <ul>.")

class PlottingCode(BaseModel):
    """Przechowuje kod Pythona do generowania wizualizacji."""
    code: str = Field(description="Czysty kod w Pythonie do generowania figur matplotlib.")


    
class InspectToolArgs(BaseModel):
    tool_name: str = Field(description="Nazwa funkcji/narzędzia do inspekcji, np. 'embed_plot_to_html'.")
    
#narzędzia dla langchain agentów    
@tool(args_schema=CodeFixArgs)
def propose_code_fix(analysis: str, corrected_code: str) -> None:
    """Użyj tego narzędzia, aby zaproponować poprawioną wersję kodu w odpowiedzi na błąd składniowy lub logiczny."""
    pass

@tool(args_schema=PackageInstallArgs)
def request_package_installation(package_name: str, analysis: str) -> None:
    """Użyj tego narzędzia, aby poprosić o instalację brakującej biblioteki, gdy napotkasz błąd 'ModuleNotFoundError'."""
    pass 


@tool(args_schema=InspectToolArgs)
def inspect_tool_code(tool_name: str) -> str:
    """Użyj tego narzędzia, aby przeczytać kod źródłowy wewnętrznej funkcji systemowej.
    Jest to przydatne, gdy podejrzewasz, że błąd (np. NameError) leży w narzędziu, a nie w kodzie, który analizujesz."""
    if tool_name in TOOL_REGISTRY:
        source_code = inspect.getsource(TOOL_REGISTRY[tool_name])
        return f"Oto kod źródłowy narzędzia '{tool_name}':\n```python\n{source_code}\n```"
    return f"BŁĄD: Nie znaleziono narzędzia o nazwie '{tool_name}'."


--- FILE: tools/utils.py ---

import os
import io
import sys
import subprocess
import inspect
import matplotlib.pyplot as plt
import base64 
import tempfile
import traceback
import uuid
import json
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import datetime
import logging
from memory.memory_models import MemoryType

#--funkcja dla pamieci--
def intelligent_truncate(text: str, max_len: int) -> str:
    """Skraca tekst, zachowując jego początek i koniec."""
    if not isinstance(text, str) or len(text) <= max_len:
        return text
    half_len = (max_len - 25) // 2
    start = text[:half_len]
    end = text[-half_len:]
    return f"{start}\n\n[... treść skrócona ...]\n\n{end}"

def extract_python_code(response: str) -> str:
    response = response.strip()
    match = re.search(r'```python\n(.*?)\n```', response, re.DOTALL)
    if match: return match.group(1).strip()
    if response.startswith("'''") and response.endswith("'''"): return response[3:-3].strip()
    if response.startswith('"""') and response.endswith('"""'): return response[3:-3].strip()
    return response


def install_package(package_name: str, upgrade: bool = True) -> bool:
    """
    Instaluje lub aktualizuje podany pakiet używając pip.
    
    Args:
        package_name (str): Nazwa pakietu do instalacji.
        upgrade (bool): Jeśli True, używa flagi --upgrade.
    """
    try:
        command = [sys.executable, "-m", "pip", "install", package_name]
        if upgrade:
            command.insert(2, "--upgrade")
        
        action = "Aktualizacja" if upgrade else "Instalacja"
        print(f"  [INSTALATOR] Próba: {action} pakietu {package_name}...")
        
        result = subprocess.run(command, check=True, capture_output=True, text=True)
        print(f"  [INSTALATOR] Pomyślnie zakończono. Logi pip:\n{result.stdout}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"  [INSTALATOR] Błąd podczas operacji na pakiecie {package_name}.\n{e.stderr}")
        return False
    

    
#DLA report agenta
def embed_plot_to_html(figure) -> str:
    """Konwertuje figurę matplotlib do stringa base64 do osadzenia w HTML."""
    buffer = io.BytesIO()
    figure.savefig(buffer, format='png', bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    graphic = base64.b64encode(image_png)
    graphic = graphic.decode('utf-8')
    plt.close(figure) # Ważne: zamykamy figurę
    return f'<img src="data:image/png;base64,{graphic}" alt="Wykres analizy danych"/>'



#Dla meta agenta
def read_source_code(file_path: str) -> str:
    """Odczytuje zawartość pliku kodu źródłowego."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f: return f.read()
    except Exception as e: return f"Nie udało się odczytać kodu źródłowego: {e}"


def read_project_source_code(root_dir=".", exclude_dirs=None, exclude_files=None): # <-- Dodaj nowy argument
    """
    Rekursywnie skanuje katalog projektu, odczytuje zawartość plików .py i .ipynb,
    i łączy je w jeden, sformatowany string dla meta-audytora.
    """
    if exclude_dirs is None:
        exclude_dirs = {'__pycache__', '.ipynb_checkpoints', 'reports', '.git'}
    
    if exclude_files is None: # <-- Dodaj tę sekcję
        exclude_files = set()

    full_source_code = ""
    for dirpath, dirnames, filenames in os.walk(root_dir):
        dirnames[:] = [d for d in dirnames if d not in exclude_dirs]
        
        for filename in filenames:
            if filename in exclude_files: # <-- Dodaj tę linię, aby pomijać pliki
                continue
            
            if filename.endswith(".py") or filename.endswith(".ipynb"):
                file_path = os.path.join(dirpath, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        full_source_code += f"--- FILE: {file_path} ---\n\n{content}\n\n"
                except Exception as e:
                    full_source_code += f"--- FILE: {file_path} ---\n\n[BŁĄD ODCZYTU: {e}]\n\n"
                    
    return full_source_code

#Zapis planowania preprocessingu- AutoGen
def save_autogen_conversation_log(log_content: str, file_path: str):
    """Zapisuje pełną treść konwersacji agentów AutoGen do pliku tekstowego."""
    print(f"INFO: Próba zapisu pełnego logu rozmowy do pliku: {file_path}")
    try:
        # Upewniamy się, że katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PEŁNY ZAPIS ROZMOWY AGENTÓW (FAZA PLANOWANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"✅ SUKCES: Log rozmowy został pomyślnie zapisany.")
    except Exception as e:
        print(f"❌ BŁĄD: Nie udało się zapisać logu rozmowy. Przyczyna: {e}")


        
#Zapis rozmowy agentow wykonowczych- LangChain        
def save_langgraph_execution_log(log_content: str, file_path: str):
    """Zapisuje pełny, szczegółowy log z wykonania grafu LangGraph do pliku."""
    print(f"INFO: Próba zapisu pełnego logu wykonania LangGraph do pliku: {file_path}")
    try:
        # Upewniamy się, że katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PEŁNY ZAPIS WYKONANIA GRAFU LANGGRAPH (FAZA WYKONANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"✅ SUKCES: Log wykonania LangGraph został pomyślnie zapisany.")
    except Exception as e:
        print(f"❌ BŁĄD: Nie udało się zapisać logu LangGraph. Przyczyna: {e}")  


def get_active_policies_from_memory(memory_client, dataset_signature: str) -> Optional[str]:
    """Odpytuje pamięć o META_INSIGHTS i tworzy z nich tekst polityk."""
    print("--- DORADCA POLITYKI SYSTEMOWEJ: Sprawdzanie pamięci... ---")
    
    meta_insights = memory_client.query_memory(
        query_text="Najważniejsze rekomendacje dotyczące ulepszenia promptów lub logiki systemu",
        scope={"dataset_signature": dataset_signature},
        top_k=3
    )
    
    active_policies = []
    if meta_insights:
        for mem in meta_insights:
            if mem.memory_type == MemoryType.META_INSIGHT and 'recommendation' in mem.content:
                active_policies.append(f"- {mem.content['recommendation']}")
    
    if active_policies:
        policy_text = "--- AKTYWNE POLITYKI SYSTEMOWE (NAJWYŻSZY PRIORYTET) ---\n" + "\n".join(active_policies)
        print(f"  [INFO] Aktywowano polityki:\n{policy_text}")
        return policy_text
    
    print("  [INFO] Brak aktywnych polityk systemowych.")
    return None

        
TOOL_REGISTRY = {
    "embed_plot_to_html": embed_plot_to_html
}


--- FILE: agents/__init__.py ---




--- FILE: agents/autogen_agent_utils.py ---

import pandas as pd
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
from .autogen_agents import TriggerAgent,PlannerAgent,CriticAgent
import autogen
from autogen import Agent, ConversableAgent
from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent





#FUNKCJA CHATU GRUPOWEGO-WYMYŚLANIE PLANU
def run_autogen_planning_phase(input_path: str,trigger_agent: TriggerAgent,planner_agent: PlannerAgent, critic_agent: CriticAgent, manager_agent_config:Dict,inspiration_prompt: str = "",active_policies: Optional[str] = None) -> Optional[str]:
    """
    Uruchamia fazę planowania z agentami AutoGen i zwraca finalny plan.
    """
    print("\n" + "="*80)
    print("### ### FAZA 1: URUCHAMIANIE PLANOWANIA STRATEGICZNEGO (AutoGen) ### ###")
    print("="*80 + "\n")

    try:
        df_summary = pd.read_csv(input_path, nrows=5)
        data_preview = f"Oto podgląd danych:\n\nKolumny:\n{df_summary.columns.tolist()}\n\nPierwsze 5 wierszy:\n{df_summary.to_string()}"
        
        
        if active_policies:
            print("INFO: Dołączam aktywne polityki systemowe do fazy planowania.")
            data_preview += "\n\n" + active_policies
        
        
        if inspiration_prompt:
            print("INFO: Dołączam inspiracje z pamięci do fazy planowania.")
            data_preview += "\n\n" + inspiration_prompt
        
    except Exception as e:
        logging.error(f"Nie można wczytać pliku wejściowego {input_path}: {e}")
        return None, ""
    
    
    
    user_proxy = autogen.UserProxyAgent(
       name="UserProxy",
       human_input_mode="NEVER",
       max_consecutive_auto_reply=10,
       is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
       code_execution_config=False,
       system_message="Zarządzasz procesem. Przekaż podgląd danych do TriggerAgenta. Następnie moderuj dyskusję między Plannerem a Krytykiem. Jeśli w wiadomości znajdują się 'AKTYWNE POLITYKI SYSTEMOWE' lub 'INSPIRACJE Z POPRZEDNICH URUCHOMIEŃ', upewnij się, że przekażesz je w całości Plannerowi."
    )

    def custom_speaker_selection_func(last_speaker: Agent, groupchat: autogen.GroupChat):
        messages = groupchat.messages

        # Warunek początkowy, pierwszy mówi TriggerAgent
        if len(messages) <= 1:
            return trigger_agent

        # Standardowy przepływ: Trigger -> Planner -> Critic -> Planner ...
        elif last_speaker is trigger_agent:
            return planner_agent
        elif last_speaker is planner_agent:
            return critic_agent
        elif last_speaker is critic_agent:

            if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in messages[-1]['content']:
                return None # To elegancko kończy rozmowę
            else:
                # Jeśli nie, wracamy do Plannera z uwagami
                return planner_agent
        else:
            # Sytuacja awaryjna lub koniec, nie wybieraj nikogo
            return None

    groupchat = autogen.GroupChat(
        agents=[user_proxy, trigger_agent, planner_agent, critic_agent],
        messages=[],
        max_round=15,
        speaker_selection_method=custom_speaker_selection_func
    )
    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=manager_agent_config)

    user_proxy.initiate_chat(manager, message=data_preview)

    # Ekstrakcja finalnego planu
    final_plan = None
    critic_messages = [msg['content'] for msg in groupchat.messages if msg['name'] == 'CriticAgent']
    for msg in reversed(critic_messages):
        if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in msg:
            match = re.search(r"OSTATECZNY PLAN:(.*)PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI", msg, re.DOTALL)
            if match:
                final_plan = match.group(1).strip()
                print("Faza planowania zakończona. Ostateczny plan został zaakceptowany.")
                break
    
    if not final_plan:
        print(" Faza planowania zakończona bez akceptacji planu lub z powodu TERMINATE.")

    
    full_conversation_log = "\n\n".join([f"--- Komunikat od: {msg['name']} ---\n{msg['content']}" for msg in groupchat.messages])

    
    return final_plan, full_conversation_log



--- FILE: agents/autogen_agents.py ---

import autogen
from autogen import Agent, ConversableAgent


class TriggerAgent(ConversableAgent):
    """Agent decydujący, czy dane nadają się do dalszego przetwarzania."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="TriggerAgent",
            llm_config=llm_config,
            system_message=prompt
        )

#PLANNER AGENT        
class PlannerAgent(ConversableAgent):
    """Agent tworzący szczegółowy plan przygotowania danych."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="PlannerAgent",
            llm_config=llm_config,
            system_message=prompt
        )

#CRITIC AGENT
class CriticAgent(ConversableAgent):
    """Agent oceniający plan i dbający o jego jakość."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="CriticAgent",
            llm_config=llm_config,
            system_message=prompt
        )
        
        
        



--- FILE: agents/langgraph_nodes.py ---

import os
import io
import sys
import subprocess
import tempfile
import traceback
import uuid
import json
import re
import matplotlib.pyplot as plt
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import langchain
from langchain_google_vertexai import ChatVertexAI
from langchain_anthropic import ChatAnthropic
from .state import AgentWorkflowState
from prompts import LangchainAgentsPrompts
from tools.utils import *
from tools.langchain_tools import *
from prompts import ArchitecturalRule, ArchitecturalRulesManager,ARCHITECTURAL_RULES
from config import MAX_CORRECTION_ATTEMPTS, PROJECT_ID,LOCATION
from memory.memory_utils import *
from memory.memory_models import *
# --- Definicje węzłów LangGraph ---

def schema_reader_node(state: AgentWorkflowState):
    print("--- WĘZEŁ: ANALIZATOR SCHEMATU DANYCH ---")
    print(f"DEBUG: Próbuję odczytać plik ze ścieżki: {state.get('input_path')}")
    try:
        df_header = pd.read_csv(state['input_path'], nrows=0)
        
        #pamięć długotrwała, tworzenie sygnatury
        memory_client = state['memory_client']
        dataset_signature = memory_client.create_dataset_signature(df_header)
        print(f"INFO: Wygenerowano sygnaturę danych: {dataset_signature}")
        #--koniec--
        
        return {"available_columns": df_header.columns.tolist(),"dataset_signature": dataset_signature}
    except Exception as e:
        return {"error_message": f"Błąd odczytu pliku: {e}", "failing_node": "schema_reader"}

def code_generator_node(state: AgentWorkflowState):
    print("---  WĘZEŁ: GENERATOR KODU ---")
    
    
    CODE_MODEL=state['config']['CODE_MODEL']
    
    llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    prompt = LangchainAgentsPrompts.code_generator(state['plan'], state['available_columns'])
    response = llm.invoke(prompt).content
    code = extract_python_code(response)
    
    print("\nAgent-Analityk wygenerował następujący kod:")
    print("--------------------------------------------------")
    print(code)
    print("--------------------------------------------------")
    return {"generated_code": code}


def architectural_validator_node(state: AgentWorkflowState):
    print("--- 🛡️ WĘZEŁ: STRAŻNIK ARCHITEKTURY 🛡️ ---")
    code_to_check = state.get('generated_code', '')
    if not code_to_check:
        error_message = "Brak kodu do walidacji."
        print(f"  [WERDYKT] ❌ {error_message}")
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": "", "correction_attempts": state.get('correction_attempts', 0) + 1}

    errors = [rule["error_message"] for rule in ARCHITECTURAL_RULES if rule["check"](code_to_check)]
    
    if errors:
        error_message = "Błąd Walidacji Architektonicznej: " + " ".join(errors)
        # <<< WAŻNY PRINT >>>
        print(f"  [WERDYKT] ❌ Kod łamie zasady architektury: {' '.join(errors)}")
        
        pending_session = {
            "initial_error": error_message,  # Używamy błędu walidacji jako błędu początkowego
            "initial_code": code_to_check,
            "fix_attempts": []
        }
        
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": code_to_check, "correction_attempts": state.get('correction_attempts', 0) + 1}
    else:
        # <<< WAŻNY PRINT >>>
        print("  [WERDYKT] Kod jest zgodny z architekturą systemu.")
        return {"error_message": None, "pending_fix_session": None}

    
def data_code_executor_node(state: AgentWorkflowState):
    """
    Wykonuje finalny kod do przetwarzania danych.
    """
    print("--- WĘZEŁ: WYKONANIE KODU DANYCH  ---")
    try:
        print("  [INFO] Uruchamiam ostatecznie zatwierdzony kod...")
        
        # Definiujemy środowisko wykonawcze tylko z niezbędnymi bibliotekami
        exec_scope = {
            'pd': pd,
            'input_path': state['input_path'],
            'output_path': state['output_path']
        }
        
        exec(state['generated_code'], exec_scope)
        
        print("  [WYNIK] Kod wykonany pomyślnie.")
        return {"error_message": None, "correction_attempts": 0}
        
    except Exception as e:
        error_traceback = traceback.format_exc()
        print(f"  [BŁĄD] Wystąpił błąd. Przekazywanie do inteligentnego debuggera:\n{error_traceback}")
        
        #--pamięć długotrwała: zapis błędu, sesja tymczasowa
        
        pending_session = {
            "initial_error": error_traceback,
            "initial_code": state['generated_code'],
            "fix_attempts": []  # Pusta lista na przyszłe próby naprawy
        }
        #--koniec--
        
        return {
            "failing_node": "data_code_executor", 
            "error_message": error_traceback, 
            "error_context_code": state['generated_code'], 
            "correction_attempts": state.get('correction_attempts', 0) + 1,
            "pending_fix_session": pending_session
        }

    
def universal_debugger_node(state: AgentWorkflowState):
    print(f"--- WĘZEŁ: INTELIGENTNY DEBUGGER (Błąd w: {state.get('failing_node')}) ---")
    failing_node_name = state.get('failing_node', 'unknown')
    
    
    
    MAIN_AGENT=state['config']['MAIN_AGENT']
    # llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    llm = ChatVertexAI(model_name=MAIN_AGENT,temperature=0.0, project=PROJECT_ID, location=LOCATION)
    tools = [propose_code_fix, request_package_installation, inspect_tool_code]
    llm_with_tools = llm.bind_tools(tools)
    prompt = LangchainAgentsPrompts.tool_based_debugger(failing_node=failing_node_name,active_policies=state.get("active_policies"))
    error_context = f"Wadliwy Kontekst:\n```\n{state['error_context_code']}\n```\n\nBłąd:\n```\n{state['error_message']}\n```"
    response = llm_with_tools.invoke(prompt + error_context)
    if not response.tool_calls:
        print("  [BŁĄD DEBUGGERA] Agent nie wybrał żadnego narzędzia. Eskalacja.")
        return {"error_message": "Debugger nie był w stanie podjąć decyzji.", "failing_node": "universal_debugger"}
    chosen_tool = response.tool_calls[0]
    tool_name = chosen_tool['name']
    tool_args = chosen_tool['args']
    print(f"  [DIAGNOZA] Debugger wybrał narzędzie: '{tool_name}' z argumentami: {tool_args}")
    return {"tool_choice": tool_name, "tool_args": tool_args, "debugger_analysis": tool_args.get("analysis", "")}


def apply_code_fix_node(state: AgentWorkflowState):
    """Aplikuje poprawkę kodu zaproponowaną przez debuggera."""
    print("--- WĘZEŁ: APLIKOWANIE POPRAWKI KODU ---")
    
    CODE_MODEL=state['config']['CODE_MODEL']
    
    analysis = state.get("debugger_analysis", "")
    corrected_code = state.get("tool_args", {}).get("corrected_code")
    failing_node = state.get("failing_node")
    
    
    if not corrected_code:
        print("  [OSTRZEŻENIE] Debugger nie dostarczył kodu. Wymuszam jego wygenerowanie...")
        
        # Tworzymy bardzo prosty prompt, który ma tylko jedno zadanie
        force_prompt = f"""Na podstawie poniższej analizy i wadliwego kodu, wygeneruj PEŁNY, POPRAWIONY i gotowy do uruchomienia skrypt Pythona.
        Twoja odpowiedź musi zawierać TYLKO i WYŁĄCZNIE blok kodu, bez żadnych dodatkowych wyjaśnień.

        [ANALIZA BŁĘDU]:
        {analysis}

        [WADLIWY KOD]:
        ```python
        {state['error_context_code']}"""
        
        
        try:
            llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
            response = llm.invoke(force_prompt).content
            corrected_code = extract_python_code(response) # Używamy istniejącej funkcji pomocniczej
            print("  [INFO] Pomyślnie wymuszono wygenerowanie kodu.")
        except Exception as e:
            print(f"  [BŁĄD KRYTYCZNY] Nie udało się wymusić generacji kodu: {e}")
            return {"error_message": "Nie udało się naprawić kodu nawet po eskalacji."}
        
        
    #--pamięć długotrwała info dla pamieci--
    
    update = {
        "error_message": None, 
        "tool_choice": None, 
        "tool_args": None
    }

    if failing_node == "plot_generator_node":
        print("  [INFO] Aplikowanie poprawki do kodu generującego wykresy.")
        update["plot_generation_code"] = corrected_code
    elif failing_node == "summary_analyst_node":
        print("  [INFO] Aplikowanie poprawki do podsumowania HTML.")
        update["summary_html"] = corrected_code
    else: # Domyślnie traktuj jako główny kod
        print("  [INFO] Aplikowanie poprawki do głównego kodu przetwarzania danych.")
        update["generated_code"] = corrected_code

    session = state.get('pending_fix_session')
    if not session:
        # Sytuacja awaryjna, nie powinno się zdarzyć w normalnym przepływie
        print("  [OSTRZEŻENIE] Próba aplikacji poprawki bez aktywnej sesji naprawczej.")
        session = {}

    # Dodajemy informacje o tej konkretnej próbie do listy w sesji
    attempt_info = {
        "debugger_analysis": state.get("debugger_analysis", "Brak analizy."),
        "corrected_code": corrected_code,
        "attempt_number": len(session.get("fix_attempts", [])) + 1
    }
    
    if "fix_attempts" in session:
        session["fix_attempts"].append(attempt_info)
    else:
        session["fix_attempts"] = [attempt_info]
    
    print(f"  [INFO] Dodano próbę naprawy nr {attempt_info['attempt_number']} do sesji.")
    
    
    #--koniec--
    
    return {
        "generated_code": corrected_code, 
        "error_message": None, 
        "tool_choice": None, 
        "tool_args": None,
        "pending_fix_session": session  # Aktualizujemy sesję w stanie
    }


def human_approval_node(state: AgentWorkflowState):
    print("\n" + "="*80 + "\n### WYMAGANA AKCJA CZŁOWIEKA  ###\n" + "="*80)
    package_name = state.get("tool_args", {}).get("package_name")
    user_input = input(f"Agent chce zainstalować pakiet '{package_name}'. Czy zgadzasz się? [y/n]: ").lower().strip()
    if user_input == 'y':
        print("Zgoda. Przechodzenie do instalacji.")
        return {"user_approval_status": "APPROVED", "package_to_install": package_name}
    else:
        print("Odrzucono. Przekazywanie do debuggera w celu znalezienia alternatywy.")
        new_error_message = f"Instalacja pakietu '{package_name}' została odrzucona przez użytkownika. Zmodyfikuj kod, aby nie używał tej zależności."
        return {"user_approval_status": "REJECTED", "error_message": new_error_message}


def package_installer_node(state: AgentWorkflowState):
    """Instaluje lub aktualizuje pakiet po uzyskaniu zgody."""
    package_name = state.get("package_to_install")
    
    # Domyślnie próbujemy aktualizacji, bo to rozwiązuje problemy z zależnościami
    success = install_package(package_name, upgrade=True)
    
    if success:
        return {"package_to_install": None, "user_approval_status": None, "error_message": None}
    else:
        return {"error_message": f"Operacja na pakiecie '{package_name}' nie powiodła się.", "failing_node": "package_installer"}

def commit_memory_node(state: AgentWorkflowState) -> Dict[str, Any]:
    """Zapisuje skonsolidowaną wiedzę do pamięci po udanej naprawie kodu."""
    session = state.get('pending_fix_session')
    
    # Jeśli nie ma sesji (np. kod zadziałał za 1. razem), nie rób nic
    if not session or not session.get("fix_attempts"):
        return {"pending_fix_session": None}

    print("--- WĘZEŁ: ZATWIERDZANIE WIEDZY W PAMIĘCI ---")
    
    distilled_content = distill_full_fix_session(
        initial_error=session['initial_error'],
        fix_attempts=session['fix_attempts'],
        successful_code=state['generated_code']
    )
    
    memory_client = state['memory_client']
    final_record = MemoryRecord(
        run_id=state['run_id'],
        memory_type=MemoryType.SUCCESSFUL_FIX, # Teraz to jest prawdziwy sukces
        dataset_signature=state['dataset_signature'],
        source_node="commit_memory_node",
        content=distilled_content,
        metadata={"total_attempts": len(session['fix_attempts'])}
    )
    memory_client.add_memory(final_record)
    
    # Wyczyść sesję po udanym zapisie
    return {"pending_fix_session": None} 

    
    
def summary_analyst_node(state: AgentWorkflowState) -> Dict[str, str]:
    """
    Agent, którego jedynym zadaniem jest analiza i stworzenie podsumowania tekstowego w HTML.
    """
    print("--- WĘZEŁ: ANALITYK PODSUMOWANIA ---")
    try:
        # Krok 1: Przygotuj dane wejściowe dla promptu
        df_original = pd.read_csv(state['input_path'])
        df_processed = pd.read_csv(state['output_path'])

        original_info_buf = io.StringIO()
        df_original.info(buf=original_info_buf)
        processed_info_buf = io.StringIO()
        df_processed.info(buf=processed_info_buf)

        original_summary = f"Podsumowanie danych ORYGINALNYCH:\n{df_original.describe().to_string()}\n{original_info_buf.getvalue()}"
        processed_summary = f"Podsumowanie danych PRZETWORZONYCH:\n{df_processed.describe().to_string()}\n{processed_info_buf.getvalue()}"

        # === POPRAWKA: Użycie dedykowanego promptu ===
        prompt = LangchainAgentsPrompts.summary_analyst_prompt(
            plan=state['plan'],
            original_summary=original_summary,
            processed_summary=processed_summary
        )
        
        llm = ChatAnthropic(model_name=state['config']['CODE_MODEL'], temperature=0.0, max_tokens=1024)
        structured_llm = llm.with_structured_output(ReportSummary)
        response = structured_llm.invoke(prompt)
        
        print("  [INFO] Analityk wygenerował podsumowanie HTML.")
        return {"summary_html": response.summary_html}
        
    except Exception as e:
        error_msg = f"Błąd w analityku podsumowania: {traceback.format_exc()}"
        print(f"  [BŁĄD] {error_msg}")
        return {
            "error_message": error_msg,
            "failing_node": "summary_analyst_node",
            "error_context_code": state.get('plan', 'Brak planu w stanie do analizy.'),
            "correction_attempts": state.get("correction_attempts", 0) + 1  # <-- DODAJ TĘ LINIĘ
        }


def plot_generator_node(state: AgentWorkflowState) -> Dict[str, str]:
    """
    Agent, którego jedynym zadaniem jest wygenerowanie KODU do tworzenia wykresów.
    """
    print("--- WĘZEŁ: GENERATOR WIZUALIZACJI ---")
    try:
        # --- NOWY KROK: POBIERZ AKTUALNE KOLUMNY Z PRZETWORZONEGO PLIKU ---
        df_processed_cols = pd.read_csv(state['output_path'], nrows=0).columns.tolist()

        # Przekaż aktualne kolumny do promptu, aby agent wiedział, na czym pracuje
        prompt = LangchainAgentsPrompts.plot_generator_prompt(
            plan=state['plan'],
            available_columns=df_processed_cols  # Przekazanie nowej informacji
        )
        
        MAIN_AGENT = state['config']['MAIN_AGENT']
        llm = ChatVertexAI(model_name=MAIN_AGENT, temperature=0.0, project=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(PlottingCode)
        
        response = structured_llm.invoke(prompt)
        cleaned_code = extract_python_code(response.code)
        
        print("  [INFO] Generator stworzył kod do wizualizacji.")
        return {"plot_generation_code": cleaned_code}
        

    except Exception as e:
        error_msg = f"Błąd w generatorze wizualizacji: {traceback.format_exc()}"
        print(f"  [BŁĄD] {error_msg}")
        return {
            "error_message": error_msg,
            "failing_node": "plot_generator_node",
            "error_context_code": state.get('plan', 'Brak planu w stanie do analizy.'),
            "correction_attempts": state.get("correction_attempts", 0) + 1
        }


def report_composer_node(state: AgentWorkflowState) -> Dict[str, Any]:
    """
    Węzeł, który składa podsumowanie i wykresy w finalny raport HTML. Nie używa LLM.
    """
    print("--- WĘZEŁ: KOMPOZYTOR RAPORTU ---")
    try:
        summary_html = state.get("summary_html")
        plot_code = state.get("plot_generation_code")
        
        if not summary_html or not plot_code:
            raise ValueError("Brak podsumowania lub kodu do generowania wykresów w stanie.")

        # 1. Przygotuj środowisko wykonawcze dla kodu z wykresami
        exec_scope = {
            'pd': pd,
            'plt': plt,
            'df_original': pd.read_csv(state['input_path']),
            'df_processed': pd.read_csv(state['output_path']),
            'figures_to_embed': []
        }

        # 2. Wykonaj kod od agenta, aby wygenerować obiekty figur
        exec(plot_code, exec_scope)
        figures = exec_scope['figures_to_embed']
        print(f"  [INFO] Wykonano kod i wygenerowano {len(figures)} wykres(y).")

        # 3. Skonwertuj figury na tagi <img> z base64
        figures_html = ""
        for i, fig in enumerate(figures):
            figures_html += f"<h3>Wykres {i+1}</h3>{embed_plot_to_html(fig)}"

        # 4. Złóż finalny raport HTML
        final_html = f"""
        <!DOCTYPE html>
        <html lang="pl">
        <head>
            <meta charset="UTF-8">
            <title>Raport z Analizy Danych</title>
            <style>
                body {{ font-family: sans-serif; margin: 2em; background-color: #f9f9f9; }}
                .container {{ max-width: 1000px; margin: auto; background: #fff; padding: 2em; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                h1, h2, h3 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 5px;}}
                img {{ max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px; border-radius: 4px; margin-top: 1em; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Raport z Przetwarzania Danych</h1>
                {summary_html}
                <h2>Wizualizacje</h2>
                {figures_html}
            </div>
        </body>
        </html>
        """

        # 5. Zapisz plik
        with open(state['report_output_path'], 'w', encoding='utf-8') as f:
            f.write(final_html)
            
        print(f"✅ Raport został pomyślnie wygenerowany w {state['report_output_path']}")
        return {}

    except Exception as e:
        error_msg = f"Błąd w kompozytorze raportu: {traceback.format_exc()}"
        print(f"  [BŁĄD] {error_msg}")
        return {
            "error_message": error_msg, 
            "failing_node": "report_composer_node",
            "error_context_code": state.get("plot_generation_code", "Brak kodu do analizy."),
            "correction_attempts": state.get("correction_attempts", 0) + 1
        }
    
    
    
    

    
def sync_report_code_node(state: AgentWorkflowState):
    """Synchronizuje naprawiony kod z powrotem do stanu agenta raportującego."""
    print("--- WĘZEŁ: SYNCHRONIZACJA KODU RAPORTU ---")
    corrected_code = state.get("generated_code")
    return {"generated_report_code": corrected_code}   
    
    
def meta_auditor_node(state: AgentWorkflowState):
    """Uruchamia audytora ORAZ zapisuje wspomnienia o sukcesie i wnioski META."""
    print("\n" + "="*80 + "\n### ### FAZA 3: META-AUDYT I KONSOLIDACJA WIEDZY ### ###\n" + "="*80 + "\n")
    memory_client = state['memory_client']

    if not state.get("escalation_report_path"):
        try:
            print("  [INFO] Uruchamiam proces destylacji wspomnienia o sukcesie...")
            # --- ZMIANA 2: Zabezpieczenie przed limitem tokenów ---
            truncated_plan = intelligent_truncate(state.get('plan', ''), 3000)
            distilled_content = distill_success_memory(final_plan=truncated_plan)
            
            if distilled_content and distilled_content.get("key_insight"):
                # Dodatkowe zabezpieczenie dla wyniku destylacji
                distilled_content["key_insight"] = intelligent_truncate(distilled_content["key_insight"], 2000)

                plan_record = MemoryRecord(
                    run_id=state['run_id'],
                    memory_type=MemoryType.SUCCESSFUL_PLAN,
                    dataset_signature=state['dataset_signature'],
                    source_node="meta_auditor_node",
                    content=distilled_content,
                    metadata={"importance_score": 0.8}
                )
                memory_client.add_memory(plan_record)
        except Exception as e:
            print(f"  [BŁĄD ZAPISU PAMIĘCI] Nie udało się zapisać udanego planu: {e}")
    
    # 2. Uruchom audytora (logika bez zmian)
    try:
        
        CRITIC_MODEL=state['config']['CRITIC_MODEL']
        
        escalation_report_content = None
        escalation_path = state.get("escalation_report_path")
        if escalation_path:
            print(f"  [INFO] Wykryto raport z eskalacji. Wczytywanie pliku: {escalation_path}")
            try:
                with open(escalation_path, 'r', encoding='utf-8') as f:
                    escalation_report_content = f.read()
            except Exception as e:
                print(f"  [OSTRZEŻENIE] Nie udało się wczytać pliku z eskalacją: {e}")
        
        
        
        # ... (cała logika generowania raportu audytora, tak jak w oryginale)
        # Załóżmy, że wynikiem jest zmienna 'audit_report'
        final_report_content = "Brak raportu do analizy."
        try:
            with open(state['report_output_path'], 'r', encoding='utf-8') as f:
                final_report_content = f.read()
        except Exception: pass
        
        llm = ChatAnthropic(model_name=CRITIC_MODEL, temperature=0.0, max_tokens=2048)
        prompt = LangchainAgentsPrompts.create_meta_auditor_prompt(
            source_code=intelligent_truncate(state['source_code'], 8000),
            autogen_conversation=intelligent_truncate(state['autogen_log'], 6000),
            langgraph_log=intelligent_truncate(state.get('langgraph_log', ''), 6000),
            final_code=state.get('generated_code', 'Brak kodu'),
            final_report=final_report_content,
            escalation_report=escalation_report_content
        )
        audit_report = llm.invoke(prompt).content
        # ... (zapis raportu do pliku)

        
        
        try:
            audit_report_path = "reports/meta_audit_report.txt"
            print(f"  [INFO] Zapisywanie raportu z audytu do: {audit_report_path}")
            with open(audit_report_path, "w", encoding="utf-8") as f:
                f.write("="*50 + "\n")
                f.write("### RAPORT Z META-AUDYTU SYSTEMU AI ###\n")
                f.write("="*50 + "\n\n")
                f.write(audit_report)
            print(f"  [SUKCES] Pomyślnie zapisano raport z audytu.")
        except Exception as e:
            print(f"  [BŁĄD] Nie udało się zapisać raportu z audytu: {e}")
        
        # 3. WYGENERUJ I ZAPISZ WNIOSEK META
        meta_insight_content = generate_meta_insight(audit_report)
        if meta_insight_content:
            insight_record = MemoryRecord(
                run_id=state['run_id'], memory_type=MemoryType.META_INSIGHT,
                dataset_signature=state['dataset_signature'], source_node="meta_auditor_node",
                content=meta_insight_content, metadata={"importance_score": 1.0}
            )
            memory_client.add_memory(insight_record)

    except Exception as e:
        print(f"BŁĄD KRYTYCZNY podczas meta-audytu: {e}")
    return {}

    
    
def human_escalation_node(state: AgentWorkflowState):
    """Węzeł eskalacji (bez zmian)."""
    print("\n==================================================")
    print(f"--- WĘZEŁ: ESKALACJA DO CZŁOWIEKA---")
    print("==================================================")
    # ... (reszta kodu bez zmian)
    report_content = f"""
Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Problem: Przekroczono maksymalny limit ({MAX_CORRECTION_ATTEMPTS}) prób automatycznej naprawy.

Ostatnia analiza debuggera:
{state.get('debugger_analysis', 'Brak analizy.')}

Ostatni kod, który zawiódł:
```python
{state.get('error_context_code', 'Brak kodu.')}
```

Pełny traceback ostatniego błędu:
{state.get('error_message', 'Brak błędu.')}
"""
    file_name = f"reports/human_escalation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(file_name, "w", encoding="utf-8") as f: f.write(report_content)
    print(f"  [INFO] Raport dla człowieka został zapisany w pliku: {file_name}")
    return {"escalation_report_path": file_name}



--- FILE: agents/state.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
from memory.memory_bank_client import MemoryBankClient

#Zmienne przekazywane do grafu LangChian
class AgentWorkflowState(TypedDict):
    config: Dict[str, Any]
    plan: str; input_path: str; output_path: str; report_output_path: str
    available_columns: List[str]; generated_code: str; generated_report_code: str
    correction_attempts: int; error_message: Optional[str]; failing_node: Optional[str]
    error_context_code: Optional[str]; debugger_analysis: Optional[str]
    package_to_install: Optional[str]; user_approval_status: Optional[str]
    tool_choice: Optional[str]; tool_args: Optional[Dict]
    source_code: str
    autogen_log: str
    langgraph_log: str
    # --- Pola pamięci ---
    run_id: str
    dataset_signature: str
    error_record_id: Optional[str]
    memory_client: MemoryBankClient
    pending_fix_session: Optional[Dict[str, Any]]
    generated_code: str # Dla głównego kodu
    summary_html: str # Wynik z summary_analyst
    plot_generation_code: str # Wynik z plot_generator
    escalation_report_path: Optional[str]


--- FILE: memory/__init__.py ---




--- FILE: memory/memory_bank_client.py ---

import json
import hashlib
import pandas as pd
from typing import Dict, List, Optional
import vertexai
from vertexai import agent_engines
from .memory_models import MemoryRecord


class MemoryBankClient:
    def __init__(self, client: vertexai.Client, agent_engine):
        """
        Inicjalizuje klienta z głównym obiektem klienta Vertex AI 
        oraz z gotowym obiektem agent_engine.
        """
        if not client or not agent_engine:
            raise ValueError("Klient Vertex AI oraz Agent Engine muszą być poprawnie zainicjalizowane.")
        
        self.client = client
        self.agent_engine = agent_engine
        self.engine_name = agent_engine.resource_name
        print(f"INFO: MemoryBankClient gotowy do pracy z silnikiem: {self.engine_name}")
        
    
    
    
    def create_dataset_signature(self, df_preview: pd.DataFrame) -> str:
        """Tworzy unikalny identyfikator dla zbioru danych."""
        s = "".join(df_preview.columns) + str(df_preview.shape)
        return hashlib.md5(s.encode()).hexdigest()

    def add_memory(self, record: MemoryRecord):
        """Zapisuje ustrukturyzowane wspomnienie w Agent Engine."""
        try:
            fact_to_remember = record.model_dump_json()
            scope = {"dataset_signature": record.dataset_signature}
            
            
            self.client.agent_engines.create_memory(
                name=self.engine_name,
                fact=fact_to_remember, 
                scope=scope
            )
            print(f"INFO: Zapisano wspomnienie typu '{record.memory_type}' w zakresie {scope}")
        except Exception as e:
            print(f"BŁĄD ZAPISU PAMIĘCI: {e}")

#     def query_memory(self, query_text: str, scope: Dict, top_k: int = 5) -> List[MemoryRecord]:
#         """
#         Odpytuje pamięć semantycznie i zwraca listę ustrukturyzowanych wspomnień.
#         """
#         retrieved_mems = []
#         try:
#             print(f"INFO: Odpytuję pamięć semantycznie z zapytaniem '{query_text}' w zakresie {scope}")

#             # Tworzymy słownik z parametrami wyszukiwania, zgodnie z Twoim znaleziskiem
#             search_params = {
#                 "search_query": query_text,
#                 "top_k": top_k
#             }

#             # Wywołujemy API z poprawnym argumentem: similarity_search_params
#             memories_iterator = self.client.agent_engines.retrieve_memories(
#                 name=self.engine_name,
#                 scope=scope,
#                 similarity_search_params=search_params
#             )

#             for mem in memories_iterator:
#                 print("mem", dir(mem))
#                 record = MemoryRecord.model_validate_json(mem.memory)
#                 retrieved_mems.append(record)

#             print(f"INFO: Znaleziono {len(retrieved_mems)} pasujących wspomnień.")
#             return retrieved_mems

#         except Exception as e:
#             print(f"BŁĄD ODCZYTU PAMIĘCI: {e}")
#             return []
        
        
    def query_memory(self, query_text: str, scope: Dict, top_k: int = 5) -> List[MemoryRecord]:
        """
        Odpytuje pamięć semantycznie, poprawnie odczytując zagnieżdżoną treść wspomnienia.
        """
        retrieved_mems = []
        try:
            print(f"INFO: Odpytuję pamięć semantycznie z zapytaniem '{query_text}' w zakresie {scope}")

            search_params = {
                "search_query": query_text,
                "top_k": top_k
            }

            memories_iterator = self.client.agent_engines.retrieve_memories(
                name=self.engine_name,
                scope=scope,
                similarity_search_params=search_params
            )

            for i, mem in enumerate(memories_iterator):
                try:

                    json_string_to_parse = mem.memory.fact

                    record = MemoryRecord.model_validate_json(json_string_to_parse)
                    retrieved_mems.append(record)
                    print("udany plan:", record)
                except Exception as e:
                    print(f"⚠️ OSTRZEŻENIE: Pominięto uszkodzony lub niekompatybilny rekord pamięci (pozycja {i}). Błąd: {e}")
                    continue

            print(f"INFO: Znaleziono i poprawnie przetworzono {len(retrieved_mems)} pasujących wspomnień.")
            return retrieved_mems

        except Exception as e:
            print(f"KRYTYCZNY BŁĄD ODCZYTU PAMIĘCI: Nie udało się wykonać zapytania. Błąd: {e}")
            return []


--- FILE: memory/memory_models.py ---

from datetime import datetime
from enum import Enum
from typing import Dict, Any, List, Optional
from pydantic import BaseModel, Field
import uuid

class MemoryType(str, Enum):
    SUCCESSFUL_PLAN = "SUCCESSFUL_PLAN"
    EXECUTION_ERROR = "EXECUTION_ERROR"
    SUCCESSFUL_FIX = "SUCCESSFUL_FIX"
    META_INSIGHT = "META_INSIGHT"

    

class MemoryRecord(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    run_id: str # Dodajemy ID bieżącego uruchomienia
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    memory_type: MemoryType
    dataset_signature: str
    source_node: str
    content: Dict[str, Any]
    metadata: Dict[str, Any] = Field(default_factory=dict)

class DistilledMemory(BaseModel):
    """Ustrukturyzowany, 'ekspercki' format dla przedestylowanego wspomnienia."""
    problem_summary: str = Field(description="Opis problemu w jednym, zwięzłym zdaniu.")
    solution_summary: str = Field(description="Opis rozwiązania w jednym, zwięzłym zdaniu.")
    applicability_context: str = Field(description="Opis w jednym zdaniu, w jakim kontekście (np. typ danych, operacja) ta lekcja jest najbardziej użyteczna.")
    key_takeaway: str = Field(description="Uniwersalna 'złota myśl' lub reguła na przyszłość, aby uniknąć podobnych błędów.")
    reusable_code_snippet: Optional[str] = Field(description="Generyczny fragment kodu w Pythonie (do 10 linijek), który implementuje 'key_takeaway'. Jeśli nie ma zastosowania, zwróć null.")
    tags: List[str] = Field(description="Lista 3-5 słów kluczowych (tagów) opisujących ten problem.")
    
    
 #--czysty zapis o sukcesie   
class DistilledSuccessMemory(BaseModel):
    """Ustrukturyzowany format dla wspomnienia o udanym przebiegu."""
    plan_summary: str = Field(description="Podsumowanie celu i kluczowych kroków zrealizowanego planu w jednym zdaniu.")
    key_insight: str = Field(description="Najważniejszy wniosek lub 'trick', który przyczynił się do sukcesu tego planu.")
    full_plan_text: str = Field(description="Pełny, szczegółowy, numerowany tekst udanego planu.")
    tags: List[str] = Field(description="Lista 3-5 słów kluczowych (tagów) opisujących ten plan.")
    
class MetaInsightMemory(BaseModel):
    """Ustrukturyzowany format dla WNIOSKU NA POZIOMIE SYSTEMU."""
    observation: str = Field(description="Zwięzłe opisanie zaobserwowanego zjawiska, np. 'Agent generujący raporty często popełniał błędy w wizualizacji danych szeregów czasowych'.")
    recommendation: str = Field(description="Konkretna, pojedyncza propozycja zmiany w prompcie lub logice systemu, np. 'Do promptu agenta raportującego należy dodać konkretny przykład użycia      `plt.xticks(rotation=45)`'.")
    target_agent_or_node: str = Field(description="Nazwa agenta lub węzła, którego dotyczy rekomendacja, np. 'reporting_agent_node'.")
    tags: List[str] = Field(description="Lista 3-5 słów kluczowych, np. ['prompt-engineering', 'reporting', 'visualization'].")
    
    
    


--- FILE: memory/memory_utils.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import vertexai
import langchain
from langchain_google_vertexai import ChatVertexAI
from langchain_anthropic import ChatAnthropic
from tools.utils import intelligent_truncate
from config import MAIN_AGENT,LOCATION,PROJECT_ID,CRITIC_MODEL
from .memory_models import *

#--narzedzie do przetwarzania info dla pamieci dlugotrwalej, llm agent uzywa llm!!
def distill_memory_content(failing_code: str, error_traceback: str, debugger_analysis: str, corrected_code: str) -> dict:
    """Używa LLM do 'przedestylowania' surowych danych o błędzie i jego naprawie do zwięzłego, ustrukturyzowanego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia (wersja ekspercka)...")
    
    prompt_template = f"""
    Persona: Jesteś starszym inżynierem oprogramowania, który pisze zwięzłe post-mortemy do wewnętrznej bazy wiedzy. Twoim celem jest stworzenie notatki, która będzie maksymalnie użyteczna dla innych agentów w przyszłości.
    Przeanalizuj poniższy kontekst i wyciągnij z niego kluczowe, gotowe do użycia wnioski.
    Kontekst:888888888888888
    [WADLIWY KOD]: {failing_code}
    [PEŁNY BŁĄD]: {error_traceback}
    [ANALIZA PROBLEMU]: {debugger_analysis}
    [POPRAWIONY KOD]: {corrected_code}
    Zadanie: Na podstawie powyższego kontekstu, wygeneruj obiekt, który będzie pasował do zdefiniowanej struktury.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomyślnie przedestylowano wspomnienie (wersja ekspercka).")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEŻENIE: Destylacja (ekspercka) nie powiodła się: {e}. Zapisuję surowe dane.")
        return {
            "problem_summary": debugger_analysis,
            "key_takeaway": "N/A - distillation failed",
            "raw_error": intelligent_truncate(error_traceback, 500)
        }
#pamiec dlugotrwala-zapis w meta agent, sukces 
def distill_success_memory(final_plan: str) -> dict:
    """Używa LLM do podsumowania udanego planu w zwięzłą notatkę."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o sukcesie...")
    prompt_template = f"""
    Persona: Jesteś starszym inżynierem AI, który dokumentuje udane strategie.
    Kontekst: Przeanalizuj poniższy plan, który zakończył się sukcesem i stwórz zwięzłe podsumowanie w formacie JSON.
    [FINALNY PLAN]: {final_plan}
    """
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        # Używamy nowego, lżejszego modelu DistilledSuccessMemory
        structured_llm = llm.with_structured_output(DistilledSuccessMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomyślnie przedestylowano wspomnienie o sukcesie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEŻENIE: Destylacja sukcesu nie powiodła się: {e}.")
        return {"plan_summary": "N/A - distillation failed"}
    
    
def distill_memory_content(debugger_analysis: str, failing_code: str, corrected_code: str) -> dict:
    """Używa LLM do 'przedestylowania' analizy debuggera i zmian w kodzie do zwięzłego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o naprawie...")
    
    # Zamiast pełnego błędu, używamy zwięzłej analizy od debuggera!
    prompt_template = f"""
    Persona: Jesteś starszym inżynierem oprogramowania, który pisze zwięzłe post-mortemy.
    Przeanalizuj poniższy kontekst dotyczący naprawy błędu i wyciągnij z niego kluczowe, gotowe do użycia wnioski.
    Kontekst:
    [ANALIZA PROBLEMU WG DEBUGGERA]: {debugger_analysis}
    [WADLIWY FRAGMENT KODU]: {intelligent_truncate(failing_code, 500)}
    [POPRAWIONY KOD]: {intelligent_truncate(corrected_code, 500)}
    Zadanie: Na podstawie powyższego kontekstu, wygeneruj obiekt JSON zgodny ze strukturą DistilledMemory.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomyślnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEŻENIE: Destylacja (naprawa) nie powiodła się: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}
    
    
    
    

    
def distill_full_fix_session(initial_error: str, fix_attempts: List[Dict], successful_code: str) -> Dict[str, Any]:
    """Używa LLM, aby podsumować całą sesję naprawczą w jedno zwięzłe wspomnienie."""
    print("  [INFO] Uruchamiam destylację całej sesji naprawczej...")

    # Tworzymy skonsolidowaną historię analiz debuggera
    consolidated_analysis = "\n".join(
        [f"Próba {i+1}: {attempt.get('debugger_analysis', 'Brak analizy.')}" for i, attempt in enumerate(fix_attempts)]
    )

    prompt_template = f"""
Persona: Jesteś starszym inżynierem, który pisze ekstremalnie zwięzłe post-mortemy. Priorytetem jest gęstość informacji przy minimalnej liczbie słów.

Przeanalizuj całą sesję naprawy błędu i wyciągnij z niej kluczowe wnioski.

[PIERWOTNY BŁĄD]:
{initial_error}

[HISTORIA ANALIZ Z NIEUDANYCH PRÓB NAPRAWY]:
{consolidated_analysis}

[KOD, KTÓRY OSTATECZNIE ZADZIAŁAŁ]:
{successful_code}

Zadanie: Wygeneruj obiekt JSON. Każde pole tekstowe musi być pojedynczym, klarownym zdaniem. Całość nie może przekroczyć 150 słów.
"""
    try:
        llm = ChatVertexAI(
            model_name=MAIN_AGENT, 
            project_id=PROJECT_ID, 
            location=LOCATION,
            max_output_tokens=512
        )
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("  [INFO] Pomyślnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"  [OSTRZEŻENIE] Destylacja sesji nie powiodła się: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}



    
def generate_meta_insight(audit_report: str) -> Optional[dict]:
    """Używa LLM do wyciągnięcia z raportu audytora jednego, kluczowego wniosku."""
    print("INFO: Uruchamiam proces generowania wniosku META...")
    prompt = f"""
    Przeanalizuj poniższy raport audytora. Twoim zadaniem jest znalezienie JEDNEJ, najważniejszej i najbardziej konkretnej rekomendacji dotyczącej ulepszenia systemu.
    Jeśli znajdziesz taką rekomendację, przekształć ją w obiekt JSON zgodny ze strukturą MetaInsightMemory. Jeśli raport jest ogólnikowy i nie zawiera konkretnych propozycji, zwróć null.
    [RAPORT AUDYTORA]:\n{audit_report}
    """
    try:
        llm = ChatAnthropic(model_name=CRITIC_MODEL, temperature=0.2)
        structured_llm = llm.with_structured_output(MetaInsightMemory)
        insight_object = structured_llm.invoke(prompt)
        print("INFO: Pomyślnie wygenerowano wniosek META.")
        return insight_object.dict()
    except Exception:
        print("OSTRZEŻENIE: Nie udało się wygenerować wniosku META z raportu audytora.")
        return None


