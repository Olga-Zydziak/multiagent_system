--- FILE: __init__.py ---




--- FILE: config.py ---

import os
import logging
from enum import Enum
from google.cloud import secretmanager
import langchain
from langchain.cache import SQLiteCache





def get_secret(project_id: str, secret_id: str, version_id: str = "latest") -> str:
    """Pobiera wartość sekretu z Google Secret Manager."""
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{project_id}/secrets/{secret_id}/versions/{version_id}"
    response = client.access_secret_version(request={"name": name})
   
    return response.payload.data.decode("UTF-8")


class ApiType(Enum):
    GOOGLE = "google"
    ANTHROPIC = "anthropic"
    def __str__(self):
        return self.value


LOCATION="us-central1"
PROJECT_ID="dark-data-discovery"

#---------AGENTS--------:
MAIN_AGENT="gemini-2.5-pro"
API_TYPE_GEMINI=str(ApiType.GOOGLE)

CRITIC_MODEL="claude-3-7-sonnet-20250219"
CODE_MODEL="claude-sonnet-4-20250514"
API_TYPE_SONNET = str(ApiType.ANTHROPIC)

LANGCHAIN_API_KEY = get_secret(PROJECT_ID,"LANGCHAIN_API_KEY")
ANTHROPIC_API_KEY=get_secret(PROJECT_ID,"ANTHROPIC_API_KEY")

MEMORY_ENGINE_DISPLAY_NAME="memory-gamma-way"

INPUT_FILE_PATH = "gs://super_model/data/structural_data/synthetic_fraud_dataset.csv"

MAX_CORRECTION_ATTEMPTS=5



os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_API_KEY"] = LANGCHAIN_API_KEY
os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
os.environ["LANGCHAIN_PROJECT"] = "Projekt Multi-Agent-System v9.0-Integrated"
os.environ["ANTHROPIC_API_KEY"] =ANTHROPIC_API_KEY


#---cache-------
langchain.llm_cache = SQLiteCache(database_path=".langchain.db")



    
#FUNKCJA KONFIGURACYJNA AGENTOW AUTOGEN
def basic_config_agent(agent_name:str, api_type:str, location:str=None, project_id:str=None, api_key:str=None):
    try:
        configuration = {"model": agent_name, "api_type": api_type}
        if api_key: configuration["api_key"] = api_key
        if project_id: configuration["project_id"] = project_id
        if location: configuration["location"] = location
        logging.info(f"Model configuration: {configuration}")
        return [configuration]

    except Exception as e:
        logging.error(f"Failed to initialize Vertex AI or configure LLM: {e}")
        print(f"Error: Failed to initialize Vertex AI or configure LLM. Please check your project ID, region, and permissions. Details: {e}")
        exit()


--- FILE: main.ipynb ---

import os
import pandas as pd
import uuid
import json
import vertexai
from vertexai import agent_engines
from langgraph.graph import StateGraph, END
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
# Importy z własnych modułów
from config import PROJECT_ID, LOCATION, MEMORY_ENGINE_DISPLAY_NAME, INPUT_FILE_PATH,MAIN_AGENT,CRITIC_MODEL,CODE_MODEL, API_TYPE_GEMINI,API_TYPE_SONNET, ANTHROPIC_API_KEY,basic_config_agent
from agents.state import AgentWorkflowState
from agents.autogen_agents import TriggerAgent,PlannerAgent,CriticAgent
from prompts import LangchainAgentsPrompts,AutoGenAgentsPrompts
from prompts_beta import PromptFactory
from agents.langgraph_nodes import * 
from agents.autogen_agent_utils import run_autogen_planning_phase
from memory.memory_bank_client import MemoryBankClient
from tools.utils import *
# --- Koniec komórki ---
AGENT_ENGINE_NAME = "" # Zostanie wypełniona po pobraniu lub utworzeniu silnika

# Inicjalizacja głównego klienta Vertex AI
client = vertexai.Client(project=PROJECT_ID, location=LOCATION)
# --- Koniec komórki ---
def get_or_create_agent_engine(display_name: str) :
    """
    Pobiera istniejący Agent Engine po nazwie wyświetlanej lub tworzy nowy, jeśli nie istnieje.
    """
    # 1. Pobierz listę wszystkich istniejących silników w projekcie
    all_engines = agent_engines.list()
    
    # 2. Sprawdź, czy któryś z nich ma pasującą nazwę
    for engine in all_engines:
        if engine.display_name == display_name:
            print(f"INFO: Znaleziono i połączono z istniejącym Agent Engine: '{display_name}'")
            return engine
            
    # 3. Jeśli pętla się zakończyła i nic nie znaleziono, stwórz nowy silnik
    print(f"INFO: Nie znaleziono Agent Engine o nazwie '{display_name}'. Tworzenie nowego...")
    try:
        new_engine = agent_engines.create(
            display_name=display_name
        )
        print(f"INFO: Pomyślnie utworzono nowy Agent Engine.")
        return new_engine
    except Exception as e:
        print(f"KRYTYCZNY BŁĄD: Nie można utworzyć Agent Engine. Sprawdź konfigurację i uprawnienia. Błąd: {e}")
        exit()

# --- Koniec komórki ---
agent_engine =get_or_create_agent_engine(MEMORY_ENGINE_DISPLAY_NAME)
AGENT_ENGINE_NAME = agent_engine.resource_name
print(AGENT_ENGINE_NAME)

# --- Koniec komórki ---
# --- Konfiguracja czatu grupowego ---
main_agent_configuration={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(agent_name=MAIN_AGENT, api_type=API_TYPE_GEMINI, location=LOCATION, project_id=PROJECT_ID)}
critic_agent_configuration ={"cache_seed": 42,"seed": 42,"temperature": 0.0,
                        "config_list": basic_config_agent(api_key=ANTHROPIC_API_KEY,agent_name=CRITIC_MODEL, api_type=API_TYPE_SONNET)}

#---WYWOŁANIE AGENTÓW
trigger_agent = TriggerAgent(llm_config=main_agent_configuration, prompt=PromptFactory.for_trigger())
planner_agent = PlannerAgent(llm_config=main_agent_configuration, prompt=PromptFactory.for_planner()) # Tutaj nie przekazujemy inspiracji
critic_agent = CriticAgent(llm_config=critic_agent_configuration, prompt=PromptFactory.for_critic())
# --- Koniec komórki ---

# --- Koniec komórki ---
if __name__ == "__main__":
    
    files_to_exclude = {'Agents_beta (10).py','pack_project.ipynb', 'caly_projekt.txt'}
    system_source_code = read_project_source_code(".", exclude_files=files_to_exclude)

    # --- Inicjalizacja Pamięci i Uruchomienia ---
    memory_client = MemoryBankClient(client=client, agent_engine=agent_engine)
    run_id = str(uuid.uuid4())
    
    print("\n--- ODPYTYWANIE PAMIĘCI O INSPIRACJE ---")
    inspiration_prompt = ""
    dataset_signature = ""
    try:
        df_preview = pd.read_csv(INPUT_FILE_PATH, nrows=0)
        dataset_signature = memory_client.create_dataset_signature(df_preview)
        past_memories = memory_client.query_memory(
            query_text="Najlepsze strategie i kluczowe wnioski dotyczące przetwarzania danych",
            scope={"dataset_signature": dataset_signature},
            top_k=3
        )
        if past_memories:
            inspirations = []
            for mem in past_memories:
                # ZMIANA: Używamy nowych, poprawnych typów wspomnień
                if mem.memory_type == MemoryType.SUCCESSFUL_WORKFLOW and 'key_planning_insight' in mem.content:
                    inspirations.append(f"SPRAWDZONY WNIOSEK Z PROCESU: {mem.content['key_planning_insight']}")
                elif mem.memory_type == MemoryType.SUCCESSFUL_FIX and 'key_takeaway' in mem.content:
                    inspirations.append(f"NAUCZKA Z NAPRAWIONEGO BŁĘDU: {mem.content['key_takeaway']}")
            if inspirations:
                inspiration_prompt = "--- INSPIRACJE Z POPRZEDNICH URUCHOMIEŃ ---\n" + "\n".join(inspirations)
                print("INFO: Pomyślnie pobrano inspiracje z pamięci.")
        else:
            print("INFO: Nie znaleziono inspiracji w pamięci dla tego typu danych.")
    except Exception as e:
        print(f"OSTRZEŻENIE: Nie udało się pobrać inspiracji z pamięci: {e}")

        
        
    active_policies = get_active_policies_from_memory(memory_client, dataset_signature)    
    
    # --- Krok 1: Faza planowania (AutoGen) ---
    final_plan, autogen_log = run_autogen_planning_phase(
        input_path=INPUT_FILE_PATH, 
        inspiration_prompt=inspiration_prompt,
        trigger_agent=trigger_agent,
        planner_agent=planner_agent,
        critic_agent=critic_agent,
        manager_agent_config=main_agent_configuration,
        active_policies=active_policies
    )
    save_autogen_conversation_log(log_content=autogen_log, file_path="reports/autogen_planning_conversation.log")

    # --- Krok 2: Faza wykonania (LangGraph) ---
    if final_plan:
        print("\n" + "="*80)
        print("### ### FAZA 2: URUCHAMIANIE WYKONANIA PLANU (LangGraph) ### ###")
        print("="*80 + "\n")
        
        workflow = StateGraph(AgentWorkflowState)
        
        # <<< ZMIANA TUTAJ: Zaktualizowana lista węzłów >>>
        nodes = [
            "schema_reader", "code_generator", "architectural_validator", 
            "data_code_executor", "universal_debugger", "apply_code_fix", 
            "human_approval", "package_installer", "human_escalation", 
            "sync_report_code","meta_auditor",
            # Nowe, wyspecjalizowane węzły raportujące:
            "summary_analyst", "plot_generator", "report_composer","memory_consolidation"
        ]
        for name in nodes: workflow.add_node(name, globals()[f"{name}_node"])

        # Definicja krawędzi
        workflow.set_entry_point("schema_reader")
        
        # Ścieżka przetwarzania danych
        workflow.add_edge("schema_reader", "code_generator")
        workflow.add_edge("code_generator", "architectural_validator")
        
        def should_continue_or_debug(state: AgentWorkflowState) -> str:
            if state.get("error_message"):
                if state.get("correction_attempts", 0) >= MAX_CORRECTION_ATTEMPTS:
                    return "request_human_help"
                return "call_debugger"
            return "continue"

        workflow.add_conditional_edges(
            "architectural_validator",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "data_code_executor"}
        )
        workflow.add_conditional_edges(
            "data_code_executor",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "summary_analyst"}
        )
        
        workflow.add_conditional_edges(
            "summary_analyst",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "plot_generator"}
        )
        workflow.add_conditional_edges(
            "plot_generator",
            should_continue_or_debug,
            {"call_debugger": "universal_debugger", "request_human_help": "human_escalation", "continue": "report_composer"}
        )
        workflow.add_conditional_edges(
            "report_composer",
            should_continue_or_debug,
            {"universal_debugger": "universal_debugger", "human_escalation": "human_escalation", "continue": "meta_auditor"}
        )

        # Ścieżki naprawcze
        workflow.add_edge("human_escalation", "meta_auditor")
        workflow.add_edge("package_installer", "data_code_executor")

        def route_after_fix(state):
            failing_node = state.get("failing_node")
            # Po naprawie wraca do węzła, który zawiódł
            if failing_node:
                return failing_node
            # Domyślnie wraca do walidacji
            return "architectural_validator"

        workflow.add_conditional_edges("apply_code_fix", route_after_fix)

        def route_from_debugger(state):
            if state.get("tool_choice") == "propose_code_fix":
                return "apply_code_fix"
            if state.get("tool_choice") == "request_package_installation":
                return "human_approval"
            return "human_escalation"

        workflow.add_conditional_edges("universal_debugger", route_from_debugger)
        workflow.add_conditional_edges("human_approval", lambda s: s.get("user_approval_status"), {
            "APPROVED": "package_installer", "REJECTED": "universal_debugger"
        })

        
        workflow.add_edge("human_escalation", "meta_auditor")
        workflow.add_edge("meta_auditor", "memory_consolidation")
        workflow.add_edge("memory_consolidation", END)
        
        app = workflow.compile()
        
        app_config = {"MAIN_AGENT": MAIN_AGENT, "CODE_MODEL": CODE_MODEL, "CRITIC_MODEL": CRITIC_MODEL}
        
        initial_state = {
            "config": app_config,
            "plan": final_plan, 
            "input_path": INPUT_FILE_PATH,
            "output_path": "reports/processed_data.csv",
            "report_output_path": "reports/transformation_report.html",
            "correction_attempts": 0, 
            "correction_history": [],
            "source_code": system_source_code,
            "autogen_log": autogen_log,
            "memory_client": memory_client,
            "run_id": run_id,
            "dataset_signature": dataset_signature,
            "pending_fix_session": None,
            "active_policies": active_policies
        }
        
        langgraph_log = ""
        final_run_state = initial_state.copy()
        
        for event in app.stream(initial_state, {"recursion_limit": 50}):
            for node_name, state_update in event.items():
                if "__end__" not in node_name:
                    print(f"--- Krok: '{node_name}' ---")
                    if state_update:
                        printable_update = state_update.copy()
                        for key in ["generated_code", "corrected_code", "generated_report_code", "error_context_code", "plot_generation_code", "summary_html"]:
                            if key in printable_update and printable_update[key]:
                                print(f"--- {key.upper()} ---")
                                print(printable_update[key])
                                print("-" * (len(key) + 8))
                                del printable_update[key]
                        if printable_update:
                            print(json.dumps(printable_update, indent=2, default=str))
                        
                        log_line = f"--- Krok: '{node_name}' ---\n{json.dumps(state_update, indent=2, default=str)}\n"
                        langgraph_log += log_line
                        final_run_state.update(state_update)
                    else:
                        print("  [INFO] Węzeł zakończył pracę bez aktualizacji stanu.")
                    print("-" * 20 + "\n")

        save_langgraph_execution_log(log_content=langgraph_log, file_path="reports/langgraph_execution.log")

        final_run_state['langgraph_log'] = langgraph_log
        meta_auditor_node(final_run_state)

        print("\n\n--- ZAKOŃCZONO PRACĘ GRAFU I AUDYT ---")
    else:
        print("Proces zakończony. Brak planu do wykonania.")
# --- Koniec komórki ---

# --- Koniec komórki ---



--- FILE: prompts.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import json
import re

class AutoGenAgentsPrompts:
    
    @staticmethod
    def Trigger_prompt() -> str:
        
        return f"""Jesteś 'Strażnikiem Danych'. Twoim jedynym zadaniem jest analiza podsumowania danych (nazwy kolumn, pierwsze wiersze).
Na tej podstawie musisz podjąć decyzję: czy te dane mają charakter **tabularyczny** (jak plik CSV lub tabela bazy danych)?
- Jeśli TAK: odpowiedz **tylko i wyłącznie**: 'Dane są tabularyczne. Przekazuję do PlannerAgent w celu stworzenia planu analizy.'. Nie dodawaj nic więcej.
- Jeśli NIE (np. są to logi serwera, obrazy, czysty tekst): Twoja wiadomość MUSI kończyć się słowem 'TERMINATE'. Wyjaśnij krótko, dlaczego dane nie są tabularyczne, np. 
'Dane nie są tabularyczne, to zbiór artykułów tekstowych. TERMINATE'. """
    
    
    @staticmethod
    def Planner_prompt()->str:
        
        return f"""Jesteś 'Architektem Planu'. Otrzymałeś potwierdzenie, że dane są tabularyczne.
Twoim zadaniem jest stworzenie szczegółowego, numerowanego planu czyszczenia i przygotowania danych do ogólnej analizy i modelowania. Plan musi być praktyczny i zgodny z najlepszymi praktykami.
Twoje zadanie składa się z dwóch części:
1.  **Analiza Inspiracji:** Jeśli w wiadomości od użytkownika znajduje się sekcja '--- INSPIRACJE Z POPRZEDNICH URUCHOMIEŃ ---', 
potraktuj ją jako cenną inspirację i punkt wyjścia. Zawiera ona sprawdzoną strategię ("złotą myśl") i może również zawierać konkretne kroki. Twoim zadaniem jest **krytyczna adaptacja** tego planu. 
**Sprawdź, czy każdy krok z inspiracji ma sens w kontekście AKTUALNEGO podglądu danych.** Możesz usunąć, dodać lub zmodyfikować kroki, aby idealnie pasowały do obecnego problemu.
2.  **Tworzenie Planu:** Jeśli nie ma inspiracji, stwórz nowy, solidny plan od podstaw.
Plan powinien zawierać kroki takie jak:
1.  Weryfikacja i obsługa brakujących wartości (np. strategia imputacji dla każdej istotnej kolumny).
2.  Weryfikacja i korekta typów danych (np. konwersja stringów na daty lub liczby).
3.  Inżynieria cech (np. tworzenie nowych, użytecznych kolumn jak 'dzien_tygodnia' z daty lub kategoryzacja wartości liczbowych).
4.  Wykrywanie i obsługa wartości odstających (outlierów).
5.  Normalizacja lub skalowanie danych (jeśli to konieczne, wyjaśnij krótko dlaczego).

Po przedstawieniu pierwszej wersji planu, oczekuj na recenzję od CriticAgenta.
- Jeśli CriticAgent prześle uwagi, stwórz **NOWĄ, KOMPLETNĄ WERSJĘ** planu, która uwzględnia **WSZYSTKIE** jego sugestie.
- W poprawionym planie zaznacz, co zostało zmienione. Prześlij zaktualizowany plan z powrotem do CriticAgenta.
Kontynuuj ten proces, aż CriticAgent ostatecznie zaakceptuje Twój plan. """
    
    
    @staticmethod
    def Critic_prompt() ->str:
        
        return f"""Jesteś 'Recenzentem Jakości'. Twoim zadaniem jest konstruktywna krytyka planu od PlannerAgenta. Oceń go pod kątem praktyczności, realizmu i efektywności.
Twoje Złote Zasady:
1.  **PROSTOTA JEST KLUCZEM:** Agresywnie kwestionuj nadmiernie skomplikowane kroki. Czy naprawdę potrzebujemy KNNImputer, gdy prosta mediana wystarczy?
2.  **JEDNA ZMIANA NA RAZ:** Jeśli plan proponuje stworzenie kilku złożonych cech w jednym kroku, odrzuć to. Zarekomenduj podzielenie tego na osobne, łatwiejsze do weryfikacji kroki. 
Plan musi być odporny na błędy.
3.  **KONKRETNE SUGESTIE:** Zawsze podawaj konkretną alternatywę. Zamiast 'To jest złe', napisz 'Krok X jest nieoptymalny. Sugeruję Y, ponieważ Z.'

**PROCES ZATWIERDZANIA (KRYTYCZNIE WAŻNE):**
- Jeśli plan wymaga jakichkolwiek poprawek, jasno je opisz i odeślij do PlannerAgenta. **NIE UŻYWAJ** poniższych fraz kluczowych.
- Jeśli plan jest **doskonały** i nie wymaga żadnych zmian, Twoja odpowiedź **MUSI** mieć następującą, ścisłą strukturę:
Najpierw napisz linię:
`OSTATECZNY PLAN:`
Poniżej wklej **CAŁY, KOMPLETNY** plan od PlannerAgenta.
Na samym końcu wiadomości dodaj frazę:
`PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI` """
    
    
    
class LangchainAgentsPrompts:
    
    SYSTEM_PROMPT_NEXUS_ENGINEER = """
# ===================================================================
# ### GŁÓWNA DYREKTYWA: PERSONA I CEL ###
# ===================================================================
Jesteś "Nexus" – światowej klasy, autonomicznym inżynierem oprogramowania AI. Twoją specjalizacją jest pisanie czystego, wydajnego i solidnego kodu w Pythonie. Twoim nadrzędnym celem jest rozwiązywanie problemów poprzez dostarczanie kompletnych, gotowych do wdrożenia i samowystarczalnych skryptów.

# ===================================================================
# ### ZASADY PODSTAWOWE (CORE PRINCIPLES) ###
# ===================================================================
Zawsze przestrzegaj następujących zasad:

1.  **Myślenie Krok po Kroku (Chain of Thought):** Zanim napiszesz jakikolwiek kod, najpierw przeanalizuj problem i stwórz plan działania. Zapisz ten plan w formie komentarzy w kodzie. To porządkuje Twoją logikę i prowadzi do lepszych rozwiązań.
2.  **Solidność i Odporność (Robustness):** Przewiduj potencjalne problemy i skrajne przypadki (edge cases). Jeśli to stosowne, używaj bloków `try...except` do obsługi błędów. Upewnij się, że kod nie zawiedzie przy nieoczekiwanych danych wejściowych.
3.  **Samowystarczalność (Self-Containment):** Twój kod musi być w pełni kompletny. Nie zakładaj istnienia żadnych zewnętrznych zmiennych, plików czy funkcji, o ile nie zostały one jawnie wymienione jako "Dostępne Zasoby".
4.  **Przejrzystość ponad Spryt (Clarity over Cleverness):** Pisz kod, który jest łatwy do zrozumienia dla człowieka. Używaj czytelnych nazw zmiennych i dodawaj komentarze tam, gdzie logika jest złożona. Unikaj nadmiernie skomplikowanych, jednowierszowych rozwiązań.

# ===================================================================
# ### PROCES ROZWIĄZYWANIA PROBLEMÓW ###
# ===================================================================
Gdy otrzymujesz zadanie, postępuj według następującego schematu:

1.  **ANALIZA CELU:** W pełni zrozum, co ma zostać osiągnięte. Zidentyfikuj dane wejściowe i oczekiwany rezultat.
2.  **TWORZENIE PLANU:** Wewnątrz bloku kodu, stwórz plan działania w formie komentarzy (`# Krok 1: ...`, `# Krok 2: ...`).
3.  **IMPLEMENTACJA KODU:** Napisz kod, który realizuje Twój plan.
4.  **AUTOKOREKTA I WERYFIKACJA:** Zanim zakończysz, dokonaj krytycznego przeglądu własnego kodu. Zadaj sobie pytania: "Czy ten kod jest kompletny?", "Czy obsłużyłem przypadki brzegowe?", "Czy jest zgodny ze wszystkimi zasadami?". Popraw wszelkie znalezione niedociągnięcia.

"""
    
    
    
    
    
    @staticmethod
    def code_generator(plan: str, available_columns: List[str]) -> str:
        task_prompt = f"""
# ===================================================================
# ### AKTUALNE ZADANIE: GENEROWANIE KODU ###
# ===================================================================
**Cel:** Na podstawie poniższego planu biznesowego i dostępnych danych, napisz kompletny i samowystarczalny skrypt w Pythonie.

**Plan Biznesowy do Implementacji:**
{plan}

**Dostępne Kolumny w Danych:**
{available_columns}

**Wymagania Architektoniczne (Bezwzględnie Przestrzegaj):**
{ArchitecturalRulesManager.get_rules_as_string()}
""" 
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER+ task_prompt
    
    @staticmethod
    def tool_based_debugger(failing_node: str,active_policies: Optional[str] = None) -> str:
        
        policy_section = ""
        if active_policies:
            policy_section = active_policies
        
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER+ f"""Jesteś 'Głównym Inżynierem Jakości Kodu'.
        {policy_section}
        Twoim zadaniem jest nie tylko naprawienie zgłoszonego błędu, ale zapewnienie, że kod będzie działał poprawnie.
        --- KONTEKST ZADANIA ---
Błąd wystąpił w węźle o nazwie: '{failing_node}'. Twoje zadanie zależy od tego kontekstu:
- Jeśli `failing_node` to 'data_code_executor' lub 'architectural_validator', Twoim zadaniem jest naprawa GŁÓWNEGO skryptu do przetwarzania danych.
- Jeśli `failing_node` to 'plot_generator_node', Twoim zadaniem jest napisanie FRAGMENTU KODU W PYTHONIE, który generuje wykresy.
- Jeśli `failing_node` to 'summary_analyst_node', Twoim zadaniem jest napisanie kodu HTML z podsumowaniem analitycznym.
**Bezwzględnie przestrzegaj tych zasad:**
     - Używaj WYŁĄCZNIE biblioteki `matplotlib.pyplot`. Nie używaj `plotly` ani `seaborn`.
    - NIE importuj bibliotek.
    - Używaj tylko ramek danych `df_original` i `df_processed`.
    - NIE używaj `plt.show()`.
    - Każdą figurę (`fig`) MUSISZ dodać do listy `figures_to_embed`.
---
--- NOWA ZDOLNOŚĆ: DIAGNOZA NARZĘDZI ---
Jeśli traceback błędu (np. NameError, AttributeError) wskazuje na funkcję, która jest wewnętrznym narzędziem systemu, a nie na kod, który masz naprawić, użyj narzędzia `inspect_tool_code`, aby przeczytać kod źródłowy tego narzędzia. Przeanalizuj go i, jeśli znajdziesz w nim błąd (np. brakujący import), w swojej finalnej poprawce do `corrected_code` dołącz brakujące importy lub logikę, aby naprawić również ten błąd.
- Jeśli błąd to `ModuleNotFoundError`, użyj `request_package_installation`.
- Jeśli błąd to `ImportError` wskazujący na konflikt wersji, również użyj `request_package_installation`, aby zasugerować aktualizację pakietu, który jest źródłem błędu.
- Dla wszystkich innych błędów w kodzie (np. `SyntaxError`, `KeyError`), użyj `propose_code_fix` a następnie przeanalizuj poniższy błąd i wadliwy kod. Twoja praca składa się z dwóch kroków:
1.  **Analiza i Naprawa:** Zidentyfikuj przyczynę błędu i stwórz kompletną, poprawioną wersję całego skryptu.
2.  **Wywołanie Narzędzia:** Wywołaj narzędzie `propose_code_fix`, podając **OBOWIĄZKOWO** dwa argumenty: `analysis` (twoja analiza) oraz `corrected_code` (pełny, naprawiony kod).
Przeanalizuj poniższy błąd i wadliwy kod. """

    @staticmethod
    def summary_analyst_prompt(plan: str, original_summary: str, processed_summary: str) -> str:
        """
        Tworzy prompt dla agenta, którego JEDYNYM zadaniem jest analiza
        i napisanie tekstowego podsumowania w HTML.
        """
        return f"""
        Jesteś analitykiem danych. Twoim jedynym zadaniem jest napisanie zwięzłego, menedżerskiego podsumowania w formacie HTML, które podkreśla kluczowe korzyści z transformacji danych.
        Skup się na zmianach w brakujących danych, wartościach odstających i liczbie kolumn.
        
        PLAN TRANSFORMACJI, KTÓRY MASZ OPISAĆ: 
        {plan}
        
        DANE PRZED TRANSFORMACJĄ (PODSUMOWANIE): 
        {original_summary}
        
        DANE PO TRANSFORMACJI (PODSUMOWANIE): 
        {processed_summary}
        
        Twoja odpowiedź musi być tylko i wyłącznie kodem HTML, gotowym do wstawienia do raportu.
        """

    @staticmethod
    def plot_generator_prompt(plan: str,available_columns: List[str]) -> str:
        """
        Tworzy prompt dla agenta, którego JEDYNYM zadaniem jest napisanie
        kodu w Pythonie do generowania wykresów.
        """
        return LangchainAgentsPrompts.SYSTEM_PROMPT_NEXUS_ENGINEER + f"""
        Jesteś ekspertem od wizualizacji danych w Pythonie przy użyciu biblioteki Matplotlib.
        Twoim jedynym zadaniem jest napisanie fragmentu kodu w Pythonie.
        
        PLAN, KTÓRY MASZ ZILUSTROWAĆ:
        {plan}

        --- KRYTYCZNE INFORMACJE ---
        DOSTĘPNE KOLUMNY W DANYCH `df_processed`, KTÓRYCH MOŻESZ UŻYĆ:
        {available_columns}
        --- KONIEC KRYTYCZNYCH INFORMACJI ---
        
        WAŻNE ZASADY:
        1.  **Generuj wykresy TYLKO dla kolumn, które znajdują się na powyższej liście dostępnych kolumn.**
        2.  Każdy wykres musi mieć tytuł i czytelne etykiety osi.
        3.  Użyj `fig.tight_layout()` przed dodaniem figury do listy.
        4.  **Używaj WYŁĄCZNIE biblioteki `matplotlib.pyplot`. Nie używaj `plotly` ani `seaborn`.**
        5.  NIE importuj bibliotek. Zakładaj, że `matplotlib.pyplot as plt` i `pandas as pd` są już dostępne.
        6.  NIE twórz własnych danych. Używaj wyłącznie ramek danych `df_original` i `df_processed`.
        7.  NIE używaj `plt.show()`. Twoim zadaniem jest tylko stworzenie obiektów figur.
        8.  Każdą stworzoną figurę (`fig`) MUSISZ dodać do listy o nazwie `figures_to_embed`.
        9.  Twoja odpowiedź musi zawierać TYLKO i WYŁĄCZNIE kod Pythona.
        10. **Twoja odpowiedź MUSI być obiektem JSON zawierającym jeden klucz: "code", którego wartością jest skrypt Pythona jako string.**
        """

    @staticmethod
    def create_meta_auditor_prompt(source_code: str, autogen_conversation: str, langgraph_log: str, final_code: str, final_report: str, escalation_report: Optional[str] = None) -> str:
        
        escalation_section = ""
        if escalation_report:
            escalation_section = f"""
# ===================================================================
# ### RAPORT Z ESKALACJI DO CZŁOWIEKA ###
# ===================================================================
UWAGA: System nie zdołał samodzielnie rozwiązać problemu i wymagał interwencji. To jest najważniejszy element do analizy.
{escalation_report}
"""
        
        return f"""**Persona:** Główny Audytor Systemów AI. Twoim zadaniem jest krytyczna ocena całego procesu AI.
        {escalation_section}
**Dostępne Dane do Analizy:**
1. KOD ŹRÓDŁOWY SYSTEMU:\n```python\n{source_code}\n```
2. ZAPIS ROZMOWY (PLANOWANIE):\n```\n{autogen_conversation}\n```
3. LOGI (WYKONANIE):\n```\n{langgraph_log}\n```
4. FINALNY KOD:\n```python\n{final_code}\n```
5. FINALNY RAPORT (fragment):\n```html\n{final_report[:2000]}\n```
**Zadania Audytorskie (odpowiedz na każde pytanie):**
1. **Ocena Planowania:** Czy dyskusja Planner-Krytyk była efektywna? Czy Krytyk był rygorystyczny?
2. **Ocena Wykonania:** Czy były pętle naprawcze? Jak skuteczny był debugger?
3. **Ocena Produktu:** Czy raport HTML jest użyteczny?
4. **Ocena Promptów Agentów (Analiza Meta):**
    - Na podstawie analizy logów i kodu źródłowego, oceń jakość i precyzję promptów dla poszczególnych agentów (Planner, Krytyk, Debugger, Generator Raportu).
    - Czy któryś z zaobserwowanych problemów (nawet tych naprawionych) mógł wynikać z niejasności w prompcie?
    - Czy widzisz możliwość ulepszenia któregoś z promptów, aby system działał bardziej niezawodnie lub efektywnie w przyszłości?
5. **Rekomendacje do Samodoskonalenia:** Zaproponuj 1-3 konkretne zmiany w kodzie lub promptach, które usprawnią system.
**Format Wyjściowy:** Zwięzły raport tekstowy."""
    
    
class ArchitecturalRule(TypedDict):
    id: str; description: str; check: Callable[[str], bool]; error_message: str

ARCHITECTURAL_RULES: List[ArchitecturalRule] = [
    {"id": "NO_MAIN_BLOCK", "description": "Żadnego bloku `if __name__ == '__main__':`.", "check": lambda code: bool(re.search(r'if\s+__name__\s*==\s*["\']__main__["\']\s*:', code)), "error_message": "Wykryto niedozwolony blok `if __name__ == '__main__':`."},
    {"id": "NO_ARGPARSE", "description": "Żadnego `argparse` ani `sys.argv`.", "check": lambda code: bool(re.search(r'import\s+argparse', code)), "error_message": "Wykryto niedozwolony import modułu `argparse`."},
    {"id": "SINGLE_FUNCTION_LOGIC", "description": "Cała logika musi być w funkcji `process_data(input_path: str, output_path: str)`.", "check": lambda code: "def process_data(input_path: str, output_path: str)" not in code, "error_message": "Brak wymaganej definicji funkcji `process_data(input_path: str, output_path: str)`."},
    {"id": "ENDS_WITH_CALL", "description": "Skrypt musi kończyć się **dokładnie jedną linią** w formacie: `process_data(input_path, output_path)  # noqa: F821`. Komentarz `# noqa: F821` jest **obowiązkowy**.", "check": lambda code: not re.search(r'^\s*process_data\(input_path,\s*output_path\)\s*#\s*noqa:\s*F821\s*$', [line for line in code.strip().split('\n') if line.strip()][-1]), "error_message": "Skrypt nie kończy się wymaganym wywołaniem `process_data(input_path, output_path)  # noqa: F821`."},
]

class ArchitecturalRulesManager:
    @staticmethod
    def get_rules_as_string() -> str:
        rules_text = "\n".join(f"        - {rule['description']}" for rule in ARCHITECTURAL_RULES)
        return f"<ARCHITECTURAL_RULES>\n    **Krytyczne Wymagania Dotyczące Struktury Kodu:**\n{rules_text}\n</ARCHITECTURAL_RULES>"


--- FILE: prompts_beta.py ---

from pydantic import BaseModel, Field
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any

# =================================================================================
# sekcja 1: DYREKTYWY SYSTEMOWE (PERSONY NADRZĘDNE)
# Te prompty definiują fundamentalne zasady dla dwóch głównych typów agentów.
# =================================================================================

SYSTEM_PROMPT_ENGINEER = """
# CORE DIRECTIVE: SOFTWARE ENGINEER AI "NEXUS"
Jesteś "Nexus", światowej klasy, autonomicznym inżynierem oprogramowania AI, którego specjalizacją jest pisanie czystego, wydajnego i solidnego kodu w Pythonie. [cite: 61] Twoim nadrzędnym celem jest rozwiązywanie problemów poprzez dostarczanie kompletnych, gotowych do wdrożenia i samowystarczalnych skryptów. [cite: 62, 63]

## CORE PRINCIPLES (NON-NEGOTIABLE)
1.  **Plan-Then-Code:** Zawsze zaczynaj od stworzenia planu działania w formie komentarzy w kodzie (`# Krok 1: ...`). [cite: 73] To zapewnia logiczną strukturę i prowadzi do lepszych rozwiązań.
2.  **Robustness & Resilience:** Przewiduj potencjalne problemy i skrajne przypadki. [cite: 65] Używaj bloków `try...except` do inteligentnej obsługi błędów. [cite: 66] Twój kod musi być kuloodporny.
3.  **Self-Containment:** Kod musi być w pełni kompletny i samowystarczalny. [cite: 67] Nie zakładaj istnienia żadnych zewnętrznych zmiennych, funkcji czy plików, o ile nie zostały jawnie dostarczone w sekcji `<AVAILABLE_RESOURCES>`. [cite: 68]
4.  **Clarity Over Cleverness:** Pisz kod, który jest prosty i czytelny dla człowieka. Używaj jasnych nazw zmiennych i dodawaj komentarze do złożonej logiki. [cite: 70] Unikaj skomplikowanych, jednowierszowych rozwiązań.
"""

SYSTEM_PROMPT_ANALYST = """
# CORE DIRECTIVE: STRATEGIC AI ANALYST "ORACLE"
Jesteś "Oracle", elitarnym analitykiem AI specjalizującym się w strategii, analizie i krytycznym myśleniu. Twoim celem jest przetwarzanie złożonych informacji, podejmowanie trafnych decyzji i komunikowanie wniosków z absolutną precyzją.

## CORE PRINCIPLES (NON-NEGOTIABLE)
1.  **Structured Thinking:** Rozkładaj każdy problem na logiczne komponenty. Zawsze identyfikuj cel, analizuj dostępne dane i formuj wnioski w sposób ustrukturyzowany.
2.  **Evidence-Based Reasoning:** Twoje decyzje i oceny muszą być oparte wyłącznie na dostarczonych danych (`<CONTEXT>`). Unikaj spekulacji i założeń.
3.  **Goal-Oriented Communication:** Komunikuj się w sposób, który bezpośrednio prowadzi do osiągnięcia celu. Bądź zwięzły, precyzyjny i unikaj zbędnych formalności.
4.  **Adherence to Format:** Ściśle przestrzegaj wymaganego formatu wyjściowego (`<OUTPUT_FORMAT>`). Od tego zależy stabilność całego systemu.
"""


class PromptConfig(BaseModel):
    """Struktura przechowująca komponenty jednego, kompletnego promptu."""
    persona: str
    task: str
    rules: List[str] = Field(default_factory=list)
    output_format: Optional[str] = None
    example: Optional[str] = None

    
    
class PromptFactory:
    """
    Centralna fabryka do generowania precyzyjnych i ustrukturyzowanych promptów
    dla wszystkich agentów w systemie.
    """

    @staticmethod
    def _build_prompt(base_directive: str, config: PromptConfig, context: Dict[str, Any]) -> str:
        """Prywatna metoda do składania finalnego promptu."""
        prompt = [base_directive]
        prompt.append(f"## ROLE: {config.persona}")
        prompt.append(f"## TASK: {config.task}")

        if config.rules:
            rules_str = "\n".join(f"{i+1}. {rule}" for i, rule in enumerate(config.rules))
            prompt.append(f"## CRITICAL RULES:\n{rules_str}")

        if context:
            context_str = "\n".join(f"<{key.upper()}>_START\n{value}\n<{key.upper()}>_END" for key, value in context.items())
            prompt.append(f"## CONTEXT:\n{context_str}")

        if config.output_format:
            prompt.append(f"## OUTPUT FORMAT:\n{config.output_format}")

        if config.example:
            prompt.append(f"## EXAMPLE:\n{config.example}")

        return "\n\n".join(prompt)
    
    

    
    @staticmethod
    def for_trigger() -> str:

        return f"""Jesteś 'Strażnikiem Danych'. Twoim jedynym zadaniem jest analiza podsumowania danych (nazwy kolumn, pierwsze wiersze).
    Na tej podstawie musisz podjąć decyzję: czy te dane mają charakter **tabularyczny** (jak plik CSV lub tabela bazy danych)?
    - Jeśli TAK: odpowiedz **tylko i wyłącznie**: 'Dane są tabularyczne. Przekazuję do PlannerAgent w celu stworzenia planu analizy.'. Nie dodawaj nic więcej.
    - Jeśli NIE (np. są to logi serwera, obrazy, czysty tekst): Twoja wiadomość MUSI kończyć się słowem 'TERMINATE'. Wyjaśnij krótko, dlaczego dane nie są tabularyczne, np. 
    'Dane nie są tabularyczne, to zbiór artykułów tekstowych. TERMINATE'. """
    
    @staticmethod
    def for_planner(plan_inspirations: Optional[str] = None) -> str:
        """Prompt dla agenta tworzącego plan przetwarzania danych."""
        context = {"plan_inspirations": plan_inspirations} if plan_inspirations else {}
        config = PromptConfig(
            persona="Jesteś 'Architektem Planu', doświadczonym analitykiem danych.",
            task="Twoim zadaniem jest stworzenie szczegółowego, numerowanego planu czyszczenia i przygotowania danych do analizy. Plan musi być praktyczny, odporny na błędy i podzielony na atomowe, łatwe do weryfikacji kroki. [cite: 41, 56]",
            rules=[
                "Jeśli w kontekście znajdują się 'plan_inspirations', dokonaj ich **krytycznej adaptacji**. Nie kopiuj ślepo. Sprawdź, czy każdy krok ma sens w kontekście **aktualnych** danych. Modyfikuj, usuwaj lub dodawaj kroki wedle potrzeby.",
                "Jeśli nie ma inspiracji, stwórz nowy, solidny plan od podstaw.",
                "Plan musi obejmować: obsługę brakujących wartości, korektę typów danych, inżynierię cech i obsługę wartości odstających.",
                "Oczekuj na recenzję od CriticAgenta. Jeśli prześle uwagi, stwórz **NOWĄ, KOMPLETNĄ WERSJĘ** planu, która uwzględnia **WSZYSTKIE** jego sugestie, i  oznacz wprowadzone zmiany."
            ]  
        )
        return PromptFactory._build_prompt(SYSTEM_PROMPT_ANALYST, config, context)
    
    
    
    @staticmethod
    def for_critic() -> str:
        """Prompt dla agenta krytykującego plan."""
        config = PromptConfig(
            persona="Jesteś 'Recenzentem Jakości', bezkompromisowym krytykiem planów analitycznych. Twoim celem jest zapewnienie, że plan jest maksymalnie prosty, solidny i efektywny.",
            task="Oceń plan od PlannerAgenta pod kątem praktyczności, realizmu i odporności na błędy.",
            rules=[
                "**PROSTOTA JEST KLUCZEM:** Agresywnie kwestionuj nadmiernie skomplikowane kroki. Zawsze proponuj prostszą alternatywę, jeśli istnieje (np. mediana zamiast KNNImputer).",
                "**JEDNA ZMIANA NA RAZ:** Plan musi być granularny. Odrzucaj kroki, które łączą kilka operacji w jedną. Zarekomenduj podzielenie ich na osobne, atomowe zadania.",
                "Jeśli plan wymaga poprawek, jasno je opisz i odeślij do PlannerAgenta. **NIE UŻYWAJ** fraz kluczowych do zatwierdzenia.",
            ],
            output_format="""- Jeśli plan jest **DOSKONAŁY** i nie wymaga **ŻADNYCH** zmian, Twoja odpowiedź **MUSI** mieć następującą, ścisłą strukturę:
OSTATECZNY PLAN:
<tutaj wklejony CAŁY, KOMPLETNY plan od PlannerAgenta>
PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI
``` """,


        )
        return PromptFactory._build_prompt(SYSTEM_PROMPT_ANALYST, config, {})
    
    
    
# --- Prompty dla agentów LangGraph (Faza Wykonania) ---

    @staticmethod
    def for_code_generator(plan: str, available_columns: List[str]) -> str:
        """Prompt dla agenta generującego główny skrypt przetwarzający."""
        context = {
            "business_plan": plan,
            "available_data_columns": ", ".join(available_columns),
            "architectural_rules": ArchitecturalRulesManager.get_rules_as_string()
        }
        config = PromptConfig(
            persona="Jesteś wykonawcą zadania w ramach dyrektywy 'Nexus'.",
            task="Na podstawie planu biznesowego i dostępnych danych, napisz kompletny, samowystarczalny i zgodny z architekturą skrypt w Pythonie do przetwarzania danych. [cite: 77]",
            output_format="Twoja odpowiedź musi zawierać **TYLKO i WYŁĄCZNIE** surowy kod Pythona. Nie umieszczaj go w blokach markdown (` ```python`)."
        )
        return PromptFactory._build_prompt(SYSTEM_PROMPT_ENGINEER, config, context)

    @staticmethod
    def for_universal_debugger(failing_node: str, error_message: str, code_context: str, active_policies: Optional[str] = None) -> str:
        """Prompt dla agenta-debuggera."""
        context = {
            "failing_node": failing_node,
            "error_traceback": error_message,
            "faulty_code": code_context,
            "active_system_policies": active_policies or "Brak"
        }
        config = PromptConfig(
            persona="Jesteś 'Głównym Inżynierem Jakości Kodu' działającym w ramach dyrektywy 'Nexus'. [cite: 78]",
            task="Twoim zadaniem jest zdiagnozowanie przyczyny błędu i wybranie **jednego, najlepszego narzędzia** do jego naprawy. Twoja analiza musi być precyzyjna, a proponowane rozwiązanie kompletne i ostateczne.",
            rules=[
                "Przeanalizuj `failing_node`, aby zrozumieć kontekst błędu (główny skrypt, generator wykresów, etc.). [cite: 80, 81, 82, 83]",
                "Jeśli błąd to `ModuleNotFoundError` lub `ImportError`, użyj narzędzia `request_package_installation`. [cite: 87]",
                "Dla wszystkich innych błędów w kodzie (np. `SyntaxError`, `KeyError`, `AttributeError`), użyj narzędzia `propose_code_fix`. [cite: 88]",
                "Jeśli podejrzewasz, że błąd leży w wewnętrznym narzędziu systemowym, użyj `inspect_tool_code`, aby zbadać jego kod źródłowy przed podjęciem finalnej decyzji. [cite: 86]",
                "`active_system_policies` to dyrektywy o najwyższym priorytecie. Zastosuj się do nich bezwzględnie."
            ],
            output_format="Musisz wywołać jedno z dostępnych narzędzi (`propose_code_fix`, `request_package_installation`, `inspect_tool_code`). Nie odpowiadaj w formie czystego tekstu."
        )
        return PromptFactory._build_prompt(SYSTEM_PROMPT_ENGINEER, config, context)

    @staticmethod
    def for_plot_generator(plan: str, available_columns: List[str]) -> str:
        """Prompt dla agenta generującego kod do wizualizacji."""
        context = {
            "plan_to_illustrate": plan,
            "available_columns_in_df_processed": ", ".join(available_columns)
        }
        config = PromptConfig(
            persona="Jesteś ekspertem od wizualizacji danych w Pythonie, działającym w ramach dyrektywy 'Nexus'. [cite: 98]",
            task="Napisz fragment kodu w Pythonie, który generuje wizualizacje ilustrujące zrealizowany plan transformacji danych.",
            rules=[
                "Używaj **WYŁĄCZNIE** biblioteki `matplotlib.pyplot`. Nie używaj `plotly` ani `seaborn`. [cite: 101]",
                "Generuj wykresy **TYLKO** dla kolumn, które istnieją w `available_columns_in_df_processed`. [cite: 99]",
                "Nie importuj bibliotek ani nie używaj `plt.show()`. Zakładaj, że `plt` i `pd` są już zaimportowane. [cite: 102, 104]",
                "Używaj wyłącznie ramek danych o nazwach `df_original` i `df_processed`. [cite: 103]",
                "Każdy wykres musi mieć tytuł, etykiety osi i wywołanie `fig.tight_layout()`. [cite: 100]",
                "Każdą stworzoną figurę (`fig`) **MUSISZ** dodać do listy o nazwie `figures_to_embed`. To krytycznie ważne. [cite: 105]"
            ],
            output_format="Twoja odpowiedź **MUSI** być obiektem JSON zawierającym jeden klucz: `code`, którego wartością jest skrypt Pythona jako pojedynczy string. [cite: 106]",
            example='{"code": "fig, ax = plt.subplots()\\nax.hist(df_processed[\'amount\'])\\nax.set_title(\'Distribution of Amount\')\\nfig.tight_layout()\\nfigures_to_embed.append(fig)"}'
        )
        return PromptFactory._build_prompt(SYSTEM_PROMPT_ENGINEER, config, context)

    @staticmethod
    def for_summary_analyst(plan: str, original_summary: str, processed_summary: str) -> str:
        """Prompt dla agenta tworzącego podsumowanie w HTML."""
        context = {
            "executed_transformation_plan": plan,
            "data_summary_before": original_summary,
            "data_summary_after": processed_summary
        }
        config = PromptConfig(
            persona="Jesteś analitykiem danych piszącym zwięzłe, menedżerskie podsumowania. [cite: 93]",
            task="Napisz podsumowanie w formacie HTML, które podkreśla kluczowe korzyści z przeprowadzonej transformacji danych. Skup się na zmianach w brakujących danych, typach kolumn i ogólnej jakości danych.",
            output_format="Twoja odpowiedź musi być **tylko i wyłącznie** kodem HTML, gotowym do wstawienia do raportu. Używaj tagów `<h2>`, `<h4>`, `<ul>`, `<li>`. "
        )
        return PromptFactory._build_prompt(SYSTEM_PROMPT_ANALYST, config, context)

    @staticmethod
    def for_meta_auditor(source_code: str, autogen_log: str, langgraph_log: str, final_code: str,final_report: str, escalation_report: Optional[str]) -> str:
        """Prompt dla agenta-audytora całego procesu."""
        context = {
            "system_source_code": source_code,
            "planning_phase_log": autogen_log,
            "execution_phase_log": langgraph_log,
            "final_generated_code": final_code,
            "final_report_html": final_report,
            "human_escalation_report": escalation_report or "Brak eskalacji - proces zakończył się autonomicznie."
        }
        config = PromptConfig(
            persona="Jesteś 'Głównym Audytorem Systemów AI'. Twoim zadaniem jest bezwzględnie krytyczna ocena całego przebiegu procesu AI w celu jego samodoskonalenia.",
            task="Przeanalizuj wszystkie dostępne dane i odpowiedz na każde pytanie z poniższej listy kontrolnej audytu. Bądź surowy, ale sprawiedliwy.",
            rules=[
                "Jeśli istnieje `human_escalation_report`, jego analiza jest Twoim absolutnym priorytetem.",
                "Twoje rekomendacje muszą być konkretne, możliwe do zaimplementowania i odnosić się do konkretnych agentów lub promptów."
            ],
            output_format="""Odpowiedz w formie zwięzłego raportu tekstowego, używając poniższych nagłówków:
            
            Ocena Planowania: (Czy dyskusja Planner-Krytyk była efektywna? Czy Krytyk był wystarczająco rygorystyczny?) 
            Ocena Wykonania: (Czy wystąpiły pętle naprawcze? Jak skuteczny był debugger i czy jego wybory narzędzi były optymalne?) 
            Ocena Jakości Promptów (Analiza Meta): (Czy któryś z problemów, nawet naprawionych, mógł wynikać z niejasności w promptach? Które prompty można ulepszyć?) 
            Rekomendacje do Samodoskonalenia (1-3 punkty): (Zaproponuj konkretne zmiany w kodzie lub promptach, które usprawnią system.) """


        )
        return PromptFactory._build_prompt(SYSTEM_PROMPT_ANALYST, config, context)
    
    
    
class ArchitecturalRule(TypedDict):
    id: str; description: str; check: Callable[[str], bool]; error_message: str

ARCHITECTURAL_RULES: List[ArchitecturalRule] = [
    {"id": "NO_MAIN_BLOCK", "description": "Żadnego bloku `if __name__ == '__main__':`.", "check": lambda code: bool(re.search(r'if\s+__name__\s*==\s*["\']__main__["\']\s*:', code)), "error_message": "Wykryto niedozwolony blok `if __name__ == '__main__':`."},
    {"id": "NO_ARGPARSE", "description": "Żadnego `argparse` ani `sys.argv`.", "check": lambda code: bool(re.search(r'import\s+argparse', code)), "error_message": "Wykryto niedozwolony import modułu `argparse`."},
    {"id": "SINGLE_FUNCTION_LOGIC", "description": "Cała logika musi być w funkcji `process_data(input_path: str, output_path: str)`.", "check": lambda code: "def process_data(input_path: str, output_path: str)" not in code, "error_message": "Brak wymaganej definicji funkcji `process_data(input_path: str, output_path: str)`."},
    {"id": "ENDS_WITH_CALL", "description": "Skrypt musi kończyć się **dokładnie jedną linią** w formacie: `process_data(input_path, output_path)  # noqa: F821`. Komentarz `# noqa: F821` jest **obowiązkowy**.", "check": lambda code: not re.search(r'^\s*process_data\(input_path,\s*output_path\)\s*#\s*noqa:\s*F821\s*$', [line for line in code.strip().split('\n') if line.strip()][-1]), "error_message": "Skrypt nie kończy się wymaganym wywołaniem `process_data(input_path, output_path)  # noqa: F821`."},
]

class ArchitecturalRulesManager:
    @staticmethod
    def get_rules_as_string() -> str:
        rules_text = "\n".join(f"        - {rule['description']}" for rule in ARCHITECTURAL_RULES)
        return f"<ARCHITECTURAL_RULES>\n    **Krytyczne Wymagania Dotyczące Struktury Kodu:**\n{rules_text}\n</ARCHITECTURAL_RULES>"


--- FILE: tools/__init__.py ---




--- FILE: tools/langchain_tools.py ---

from pydantic import BaseModel, Field
from langchain_core.tools import tool
from .utils import TOOL_REGISTRY


# --- Schematy Odpowiedzi Agentów ---    
class GeneratedCode(BaseModel):
    """Przechowuje kompletny i gotowy do wykonania skrypt w Pythonie."""
    code: str = Field(description="Kompletny, surowy kod w Pythonie, gotowy do bezpośredniego wykonania. Musi zawierać wszystkie niezbędne importy i logikę.")   
    
class ReportSummary(BaseModel):
    """Przechowuje podsumowanie analityczne w formacie HTML."""
    summary_html: str = Field(description="Tekst podsumowania w formacie HTML, zawierający tagi takie jak <h2> i <ul>.")    
    
class PlottingCode(BaseModel):
    """Przechowuje kod Pythona do generowania wizualizacji."""
    code: str = Field(description="Czysty kod w Pythonie do generowania figur matplotlib.")
    

class AuditReport(BaseModel):
    """Przechowuje ustrukturyzowaną treść finalnego raportu z audytu."""
    planning_evaluation: str = Field(description="Ocena fazy planowania, w tym dyskusji Planner-Krytyk.")
    execution_evaluation: str = Field(description="Ocena fazy wykonania, w tym pętli naprawczych i skuteczności debuggera.")
    prompt_quality_analysis: str = Field(description="Analiza meta dotycząca jakości promptów i ich wpływu na działanie systemu.")
    recommendations: str = Field(description="Lista 1-3 konkretnych propozycji zmian w kodzie lub promptach w celu usprawnienia systemu.")    
    

# --- Schematy Narzędzi (bez zmian) ---    

class CodeFixArgs(BaseModel):
    analysis: str = Field(description="Techniczna analiza przyczyny błędu i wprowadzonej poprawki w kodzie.")
    corrected_code: str = Field(description="Pełny, kompletny i POPRAWIONY skrypt w Pythonie. Musi być gotowy do wykonania.")
    
class PackageInstallArgs(BaseModel):
    package_name: str = Field(description="Nazwa pakietu, który należy zainstalować, aby rozwiązać błąd 'ModuleNotFoundError'. Np. 'scikit-learn', 'seaborn'.")
    analysis: str = Field(description="Krótka analiza potwierdzająca, że przyczyną błędu jest brakujący pakiet.")

class ReportSummary(BaseModel):
    """Przechowuje podsumowanie analityczne w formacie HTML."""
    summary_html: str = Field(description="Tekst podsumowania w formacie HTML, zawierający tagi takie jak <h2> i <ul>.")

class InspectToolArgs(BaseModel):
    tool_name: str = Field(description="Nazwa funkcji/narzędzia do inspekcji, np. 'embed_plot_to_html'.")
    
#narzędzia dla langchain agentów    
@tool(args_schema=CodeFixArgs)
def propose_code_fix(analysis: str, corrected_code: str) -> None:
    """Użyj tego narzędzia, aby zaproponować poprawioną wersję kodu w odpowiedzi na błąd składniowy lub logiczny."""
    pass

@tool(args_schema=PackageInstallArgs)
def request_package_installation(package_name: str, analysis: str) -> None:
    """Użyj tego narzędzia, aby poprosić o instalację brakującej biblioteki, gdy napotkasz błąd 'ModuleNotFoundError'."""
    pass 


@tool(args_schema=InspectToolArgs)
def inspect_tool_code(tool_name: str) -> str:
    """Użyj tego narzędzia, aby przeczytać kod źródłowy wewnętrznej funkcji systemowej.
    Jest to przydatne, gdy podejrzewasz, że błąd (np. NameError) leży w narzędziu, a nie w kodzie, który analizujesz."""
    if tool_name in TOOL_REGISTRY:
        source_code = inspect.getsource(TOOL_REGISTRY[tool_name])
        return f"Oto kod źródłowy narzędzia '{tool_name}':\n```python\n{source_code}\n```"
    return f"BŁĄD: Nie znaleziono narzędzia o nazwie '{tool_name}'."


--- FILE: tools/utils.py ---

import os
import io
import sys
import subprocess
import inspect
import matplotlib.pyplot as plt
import base64 
import tempfile
import traceback
import uuid
import json
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import datetime
import logging
from memory.memory_models import MemoryType

#--funkcja dla pamieci--
def intelligent_truncate(text: str, max_len: int) -> str:
    """Skraca tekst, zachowując jego początek i koniec."""
    if not isinstance(text, str) or len(text) <= max_len:
        return text
    half_len = (max_len - 25) // 2
    start = text[:half_len]
    end = text[-half_len:]
    return f"{start}\n\n[... treść skrócona ...]\n\n{end}"

def extract_python_code(response: str) -> str:
    response = response.strip()
    match = re.search(r'```python\n(.*?)\n```', response, re.DOTALL)
    if match: return match.group(1).strip()
    if response.startswith("'''") and response.endswith("'''"): return response[3:-3].strip()
    if response.startswith('"""') and response.endswith('"""'): return response[3:-3].strip()
    return response


def install_package(package_name: str, upgrade: bool = True) -> bool:
    """
    Instaluje lub aktualizuje podany pakiet używając pip.
    
    Args:
        package_name (str): Nazwa pakietu do instalacji.
        upgrade (bool): Jeśli True, używa flagi --upgrade.
    """
    try:
        command = [sys.executable, "-m", "pip", "install", package_name]
        if upgrade:
            command.insert(2, "--upgrade")
        
        action = "Aktualizacja" if upgrade else "Instalacja"
        print(f"  [INSTALATOR] Próba: {action} pakietu {package_name}...")
        
        result = subprocess.run(command, check=True, capture_output=True, text=True)
        print(f"  [INSTALATOR] Pomyślnie zakończono. Logi pip:\n{result.stdout}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"  [INSTALATOR] Błąd podczas operacji na pakiecie {package_name}.\n{e.stderr}")
        return False
    

    
#DLA report agenta
def embed_plot_to_html(figure) -> str:
    """Konwertuje figurę matplotlib do stringa base64 do osadzenia w HTML."""
    buffer = io.BytesIO()
    figure.savefig(buffer, format='png', bbox_inches='tight')
    buffer.seek(0)
    image_png = buffer.getvalue()
    buffer.close()
    graphic = base64.b64encode(image_png)
    graphic = graphic.decode('utf-8')
    plt.close(figure) # Ważne: zamykamy figurę
    return f'<img src="data:image/png;base64,{graphic}" alt="Wykres analizy danych"/>'



#Dla meta agenta
def read_source_code(file_path: str) -> str:
    """Odczytuje zawartość pliku kodu źródłowego."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f: return f.read()
    except Exception as e: return f"Nie udało się odczytać kodu źródłowego: {e}"


def read_project_source_code(root_dir=".", exclude_dirs=None, exclude_files=None): # <-- Dodaj nowy argument
    """
    Rekursywnie skanuje katalog projektu, odczytuje zawartość plików .py i .ipynb,
    i łączy je w jeden, sformatowany string dla meta-audytora.
    """
    if exclude_dirs is None:
        exclude_dirs = {'__pycache__', '.ipynb_checkpoints', 'reports', '.git'}
    
    if exclude_files is None: # <-- Dodaj tę sekcję
        exclude_files = set()

    full_source_code = ""
    for dirpath, dirnames, filenames in os.walk(root_dir):
        dirnames[:] = [d for d in dirnames if d not in exclude_dirs]
        
        for filename in filenames:
            if filename in exclude_files: # <-- Dodaj tę linię, aby pomijać pliki
                continue
            
            if filename.endswith(".py") or filename.endswith(".ipynb"):
                file_path = os.path.join(dirpath, filename)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        full_source_code += f"--- FILE: {file_path} ---\n\n{content}\n\n"
                except Exception as e:
                    full_source_code += f"--- FILE: {file_path} ---\n\n[BŁĄD ODCZYTU: {e}]\n\n"
                    
    return full_source_code

#Zapis planowania preprocessingu- AutoGen
def save_autogen_conversation_log(log_content: str, file_path: str):
    """Zapisuje pełną treść konwersacji agentów AutoGen do pliku tekstowego."""
    print(f"INFO: Próba zapisu pełnego logu rozmowy do pliku: {file_path}")
    try:
        # Upewniamy się, że katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PEŁNY ZAPIS ROZMOWY AGENTÓW (FAZA PLANOWANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"✅ SUKCES: Log rozmowy został pomyślnie zapisany.")
    except Exception as e:
        print(f"❌ BŁĄD: Nie udało się zapisać logu rozmowy. Przyczyna: {e}")


        
#Zapis rozmowy agentow wykonowczych- LangChain        
def save_langgraph_execution_log(log_content: str, file_path: str):
    """Zapisuje pełny, szczegółowy log z wykonania grafu LangGraph do pliku."""
    print(f"INFO: Próba zapisu pełnego logu wykonania LangGraph do pliku: {file_path}")
    try:
        # Upewniamy się, że katalog 'reports' istnieje
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("="*40 + "\n")
            f.write("### PEŁNY ZAPIS WYKONANIA GRAFU LANGGRAPH (FAZA WYKONANIA) ###\n")
            f.write("="*40 + "\n\n")
            f.write(log_content)
            
        print(f"✅ SUKCES: Log wykonania LangGraph został pomyślnie zapisany.")
    except Exception as e:
        print(f"❌ BŁĄD: Nie udało się zapisać logu LangGraph. Przyczyna: {e}")  


def get_active_policies_from_memory(memory_client, dataset_signature: str) -> Optional[str]:
    """Odpytuje pamięć o META_INSIGHTS i tworzy z nich tekst polityk."""
    print("--- DORADCA POLITYKI SYSTEMOWEJ: Sprawdzanie pamięci... ---")
    
    meta_insights = memory_client.query_memory(
        query_text="Najważniejsze rekomendacje dotyczące ulepszenia promptów lub logiki systemu",
        scope={"dataset_signature": dataset_signature},
        top_k=3
    )
    
    active_policies = []
    if meta_insights:
        for mem in meta_insights:
            if mem.memory_type == MemoryType.META_INSIGHT and 'recommendation' in mem.content:
                active_policies.append(f"- {mem.content['recommendation']}")
    
    if active_policies:
        policy_text = "--- AKTYWNE POLITYKI SYSTEMOWE (NAJWYŻSZY PRIORYTET) ---\n" + "\n".join(active_policies)
        print(f"  [INFO] Aktywowano polityki:\n{policy_text}")
        return policy_text
    
    print("  [INFO] Brak aktywnych polityk systemowych.")
    return None

        
TOOL_REGISTRY = {
    "embed_plot_to_html": embed_plot_to_html
}


--- FILE: agents/__init__.py ---




--- FILE: agents/autogen_agent_utils.py ---

import pandas as pd
import re
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
from .autogen_agents import TriggerAgent,PlannerAgent,CriticAgent
import autogen
from autogen import Agent, ConversableAgent
from autogen.agentchat.contrib.multimodal_conversable_agent import MultimodalConversableAgent





#FUNKCJA CHATU GRUPOWEGO-WYMYŚLANIE PLANU
def run_autogen_planning_phase(input_path: str,trigger_agent: TriggerAgent,planner_agent: PlannerAgent, critic_agent: CriticAgent, manager_agent_config:Dict,inspiration_prompt: str = "",active_policies: Optional[str] = None) -> Optional[str]:
    """
    Uruchamia fazę planowania z agentami AutoGen i zwraca finalny plan.
    """
    print("\n" + "="*80)
    print("### ### FAZA 1: URUCHAMIANIE PLANOWANIA STRATEGICZNEGO (AutoGen) ### ###")
    print("="*80 + "\n")

    try:
        df_summary = pd.read_csv(input_path, nrows=5)
        data_preview = f"Oto podgląd danych:\n\nKolumny:\n{df_summary.columns.tolist()}\n\nPierwsze 5 wierszy:\n{df_summary.to_string()}"
        
        
        if active_policies:
            print("INFO: Dołączam aktywne polityki systemowe do fazy planowania.")
            data_preview += "\n\n" + active_policies
        
        
        if inspiration_prompt:
            print("INFO: Dołączam inspiracje z pamięci do fazy planowania.")
            data_preview += "\n\n" + inspiration_prompt
        
    except Exception as e:
        logging.error(f"Nie można wczytać pliku wejściowego {input_path}: {e}")
        return None, ""
    
    
    
    user_proxy = autogen.UserProxyAgent(
       name="UserProxy",
       human_input_mode="NEVER",
       max_consecutive_auto_reply=10,
       is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINATE"),
       code_execution_config=False,
       system_message="Zarządzasz procesem. Przekaż podgląd danych do TriggerAgenta. Następnie moderuj dyskusję między Plannerem a Krytykiem. Jeśli w wiadomości znajdują się 'AKTYWNE POLITYKI SYSTEMOWE' lub 'INSPIRACJE Z POPRZEDNICH URUCHOMIEŃ', upewnij się, że przekażesz je w całości Plannerowi."
    )

    def custom_speaker_selection_func(last_speaker: Agent, groupchat: autogen.GroupChat):
        messages = groupchat.messages

        # Warunek początkowy, pierwszy mówi TriggerAgent
        if len(messages) <= 1:
            return trigger_agent

        # Standardowy przepływ: Trigger -> Planner -> Critic -> Planner ...
        elif last_speaker is trigger_agent:
            return planner_agent
        elif last_speaker is planner_agent:
            return critic_agent
        elif last_speaker is critic_agent:

            if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in messages[-1]['content']:
                return None # To elegancko kończy rozmowę
            else:
                # Jeśli nie, wracamy do Plannera z uwagami
                return planner_agent
        else:
            # Sytuacja awaryjna lub koniec, nie wybieraj nikogo
            return None

    groupchat = autogen.GroupChat(
        agents=[user_proxy, trigger_agent, planner_agent, critic_agent],
        messages=[],
        max_round=15,
        speaker_selection_method=custom_speaker_selection_func
    )
    manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=manager_agent_config)

    user_proxy.initiate_chat(manager, message=data_preview)

    # Ekstrakcja finalnego planu
    final_plan = None
    critic_messages = [msg['content'] for msg in groupchat.messages if msg['name'] == 'CriticAgent']
    for msg in reversed(critic_messages):
        if "PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI" in msg:
            match = re.search(r"OSTATECZNY PLAN:(.*)PLAN_AKCEPTOWANY_PRZEJSCIE_DO_IMPLEMENTACJI", msg, re.DOTALL)
            if match:
                final_plan = match.group(1).strip()
                print("Faza planowania zakończona. Ostateczny plan został zaakceptowany.")
                break
    
    if not final_plan:
        print(" Faza planowania zakończona bez akceptacji planu lub z powodu TERMINATE.")

    
    full_conversation_log = "\n\n".join([f"--- Komunikat od: {msg['name']} ---\n{msg['content']}" for msg in groupchat.messages])

    
    return final_plan, full_conversation_log



--- FILE: agents/autogen_agents.py ---

import autogen
from autogen import Agent, ConversableAgent


class TriggerAgent(ConversableAgent):
    """Agent decydujący, czy dane nadają się do dalszego przetwarzania."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="TriggerAgent",
            llm_config=llm_config,
            system_message=prompt
        )

#PLANNER AGENT        
class PlannerAgent(ConversableAgent):
    """Agent tworzący szczegółowy plan przygotowania danych."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="PlannerAgent",
            llm_config=llm_config,
            system_message=prompt
        )

#CRITIC AGENT
class CriticAgent(ConversableAgent):
    """Agent oceniający plan i dbający o jego jakość."""
    def __init__(self, llm_config, prompt):
        super().__init__(
            name="CriticAgent",
            llm_config=llm_config,
            system_message=prompt
        )
        
        
        



--- FILE: agents/langgraph_nodes.py ---

import os
import io
import sys
import subprocess
import tempfile
import traceback
import uuid
import json
import re
import matplotlib.pyplot as plt
from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import pandas as pd
import langchain
from langchain_google_vertexai import ChatVertexAI
from langchain_anthropic import ChatAnthropic
from .state import AgentWorkflowState
from prompts import LangchainAgentsPrompts
from tools.utils import *
from tools.langchain_tools import *
from prompts import ArchitecturalRule, ArchitecturalRulesManager,ARCHITECTURAL_RULES
from prompts_beta import PromptFactory
from config import MAX_CORRECTION_ATTEMPTS, PROJECT_ID,LOCATION
from memory.memory_utils import *
from memory.memory_models import *
# --- Definicje węzłów LangGraph ---

def schema_reader_node(state: AgentWorkflowState):
    print("--- WĘZEŁ: ANALIZATOR SCHEMATU DANYCH ---")
    print(f"DEBUG: Próbuję odczytać plik ze ścieżki: {state.get('input_path')}")
    try:
        df_header = pd.read_csv(state['input_path'], nrows=0)
        
        #pamięć długotrwała, tworzenie sygnatury
        memory_client = state['memory_client']
        dataset_signature = memory_client.create_dataset_signature(df_header)
        print(f"INFO: Wygenerowano sygnaturę danych: {dataset_signature}")
        #--koniec--
        
        return {"available_columns": df_header.columns.tolist(),"dataset_signature": dataset_signature}
    except Exception as e:
        return {"error_message": f"Błąd odczytu pliku: {e}", "failing_node": "schema_reader"}

def code_generator_node(state: AgentWorkflowState):
    """Generuje główny skrypt przetwarzający dane z użyciem structured output."""
    print("---  WĘZEŁ: GENERATOR KODU ---")
    try:
        CODE_MODEL = state['config']['CODE_MODEL']
        
        # ZMIANA: Znacząco zwiększamy max_tokens, aby model miał miejsce na wygenerowanie pełnego kodu.
        llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=4096)
        
        # Powiązanie LLM ze schematem Pydantic, aby wymusić poprawny format wyjściowy.
        structured_llm = llm.with_structured_output(GeneratedCode)
        
        prompt = PromptFactory.for_code_generator(
            plan=state['plan'], 
            available_columns=state['available_columns']
        )
        
        # Wywołanie zwraca obiekt Pydantic, a nie surowy string.
        response_object = structured_llm.invoke(prompt)
        
        # Używamy poprawnej i ujednoliconej nazwy pola: 'code'.
        code = response_object.code
        
        print("\nAgent-Analityk wygenerował następujący kod:")
        print("--------------------------------------------------")
        print(code)
        print("--------------------------------------------------")
        
        return {"generated_code": code}

    except Exception as e:
        # Dodajemy obsługę błędu, aby dać więcej kontekstu, jeśli coś pójdzie nie tak.
        print(f"BŁĄD KRYTYCZNY w code_generator_node podczas wywołania LLM: {e}")
        # Zwracamy błąd do stanu, aby graf mógł na niego zareagować.
        return {
            "error_message": f"Błąd podczas generowania kodu: {e}", 
            "failing_node": "code_generator",
            "error_context_code": state.get('plan', 'Brak planu w stanie do analizy.')
        }




def architectural_validator_node(state: AgentWorkflowState):
    print("--- 🛡️ WĘZEŁ: STRAŻNIK ARCHITEKTURY 🛡️ ---")
    code_to_check = state.get('generated_code', '')
    if not code_to_check:
        error_message = "Brak kodu do walidacji."
        print(f"  [WERDYKT] ❌ {error_message}")
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": "", "correction_attempts": state.get('correction_attempts', 0) + 1}

    errors = [rule["error_message"] for rule in ARCHITECTURAL_RULES if rule["check"](code_to_check)]
    
    if errors:
        error_message = "Błąd Walidacji Architektonicznej: " + " ".join(errors)
        # <<< WAŻNY PRINT >>>
        print(f"  [WERDYKT] ❌ Kod łamie zasady architektury: {' '.join(errors)}")
        
        pending_session = {
            "initial_error": error_message,  # Używamy błędu walidacji jako błędu początkowego
            "initial_code": code_to_check,
            "fix_attempts": []
        }
        
        return {"error_message": error_message, "failing_node": "architectural_validator", "error_context_code": code_to_check, "correction_attempts": state.get('correction_attempts', 0) + 1}
    else:
        # <<< WAŻNY PRINT >>>
        print("  [WERDYKT] Kod jest zgodny z architekturą systemu.")
        return {"error_message": None, "pending_fix_session": None}

    
def data_code_executor_node(state: AgentWorkflowState):
    """
    Wykonuje finalny kod do przetwarzania danych.
    """
    print("--- WĘZEŁ: WYKONANIE KODU DANYCH  ---")
    try:
        print("  [INFO] Uruchamiam ostatecznie zatwierdzony kod...")
        
        # Definiujemy środowisko wykonawcze tylko z niezbędnymi bibliotekami
        exec_scope = {
            'pd': pd,
            'input_path': state['input_path'],
            'output_path': state['output_path']
        }
        
        exec(state['generated_code'], exec_scope)
        
        print("  [WYNIK] Kod wykonany pomyślnie.")
        return {"error_message": None, "correction_attempts": 0}
        
    except Exception as e:
        error_traceback = traceback.format_exc()
        print(f"  [BŁĄD] Wystąpił błąd. Przekazywanie do inteligentnego debuggera:\n{error_traceback}")
        
        #--pamięć długotrwała: zapis błędu, sesja tymczasowa
        
        pending_session = {
            "initial_error": error_traceback,
            "initial_code": state['generated_code'],
            "fix_attempts": []  # Pusta lista na przyszłe próby naprawy
        }
        #--koniec--
        
        return {
            "failing_node": "data_code_executor", 
            "error_message": error_traceback, 
            "error_context_code": state['generated_code'], 
            "correction_attempts": state.get('correction_attempts', 0) + 1,
            "pending_fix_session": pending_session
        }

    
def universal_debugger_node(state: AgentWorkflowState):
    print(f"--- WĘZEŁ: INTELIGENTNY DEBUGGER (Błąd w: {state.get('failing_node')}) ---")
    failing_node_name = state.get('failing_node', 'unknown')
    
    
    
    MAIN_AGENT=state['config']['MAIN_AGENT']
    # llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
    llm = ChatVertexAI(model_name=MAIN_AGENT,temperature=0.0, project=PROJECT_ID, location=LOCATION)
    tools = [propose_code_fix, request_package_installation, inspect_tool_code]
    llm_with_tools = llm.bind_tools(tools)
    
    prompt = PromptFactory.for_universal_debugger(
    failing_node=failing_node_name,
    error_message=state['error_message'],
    code_context=state['error_context_code'],
    active_policies=state.get("active_policies")
    )
    
    error_context = f"Wadliwy Kontekst:\n```\n{state['error_context_code']}\n```\n\nBłąd:\n```\n{state['error_message']}\n```"
    response = llm_with_tools.invoke(prompt + error_context)
    if not response.tool_calls:
        print("  [BŁĄD DEBUGGERA] Agent nie wybrał żadnego narzędzia. Eskalacja.")
        return {"error_message": "Debugger nie był w stanie podjąć decyzji.", "failing_node": "universal_debugger"}
    chosen_tool = response.tool_calls[0]
    tool_name = chosen_tool['name']
    tool_args = chosen_tool['args']
    print(f"  [DIAGNOZA] Debugger wybrał narzędzie: '{tool_name}' z argumentami: {tool_args}")
    return {"tool_choice": tool_name, "tool_args": tool_args, "debugger_analysis": tool_args.get("analysis", "")}


def apply_code_fix_node(state: AgentWorkflowState):
    """Aplikuje poprawkę kodu zaproponowaną przez debuggera."""
    print("--- WĘZEŁ: APLIKOWANIE POPRAWKI KODU ---")
    
    CODE_MODEL=state['config']['CODE_MODEL']
    
    analysis = state.get("debugger_analysis", "")
    corrected_code = state.get("tool_args", {}).get("corrected_code")
    failing_node = state.get("failing_node")
    
    
    if not corrected_code:
        print("  [OSTRZEŻENIE] Debugger nie dostarczył kodu. Wymuszam jego wygenerowanie...")
        
        # Tworzymy bardzo prosty prompt, który ma tylko jedno zadanie
        force_prompt = f"""Na podstawie poniższej analizy i wadliwego kodu, wygeneruj PEŁNY, POPRAWIONY i gotowy do uruchomienia skrypt Pythona.
        Twoja odpowiedź musi zawierać TYLKO i WYŁĄCZNIE blok kodu, bez żadnych dodatkowych wyjaśnień.

        [ANALIZA BŁĘDU]:
        {analysis}

        [WADLIWY KOD]:
        ```python
        {state['error_context_code']}"""
        
        
        try:
            llm = ChatAnthropic(model_name=CODE_MODEL, temperature=0.0, max_tokens=2048)
            response = llm.invoke(force_prompt).content
            corrected_code = extract_python_code(response) # Używamy istniejącej funkcji pomocniczej
            print("  [INFO] Pomyślnie wymuszono wygenerowanie kodu.")
        except Exception as e:
            print(f"  [BŁĄD KRYTYCZNY] Nie udało się wymusić generacji kodu: {e}")
            return {"error_message": "Nie udało się naprawić kodu nawet po eskalacji."}
        
        
    #--pamięć długotrwała info dla pamieci--
    
    update = {
        "error_message": None, 
        "tool_choice": None, 
        "tool_args": None
    }

    if failing_node == "plot_generator_node":
        print("  [INFO] Aplikowanie poprawki do kodu generującego wykresy.")
        update["plot_generation_code"] = corrected_code
    elif failing_node == "summary_analyst_node":
        print("  [INFO] Aplikowanie poprawki do podsumowania HTML.")
        update["summary_html"] = corrected_code
    else: # Domyślnie traktuj jako główny kod
        print("  [INFO] Aplikowanie poprawki do głównego kodu przetwarzania danych.")
        update["generated_code"] = corrected_code

    session = state.get('pending_fix_session')
    if not session:
        # Sytuacja awaryjna, nie powinno się zdarzyć w normalnym przepływie
        print("  [OSTRZEŻENIE] Próba aplikacji poprawki bez aktywnej sesji naprawczej.")
        session = {}

    # Dodajemy informacje o tej konkretnej próbie do listy w sesji
    attempt_info = {
        "debugger_analysis": state.get("debugger_analysis", "Brak analizy."),
        "corrected_code": corrected_code,
        "attempt_number": len(session.get("fix_attempts", [])) + 1
    }
    
    if "fix_attempts" in session:
        session["fix_attempts"].append(attempt_info)
    else:
        session["fix_attempts"] = [attempt_info]
    
    print(f"  [INFO] Dodano próbę naprawy nr {attempt_info['attempt_number']} do sesji.")
    
    
    #--koniec--
    
    return {
        "generated_code": corrected_code, 
        "error_message": None, 
        "tool_choice": None, 
        "tool_args": None,
        "pending_fix_session": session  # Aktualizujemy sesję w stanie
    }


def human_approval_node(state: AgentWorkflowState):
    print("\n" + "="*80 + "\n### WYMAGANA AKCJA CZŁOWIEKA  ###\n" + "="*80)
    package_name = state.get("tool_args", {}).get("package_name")
    user_input = input(f"Agent chce zainstalować pakiet '{package_name}'. Czy zgadzasz się? [y/n]: ").lower().strip()
    if user_input == 'y':
        print("Zgoda. Przechodzenie do instalacji.")
        return {"user_approval_status": "APPROVED", "package_to_install": package_name}
    else:
        print("Odrzucono. Przekazywanie do debuggera w celu znalezienia alternatywy.")
        new_error_message = f"Instalacja pakietu '{package_name}' została odrzucona przez użytkownika. Zmodyfikuj kod, aby nie używał tej zależności."
        return {"user_approval_status": "REJECTED", "error_message": new_error_message}


def package_installer_node(state: AgentWorkflowState):
    """Instaluje lub aktualizuje pakiet po uzyskaniu zgody."""
    package_name = state.get("package_to_install")
    
    # Domyślnie próbujemy aktualizacji, bo to rozwiązuje problemy z zależnościami
    success = install_package(package_name, upgrade=True)
    
    if success:
        return {"package_to_install": None, "user_approval_status": None, "error_message": None}
    else:
        return {"error_message": f"Operacja na pakiecie '{package_name}' nie powiodła się.", "failing_node": "package_installer"}


    
def summary_analyst_node(state: AgentWorkflowState) -> Dict[str, str]:
    """
    Agent, którego jedynym zadaniem jest analiza i stworzenie podsumowania tekstowego w HTML.
    """
    print("--- WĘZEŁ: ANALITYK PODSUMOWANIA ---")
    try:
        # Krok 1: Przygotuj dane wejściowe dla promptu
        df_original = pd.read_csv(state['input_path'])
        df_processed = pd.read_csv(state['output_path'])

        original_info_buf = io.StringIO()
        df_original.info(buf=original_info_buf)
        processed_info_buf = io.StringIO()
        df_processed.info(buf=processed_info_buf)

        original_summary = f"Podsumowanie danych ORYGINALNYCH:\n{df_original.describe().to_string()}\n{original_info_buf.getvalue()}"
        processed_summary = f"Podsumowanie danych PRZETWORZONYCH:\n{df_processed.describe().to_string()}\n{processed_info_buf.getvalue()}"

        # === POPRAWKA: Użycie dedykowanego promptu ===
        prompt = PromptFactory.for_summary_analyst(
        plan=state['plan'],
        original_summary=original_summary,
        processed_summary=processed_summary
        )
        
        llm = ChatAnthropic(model_name=state['config']['CODE_MODEL'], temperature=0.0, max_tokens=1024)
        structured_llm = llm.with_structured_output(ReportSummary)
        response = structured_llm.invoke(prompt)
        
        print("  [INFO] Analityk wygenerował podsumowanie HTML.")
        return {"summary_html": response.summary_html}
        
    except Exception as e:
        error_msg = f"Błąd w analityku podsumowania: {traceback.format_exc()}"
        print(f"  [BŁĄD] {error_msg}")
        return {
            "error_message": error_msg,
            "failing_node": "summary_analyst_node",
            "error_context_code": state.get('plan', 'Brak planu w stanie do analizy.'),
            "correction_attempts": state.get("correction_attempts", 0) + 1  # <-- DODAJ TĘ LINIĘ
        }


def plot_generator_node(state: AgentWorkflowState) -> Dict[str, str]:
    """
    Agent, którego jedynym zadaniem jest wygenerowanie KODU do tworzenia wykresów.
    """
    print("--- WĘZEŁ: GENERATOR WIZUALIZACJI ---")
    try:
        # --- NOWY KROK: POBIERZ AKTUALNE KOLUMNY Z PRZETWORZONEGO PLIKU ---
        df_processed_cols = pd.read_csv(state['output_path'], nrows=0).columns.tolist()

        # Przekaż aktualne kolumny do promptu, aby agent wiedział, na czym pracuje
        prompt = PromptFactory.for_plot_generator(
        plan=state['plan'],
        available_columns=df_processed_cols
        )
        
        MAIN_AGENT = state['config']['MAIN_AGENT']
        llm = ChatVertexAI(model_name=MAIN_AGENT, temperature=0.0, project=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(PlottingCode)
        
        response = structured_llm.invoke(prompt)
        cleaned_code = extract_python_code(response.code)
        
        print("  [INFO] Generator stworzył kod do wizualizacji.")
        return {"plot_generation_code": cleaned_code}
        

    except Exception as e:
        error_msg = f"Błąd w generatorze wizualizacji: {traceback.format_exc()}"
        print(f"  [BŁĄD] {error_msg}")
        return {
            "error_message": error_msg,
            "failing_node": "plot_generator_node",
            "error_context_code": state.get('plan', 'Brak planu w stanie do analizy.'),
            "correction_attempts": state.get("correction_attempts", 0) + 1
        }


def report_composer_node(state: AgentWorkflowState) -> Dict[str, Any]:
    """
    Węzeł, który składa podsumowanie i wykresy w finalny raport HTML. Nie używa LLM.
    """
    print("--- WĘZEŁ: KOMPOZYTOR RAPORTU ---")
    try:
        summary_html = state.get("summary_html")
        plot_code = state.get("plot_generation_code")
        
        if not summary_html or not plot_code:
            raise ValueError("Brak podsumowania lub kodu do generowania wykresów w stanie.")

        # 1. Przygotuj środowisko wykonawcze dla kodu z wykresami
        exec_scope = {
            'pd': pd,
            'plt': plt,
            'df_original': pd.read_csv(state['input_path']),
            'df_processed': pd.read_csv(state['output_path']),
            'figures_to_embed': []
        }

        # 2. Wykonaj kod od agenta, aby wygenerować obiekty figur
        exec(plot_code, exec_scope)
        figures = exec_scope['figures_to_embed']
        print(f"  [INFO] Wykonano kod i wygenerowano {len(figures)} wykres(y).")

        # 3. Skonwertuj figury na tagi <img> z base64
        figures_html = ""
        for i, fig in enumerate(figures):
            figures_html += f"<h3>Wykres {i+1}</h3>{embed_plot_to_html(fig)}"

        # 4. Złóż finalny raport HTML
        final_html = f"""
        <!DOCTYPE html>
        <html lang="pl">
        <head>
            <meta charset="UTF-8">
            <title>Raport z Analizy Danych</title>
            <style>
                body {{ font-family: sans-serif; margin: 2em; background-color: #f9f9f9; }}
                .container {{ max-width: 1000px; margin: auto; background: #fff; padding: 2em; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                h1, h2, h3 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 5px;}}
                img {{ max-width: 100%; height: auto; border: 1px solid #ddd; padding: 4px; border-radius: 4px; margin-top: 1em; }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>Raport z Przetwarzania Danych</h1>
                {summary_html}
                <h2>Wizualizacje</h2>
                {figures_html}
            </div>
        </body>
        </html>
        """

        # 5. Zapisz plik
        with open(state['report_output_path'], 'w', encoding='utf-8') as f:
            f.write(final_html)
            
        print(f"✅ Raport został pomyślnie wygenerowany w {state['report_output_path']}")
        return {}

    except Exception as e:
        error_msg = f"Błąd w kompozytorze raportu: {traceback.format_exc()}"
        print(f"  [BŁĄD] {error_msg}")
        return {
            "error_message": error_msg, 
            "failing_node": "report_composer_node",
            "error_context_code": state.get("plot_generation_code", "Brak kodu do analizy."),
            "correction_attempts": state.get("correction_attempts", 0) + 1
        }
    
    
    
    

    
def sync_report_code_node(state: AgentWorkflowState):
    """Synchronizuje naprawiony kod z powrotem do stanu agenta raportującego."""
    print("--- WĘZEŁ: SYNCHRONIZACJA KODU RAPORTU ---")
    corrected_code = state.get("generated_code")
    return {"generated_report_code": corrected_code}   
    
    
def meta_auditor_node(state: AgentWorkflowState):
    """Uruchamia audytora ORAZ zapisuje wspomnienia o sukcesie i wnioski META."""
    print("\n" + "="*80 + "\n### ### FAZA 3: META-AUDYT I KONSOLIDACJA WIEDZY ### ###\n" + "="*80 + "\n")
    
    try:
        
        CRITIC_MODEL=state['config']['CRITIC_MODEL']
        
        escalation_report_content = None
        escalation_path = state.get("escalation_report_path")
        if escalation_path:
            print(f"  [INFO] Wykryto raport z eskalacji. Wczytywanie pliku: {escalation_path}")
            try:
                with open(escalation_path, 'r', encoding='utf-8') as f:
                    escalation_report_content = f.read()
            except Exception as e:
                print(f"  [OSTRZEŻENIE] Nie udało się wczytać pliku z eskalacją: {e}")
        
        
        
        # ... (cała logika generowania raportu audytora, tak jak w oryginale)
        # Załóżmy, że wynikiem jest zmienna 'audit_report'
        final_report_content = "Brak raportu do analizy."
        try:
            with open(state['report_output_path'], 'r', encoding='utf-8') as f:
                final_report_content = f.read()
        except Exception: pass
        
        llm = ChatAnthropic(model_name=CRITIC_MODEL, temperature=0.0, max_tokens=2048)
        structured_llm = llm.with_structured_output(AuditReport)
        
        prompt = PromptFactory.for_meta_auditor(
        source_code=intelligent_truncate(state['source_code'], 8000),
        autogen_log=intelligent_truncate(state['autogen_log'], 6000),
        langgraph_log=intelligent_truncate(state.get('langgraph_log', ''), 6000),
        final_code=state.get('generated_code', 'Brak kodu'),
        final_report=final_report_content,
        escalation_report=escalation_report_content
        )
        report_object = structured_llm.invoke(prompt)
        # ... (zapis raportu do pliku)

        audit_report = f"""
1.  **Ocena Planowania:**
    {report_object.planning_evaluation}

2.  **Ocena Wykonania:**
    {report_object.execution_evaluation}

3.  **Ocena Jakości Promptów (Analiza Meta):**
    {report_object.prompt_quality_analysis}

4.  **Rekomendacje do Samodoskonalenia:**
    {report_object.recommendations}
"""
        
        try:
            audit_report_path = "reports/meta_audit_report.txt"
            print(f"  [INFO] Zapisywanie raportu z audytu do: {audit_report_path}")
            with open(audit_report_path, "w", encoding="utf-8") as f:
                f.write("="*50 + "\n")
                f.write("### RAPORT Z META-AUDYTU SYSTEMU AI ###\n")
                f.write("="*50 + "\n\n")
                f.write(audit_report)
            print(f"  [SUKCES] Pomyślnie zapisano raport z audytu.")
        except Exception as e:
            print(f"  [BŁĄD] Nie udało się zapisać raportu z audytu: {e}")
        
        # 3. WYGENERUJ I ZAPISZ WNIOSEK META
        meta_insight_content = generate_meta_insight(audit_report)
        return {"meta_insight_content": meta_insight_content}

    except Exception as e:
        print(f"BŁĄD KRYTYCZNY podczas meta-audytu: {e}")
        return {"meta_insight_content": None}

    
    
def human_escalation_node(state: AgentWorkflowState):
    """Węzeł eskalacji (bez zmian)."""
    print("\n==================================================")
    print(f"--- WĘZEŁ: ESKALACJA DO CZŁOWIEKA---")
    print("==================================================")
    # ... (reszta kodu bez zmian)
    report_content = f"""
Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Problem: Przekroczono maksymalny limit ({MAX_CORRECTION_ATTEMPTS}) prób automatycznej naprawy.

Ostatnia analiza debuggera:
{state.get('debugger_analysis', 'Brak analizy.')}

Ostatni kod, który zawiódł:
```python
{state.get('error_context_code', 'Brak kodu.')}
```

Pełny traceback ostatniego błędu:
{state.get('error_message', 'Brak błędu.')}
"""
    file_name = f"reports/human_escalation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(file_name, "w", encoding="utf-8") as f: f.write(report_content)
    print(f"  [INFO] Raport dla człowieka został zapisany w pliku: {file_name}")
    return {"escalation_report_path": file_name}




def memory_consolidation_node(state: AgentWorkflowState):
    """
    Finalny węzeł grafu, odpowiedzialny za analizę całego przebiegu
    i zapisanie odpowiedniego rodzaju wspomnienia do pamięci długotrwałej.
    """
    print("\n" + "="*80 + "\n### ### FAZA 4: KONSOLIDACJA WIEDZY W PAMIĘCI ### ###\n" + "="*80 + "\n")
    memory_client = state['memory_client']
    run_id = state['run_id']
    dataset_signature = state['dataset_signature']
    
    # Scenariusz 1: Nastąpiła udana naprawa błędu w trakcie procesu.
    fix_session = state.get('pending_fix_session')
    if fix_session and fix_session.get("fix_attempts"):
        print("  [PAMIĘĆ] Wykryto udaną sesję naprawczą. Zapisuję wspomnienie typu SUCCESSFUL_FIX.")
        distilled_content = distill_fix_memory(
            initial_error=fix_session['initial_error'],
            fix_attempts=fix_session['fix_attempts'],
            successful_code=state['generated_code'] # lub inny odpowiedni kod
        )
        record = MemoryRecord(
            run_id=run_id,
            memory_type=MemoryType.SUCCESSFUL_FIX,
            dataset_signature=dataset_signature,
            source_node="memory_consolidation_node",
            content=distilled_content,
            metadata={"total_attempts": len(fix_session['fix_attempts'])}
        )
        memory_client.add_memory(record)

    # Scenariusz 2: Proces zakończył się pełnym sukcesem bez żadnych błędów.
    elif not state.get("escalation_report_path"):
        print("  [PAMIĘĆ] Wykryto pomyślny przebieg bez błędów. Zapisuję wspomnienie typu SUCCESSFUL_WORKFLOW.")
        distilled_content = distill_successful_workflow(
            plan=state.get('plan', ''),
            final_code=state.get('generated_code', ''),
            langgraph_log=state.get('langgraph_log', '')
        )
        record = MemoryRecord(
            run_id=run_id,
            memory_type=MemoryType.SUCCESSFUL_WORKFLOW,
            dataset_signature=dataset_signature,
            source_node="memory_consolidation_node",
            content=distilled_content,
            metadata={"importance_score": 0.9}
        )
        memory_client.add_memory(record)

    # Scenariusz 3: Nastąpiła eskalacja do człowieka lub inny nieprzewidziany błąd.
    else:
        print("  [PAMIĘĆ] Wykryto eskalację lub nieudany przebieg. Nie zapisuję wspomnienia o sukcesie.")
        # W przyszłości można tu dodać logikę zapisu wspomnienia o porażce.

    # Na samym końcu zapisujemy wniosek z audytu, jeśli istnieje
    meta_insight_content = state.get("meta_insight_content") # Zakładamy, że audytor umieścił to w stanie
    if meta_insight_content:
        print("  [PAMIĘĆ] Zapisuję wniosek META z audytu.")
        insight_record = MemoryRecord(
            run_id=run_id, memory_type=MemoryType.META_INSIGHT,
            dataset_signature=dataset_signature, source_node="meta_auditor_node",
            content=meta_insight_content, metadata={"importance_score": 1.0}
        )
        memory_client.add_memory(insight_record)
        
    return {}



--- FILE: agents/state.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
from memory.memory_bank_client import MemoryBankClient

#Zmienne przekazywane do grafu LangChian
class AgentWorkflowState(TypedDict):
    config: Dict[str, Any]
    plan: str; input_path: str; output_path: str; report_output_path: str
    available_columns: List[str]; generated_code: str; generated_report_code: str
    correction_attempts: int; error_message: Optional[str]; failing_node: Optional[str]
    error_context_code: Optional[str]; debugger_analysis: Optional[str]
    package_to_install: Optional[str]; user_approval_status: Optional[str]
    tool_choice: Optional[str]; tool_args: Optional[Dict]
    source_code: str
    autogen_log: str
    langgraph_log: str
    # --- Pola pamięci ---
    run_id: str
    dataset_signature: str
    error_record_id: Optional[str]
    memory_client: MemoryBankClient
    pending_fix_session: Optional[Dict[str, Any]]
    generated_code: str # Dla głównego kodu
    summary_html: str # Wynik z summary_analyst
    plot_generation_code: str # Wynik z plot_generator
    escalation_report_path: Optional[str]


--- FILE: prolog/main_app.ipynb ---

import sys
!{sys.executable} -m pip install pyswip
# --- Koniec komórki ---
import json
from pyswip import Prolog
from langchain_google_vertexai import ChatVertexAI
from rule_compiler import compile_rules
# --- Koniec komórki ---
# --- Konfiguracja ---
LOCATION="us-central1"
PROJECT_ID="dark-data-discovery"
MODEL_NAME = "gemini-2.5-pro"

# --- Koniec komórki ---
def get_llm_response(prompt: str) -> str:
    """Wywołuje LLM, aby uzyskać odpowiedź."""
    print("\n--- Agent Neuronowy (LLM) tworzy odpowiedź... ---")
    llm = ChatVertexAI(model_name=MODEL_NAME, project=PROJECT_ID, location=LOCATION, temperature=0.5)
    response = llm.invoke(prompt)
    print(f"  [ODPOWIEDŹ AGENTA]:\n---\n{response.content}\n---")
    return response.content
# --- Koniec komórki ---
def validate_response_with_prolog(response_text: str, rules_path: str) -> list:
    """Używa Prologu do walidacji odpowiedzi na podstawie reguł."""
    print("\n--- Strażnik Symboliczny (Prolog) rozpoczyna walidację... ---")
    violations = []
    try:
        prolog = Prolog()
        prolog.consult(rules_path)
        
        # Użyj json.dumps, aby bezpiecznie przekazać string do Prologu
        safe_content = json.dumps(response_text)
        
        query = f"policy_violation({safe_content}, ViolationMessage)"
        results = list(prolog.query(query))
        
        if results:
            for result in results:
                violations.append(result["ViolationMessage"])
    except Exception as e:
        violations.append(f"Błąd krytyczny silnika Prolog: {e}")
        
    return violations
# --- Koniec komórki ---
def main():
    # 1. Skompiluj najnowsze reguły z JSON do Prologu
    compile_rules()

    # 2. Agent generuje odpowiedź ZGODNĄ z regułami
    prompt_compliant = "Napisz krótkiego e-maila do klienta, w którym przeprosisz za opóźnienie paczki i zaoferujesz kupon rabatowy na następne zakupy. Nie podawaj konkretnej daty dostawy."
    compliant_response = get_llm_response(prompt_compliant)
    
    # 3. Agent generuje odpowiedź ŁAMIĄCĄ reguły
    prompt_violating = "Napisz krótkiego e-maila do klienta i obiecaj mu, że paczka na pewno będzie jutro. Nie przepraszaj i nie oferuj żadnych zniżek."
    violating_response = get_llm_response(prompt_violating)

    # 4. Uruchom walidację dla obu odpowiedzi
    compliant_violations = validate_response_with_prolog(compliant_response, "customer_policies.pl")
    if not compliant_violations:
        print("  [WERDYKT] ✅ Odpowiedź ZGODNA z polityką firmy.")
    else:
        print(f"  [WERDYKT] ❌ Odpowiedź NIEZGODNA. Naruszone reguły: {compliant_violations}")

    violating_violations = validate_response_with_prolog(violating_response, "customer_policies.pl")
    if not violating_violations:
        print("  [WERDYKT] ✅ Odpowiedź ZGODNA z polityką firmy.")
    else:
        print(f"  [WERDYKT] ❌ Odpowiedź NIEZGODNA. Naruszone reguły: {violating_violations}")
# --- Koniec komórki ---
if __name__ == "__main__":
    main()
# --- Koniec komórki ---



--- FILE: prolog/rule_compiler.py ---

import json

def compile_rules():
    print("--- 1. Wczytywanie reguł z `customer_service_rules.json` ---")
    with open("rules.json", 'r', encoding='utf-8') as f:
        rules_data = json.load(f)

    prolog_code = ""
    for rule in rules_data.get("rules", []):
        prolog_code += (
            f"policy_violation(Content, '{rule['error_message']}') :- "
            f"{rule['prolog_condition']}.\n"
        )
    
    print("--- 2. Kompilowanie reguł do `customer_policies.pl` ---")
    with open("customer_policies.pl", "w", encoding="utf-8") as f:
        preamble = """
% Plik wygenerowany dynamicznie
:- style_check(-singleton).
contains_substring(String, Substring) :- sub_string(String, _, _, _, Substring).
"""
        f.write(preamble.strip() + "\n\n" + prolog_code.strip())
    print("  [SUKCES] Pomyślnie skompilowano reguły.")

if __name__ == "__main__":
    compile_rules()


--- FILE: memory/__init__.py ---




--- FILE: memory/memory_bank_client.py ---

import json
import hashlib
import pandas as pd
from typing import Dict, List, Optional
import vertexai
from vertexai import agent_engines
from .memory_models import MemoryRecord


class MemoryBankClient:
    def __init__(self, client: vertexai.Client, agent_engine):
        """
        Inicjalizuje klienta z głównym obiektem klienta Vertex AI 
        oraz z gotowym obiektem agent_engine.
        """
        if not client or not agent_engine:
            raise ValueError("Klient Vertex AI oraz Agent Engine muszą być poprawnie zainicjalizowane.")
        
        self.client = client
        self.agent_engine = agent_engine
        self.engine_name = agent_engine.resource_name
        print(f"INFO: MemoryBankClient gotowy do pracy z silnikiem: {self.engine_name}")
        
    
    
    
    def create_dataset_signature(self, df_preview: pd.DataFrame) -> str:
        """Tworzy unikalny identyfikator dla zbioru danych."""
        s = "".join(df_preview.columns) + str(df_preview.shape)
        return hashlib.md5(s.encode()).hexdigest()

    def add_memory(self, record: MemoryRecord):
        """Zapisuje ustrukturyzowane wspomnienie w Agent Engine."""
        try:
            fact_to_remember = record.model_dump_json()
            scope = {"dataset_signature": record.dataset_signature}
            
            
            self.client.agent_engines.create_memory(
                name=self.engine_name,
                fact=fact_to_remember, 
                scope=scope
            )
            print(f"INFO: Zapisano wspomnienie typu '{record.memory_type}' w zakresie {scope}")
        except Exception as e:
            print(f"BŁĄD ZAPISU PAMIĘCI: {e}")

#     def query_memory(self, query_text: str, scope: Dict, top_k: int = 5) -> List[MemoryRecord]:
#         """
#         Odpytuje pamięć semantycznie i zwraca listę ustrukturyzowanych wspomnień.
#         """
#         retrieved_mems = []
#         try:
#             print(f"INFO: Odpytuję pamięć semantycznie z zapytaniem '{query_text}' w zakresie {scope}")

#             # Tworzymy słownik z parametrami wyszukiwania, zgodnie z Twoim znaleziskiem
#             search_params = {
#                 "search_query": query_text,
#                 "top_k": top_k
#             }

#             # Wywołujemy API z poprawnym argumentem: similarity_search_params
#             memories_iterator = self.client.agent_engines.retrieve_memories(
#                 name=self.engine_name,
#                 scope=scope,
#                 similarity_search_params=search_params
#             )

#             for mem in memories_iterator:
#                 print("mem", dir(mem))
#                 record = MemoryRecord.model_validate_json(mem.memory)
#                 retrieved_mems.append(record)

#             print(f"INFO: Znaleziono {len(retrieved_mems)} pasujących wspomnień.")
#             return retrieved_mems

#         except Exception as e:
#             print(f"BŁĄD ODCZYTU PAMIĘCI: {e}")
#             return []
        
        
    def query_memory(self, query_text: str, scope: Dict, top_k: int = 5) -> List[MemoryRecord]:
        """
        Odpytuje pamięć semantycznie, poprawnie odczytując zagnieżdżoną treść wspomnienia.
        """
        retrieved_mems = []
        try:
            print(f"INFO: Odpytuję pamięć semantycznie z zapytaniem '{query_text}' w zakresie {scope}")

            search_params = {
                "search_query": query_text,
                "top_k": top_k
            }

            memories_iterator = self.client.agent_engines.retrieve_memories(
                name=self.engine_name,
                scope=scope,
                similarity_search_params=search_params
            )

            for i, mem in enumerate(memories_iterator):
                try:

                    json_string_to_parse = mem.memory.fact

                    record = MemoryRecord.model_validate_json(json_string_to_parse)
                    retrieved_mems.append(record)
                    print("udany plan:", record)
                except Exception as e:
                    print(f"⚠️ OSTRZEŻENIE: Pominięto uszkodzony lub niekompatybilny rekord pamięci (pozycja {i}). Błąd: {e}")
                    continue

            print(f"INFO: Znaleziono i poprawnie przetworzono {len(retrieved_mems)} pasujących wspomnień.")
            return retrieved_mems

        except Exception as e:
            print(f"KRYTYCZNY BŁĄD ODCZYTU PAMIĘCI: Nie udało się wykonać zapytania. Błąd: {e}")
            return []


--- FILE: memory/memory_models.py ---

from datetime import datetime
from enum import Enum
from typing import Dict, Any, List, Optional
from pydantic import BaseModel, Field
import uuid

class MemoryType(str, Enum):
    SUCCESSFUL_WORKFLOW = "SUCCESSFUL_WORKFLOW"
    EXECUTION_ERROR = "EXECUTION_ERROR"
    SUCCESSFUL_FIX = "SUCCESSFUL_FIX"
    META_INSIGHT = "META_INSIGHT"

    

class MemoryRecord(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    run_id: str # Dodajemy ID bieżącego uruchomienia
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    memory_type: MemoryType
    dataset_signature: str
    source_node: str
    content: Dict[str, Any]
    metadata: Dict[str, Any] = Field(default_factory=dict)

class DistilledMemory(BaseModel):
    """Ustrukturyzowany, 'ekspercki' format dla przedestylowanego wspomnienia."""
    problem_summary: str = Field(description="Opis problemu w jednym, zwięzłym zdaniu.")
    solution_summary: str = Field(description="Opis rozwiązania w jednym, zwięzłym zdaniu.")
    applicability_context: str = Field(description="Opis w jednym zdaniu, w jakim kontekście (np. typ danych, operacja) ta lekcja jest najbardziej użyteczna.")
    key_takeaway: str = Field(description="Uniwersalna 'złota myśl' lub reguła na przyszłość, aby uniknąć podobnych błędów.")
    reusable_code_snippet: Optional[str] = Field(description="Generyczny fragment kodu w Pythonie (do 10 linijek), który implementuje 'key_takeaway'. Jeśli nie ma zastosowania, zwróć null.")
    tags: List[str] = Field(description="Lista 3-5 słów kluczowych (tagów) opisujących ten problem.")
    
    
 #--czysty zapis o sukcesie   
class DistilledSuccessMemory(BaseModel):
    """Ustrukturyzowany format dla wspomnienia o udanym przebiegu."""
    plan_summary: str = Field(description="Podsumowanie celu i kluczowych kroków zrealizowanego planu w jednym zdaniu.")
    key_insight: str = Field(description="Najważniejszy wniosek lub 'trick', który przyczynił się do sukcesu tego planu.")
    full_plan_text: str = Field(description="Pełny, szczegółowy, numerowany tekst udanego planu.")
    tags: List[str] = Field(description="Lista 3-5 słów kluczowych (tagów) opisujących ten plan.")
    
class MetaInsightMemory(BaseModel):
    """Ustrukturyzowany format dla WNIOSKU NA POZIOMIE SYSTEMU."""
    observation: str = Field(description="Zwięzłe opisanie zaobserwowanego zjawiska, np. 'Agent generujący raporty często popełniał błędy w wizualizacji danych szeregów czasowych'.")
    recommendation: str = Field(description="Konkretna, pojedyncza propozycja zmiany w prompcie lub logice systemu, np. 'Do promptu agenta raportującego należy dodać konkretny przykład użycia      `plt.xticks(rotation=45)`'.")
    target_agent_or_node: str = Field(description="Nazwa agenta lub węzła, którego dotyczy rekomendacja, np. 'reporting_agent_node'.")
    tags: List[str] = Field(description="Lista 3-5 słów kluczowych, np. ['prompt-engineering', 'reporting', 'visualization'].")
    
    
    


--- FILE: memory/memory_utils.py ---

from typing import TypedDict, List, Callable, Dict, Optional, Union, Any
import vertexai
import langchain
from langchain_google_vertexai import ChatVertexAI
from langchain_anthropic import ChatAnthropic
from tools.utils import intelligent_truncate
from config import MAIN_AGENT,LOCATION,PROJECT_ID,CRITIC_MODEL
from .memory_models import *

#--narzedzie do przetwarzania info dla pamieci dlugotrwalej, llm agent uzywa llm!!
def distill_memory_content(failing_code: str, error_traceback: str, debugger_analysis: str, corrected_code: str) -> dict:
    """Używa LLM do 'przedestylowania' surowych danych o błędzie i jego naprawie do zwięzłego, ustrukturyzowanego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia (wersja ekspercka)...")
    
    prompt_template = f"""
    Persona: Jesteś starszym inżynierem oprogramowania, który pisze zwięzłe post-mortemy do wewnętrznej bazy wiedzy. Twoim celem jest stworzenie notatki, która będzie maksymalnie użyteczna dla innych agentów w przyszłości.
    Przeanalizuj poniższy kontekst i wyciągnij z niego kluczowe, gotowe do użycia wnioski.
    Kontekst:
    [WADLIWY KOD]: {failing_code}
    [PEŁNY BŁĄD]: {error_traceback}
    [ANALIZA PROBLEMU]: {debugger_analysis}
    [POPRAWIONY KOD]: {corrected_code}
    Zadanie: Na podstawie powyższego kontekstu, wygeneruj obiekt, który będzie pasował do zdefiniowanej struktury.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomyślnie przedestylowano wspomnienie (wersja ekspercka).")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEŻENIE: Destylacja (ekspercka) nie powiodła się: {e}. Zapisuję surowe dane.")
        return {
            "problem_summary": debugger_analysis,
            "key_takeaway": "N/A - distillation failed",
            "raw_error": intelligent_truncate(error_traceback, 500)
        }
#pamiec dlugotrwala-zapis w meta agent, sukces 
def distill_success_memory(final_plan: str) -> dict:
    """Używa LLM do podsumowania udanego planu w zwięzłą notatkę."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o sukcesie...")
    prompt_template = f"""
    Persona: Jesteś starszym inżynierem AI, który dokumentuje udane strategie.
    Kontekst: Przeanalizuj poniższy plan, który zakończył się sukcesem i stwórz zwięzłe podsumowanie w formacie JSON.
    [FINALNY PLAN]: {final_plan}
    """
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        # Używamy nowego, lżejszego modelu DistilledSuccessMemory
        structured_llm = llm.with_structured_output(DistilledSuccessMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomyślnie przedestylowano wspomnienie o sukcesie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEŻENIE: Destylacja sukcesu nie powiodła się: {e}.")
        return {"plan_summary": "N/A - distillation failed"}
    
    
def distill_memory_content(debugger_analysis: str, failing_code: str, corrected_code: str) -> dict:
    """Używa LLM do 'przedestylowania' analizy debuggera i zmian w kodzie do zwięzłego formatu."""
    print("INFO: Uruchamiam proces destylacji wspomnienia o naprawie...")
    
    # Zamiast pełnego błędu, używamy zwięzłej analizy od debuggera!
    prompt_template = f"""
    Persona: Jesteś starszym inżynierem oprogramowania, który pisze zwięzłe post-mortemy.
    Przeanalizuj poniższy kontekst dotyczący naprawy błędu i wyciągnij z niego kluczowe, gotowe do użycia wnioski.
    Kontekst:
    [ANALIZA PROBLEMU WG DEBUGGERA]: {debugger_analysis}
    [WADLIWY FRAGMENT KODU]: {intelligent_truncate(failing_code, 500)}
    [POPRAWIONY KOD]: {intelligent_truncate(corrected_code, 500)}
    Zadanie: Na podstawie powyższego kontekstu, wygeneruj obiekt JSON zgodny ze strukturą DistilledMemory.
    """
    
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("INFO: Pomyślnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"OSTRZEŻENIE: Destylacja (naprawa) nie powiodła się: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}
    
    
    
    

    
def distill_full_fix_session(initial_error: str, fix_attempts: List[Dict], successful_code: str) -> Dict[str, Any]:
    """Używa LLM, aby podsumować całą sesję naprawczą w jedno zwięzłe wspomnienie."""
    print("  [INFO] Uruchamiam destylację całej sesji naprawczej...")

    # Tworzymy skonsolidowaną historię analiz debuggera
    consolidated_analysis = "\n".join(
        [f"Próba {i+1}: {attempt.get('debugger_analysis', 'Brak analizy.')}" for i, attempt in enumerate(fix_attempts)]
    )

    prompt_template = f"""
Persona: Jesteś starszym inżynierem, który pisze ekstremalnie zwięzłe post-mortemy. Priorytetem jest gęstość informacji przy minimalnej liczbie słów.

Przeanalizuj całą sesję naprawy błędu i wyciągnij z niej kluczowe wnioski.

[PIERWOTNY BŁĄD]:
{initial_error}

[HISTORIA ANALIZ Z NIEUDANYCH PRÓB NAPRAWY]:
{consolidated_analysis}

[KOD, KTÓRY OSTATECZNIE ZADZIAŁAŁ]:
{successful_code}

Zadanie: Wygeneruj obiekt JSON. Każde pole tekstowe musi być pojedynczym, klarownym zdaniem. Całość nie może przekroczyć 150 słów.
"""
    try:
        llm = ChatVertexAI(
            model_name=MAIN_AGENT, 
            project_id=PROJECT_ID, 
            location=LOCATION,
            max_output_tokens=512
        )
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("  [INFO] Pomyślnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"  [OSTRZEŻENIE] Destylacja sesji nie powiodła się: {e}.")
        return {"key_takeaway": "N/A - distillation failed"}


    
    
    
    
# --- FUNKCJA 1: Destylacja wspomnienia o UDANEJ NAPRAWIE ---
def distill_fix_memory(initial_error: str, fix_attempts: List[Dict], successful_code: str) -> Dict[str, Any]:
    """
    Używa LLM, aby podsumować całą, kompletną sesję naprawczą w jedno zwięzłe wspomnienie.
    Inteligentnie skraca duże fragmenty danych PRZED wysłaniem ich do LLM.
    """
    print("  [PAMIĘĆ] Uruchamiam destylację całej sesji naprawczej...")

    truncated_error = intelligent_truncate(initial_error, 1500)
    truncated_code = intelligent_truncate(successful_code, 2000)

    consolidated_analysis = "\n".join(
        [f"Próba {i+1}: {intelligent_truncate(attempt.get('debugger_analysis', 'Brak analizy.'), 500)}" for i, attempt in enumerate(fix_attempts)]
    )

    prompt_template = f"""
Persona: Jesteś starszym inżynierem AI, który pisze ekstremalnie zwięzłe post-mortemy. Twoim celem jest stworzenie notatki, która będzie maksymalnie użyteczna dla innych w przyszłości. Priorytetem jest gęstość informacji.

Przeanalizuj poniższą sesję naprawy błędu i wyciągnij z niej kluczowe wnioski.

<PIERWOTNY_BŁĄD>
{truncated_error}
</PIERWOTNY_BŁĄD>

<HISTORIA_ANALIZ_Z_NIEUDANYCH_PRÓB>
{consolidated_analysis}
</HISTORIA_ANALIZ_Z_NIEUDANYCH_PRÓB>

<KOD_KTORY_ZADZIAŁAŁ>
{truncated_code}
</KOD_KTORY_ZADZIAŁAŁ>

Zadanie: Wygeneruj obiekt JSON. Każde pole tekstowe musi być pojedynczym, klarownym zdaniem. Unikaj ogólników.
"""
    try:
        llm = ChatVertexAI(
            model_name=MAIN_AGENT,
            project_id=PROJECT_ID,
            location=LOCATION,
            max_output_tokens=1024
        )
        structured_llm = llm.with_structured_output(DistilledMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("  [PAMIĘĆ] ✅ Pomyślnie przedestylowano wspomnienie o naprawie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"  [PAMIĘĆ] ⚠️ OSTRZEŻENIE: Destylacja sesji nie powiodła się: {e}.")
        return {
            "problem_summary": "Distillation failed. The initial error was likely related to code execution.",
            "solution_summary": "A fix was applied, but could not be summarized.",
            "key_takeaway": "N/A - distillation process failed.",
            "tags": ["error", "distillation-failure"],
            "reusable_code_snippet": None
        }

    
    
    
def distill_successful_workflow(plan: str, final_code: str, langgraph_log: str) -> dict:
    """Używa LLM do podsumowania całego udanego procesu w jedną, bogatą notatkę."""
    print("  [PAMIĘĆ] Uruchamiam destylację całego udanego procesu...")

    truncated_plan = intelligent_truncate(plan, 2000)
    truncated_code = intelligent_truncate(final_code, 2000)
    truncated_log = intelligent_truncate(langgraph_log, 3000)

    prompt_template = f"""
Persona: Jesteś starszym inżynierem AI, który dokumentuje udane projekty w całości.
Kontekst: Przeanalizuj poniższe artefakty z pomyślnie zakończonego procesu przetwarzania danych. Twoim zadaniem jest wyciągnięcie esencji sukcesu zarówno z fazy planowania, jak i wykonania.

<FINALNY_PLAN>
{truncated_plan}
</FINALNY_PLAN>

<FINALNY_WYKONANY_KOD>
{truncated_code}
</FINALNY_WYKONANY_KOD>

<LOG_WYKONANIA>
{truncated_log}
</LOG_WYKONANIA>

Zadanie: Wygeneruj obiekt JSON zgodny ze strukturą `DistilledWorkflowMemory`. Rozróżnij wniosek z planowania od obserwacji z wykonania.
"""
    try:
        llm = ChatVertexAI(model_name=MAIN_AGENT, project_id=PROJECT_ID, location=LOCATION)
        structured_llm = llm.with_structured_output(DistilledWorkflowMemory)
        distilled_object = structured_llm.invoke(prompt_template)
        print("  [PAMIĘĆ] ✅ Pomyślnie przedestylowano wspomnienie o całym procesie.")
        return distilled_object.dict()
    except Exception as e:
        print(f"  [PAMIĘĆ] ⚠️ OSTRZEŻENIE: Destylacja procesu nie powiodła się: {e}.")
        return {"workflow_summary": "N/A - distillation failed"}

    
def generate_meta_insight(audit_report: str) -> Optional[dict]:
    """Używa LLM do wyciągnięcia z raportu audytora jednego, kluczowego wniosku."""
    print("  [AUDYT] Uruchamiam proces generowania wniosku META...")
    prompt = f"""
Przeanalizuj poniższy raport audytora. Twoim zadaniem jest znalezienie JEDNEJ, najważniejszej i najbardziej konkretnej rekomendacji dotyczącej ulepszenia systemu.
Jeśli znajdziesz taką rekomendację, przekształć ją w obiekt JSON zgodny ze strukturą MetaInsightMemory.
Jeśli raport jest ogólnikowy i nie zawiera konkretnych propozycji, zwróć null.
[RAPORT AUDYTORA]:\n{audit_report}
"""
    try:
        llm = ChatAnthropic(model_name=CRITIC_MODEL, temperature=0.2)
        structured_llm = llm.with_structured_output(MetaInsightMemory)
        insight_object = structured_llm.invoke(prompt)
        print("  [AUDYT] ✅ Pomyślnie wygenerowano wniosek META.")
        return insight_object.dict()
    except Exception as e:
        print(f"  [AUDYT] ⚠️ OSTRZEŻENIE: Nie udało się wygenerować wniosku META z raportu audytora. Błąd: {e}")
        return None    
    




